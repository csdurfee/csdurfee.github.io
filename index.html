<!DOCTYPE html>
<html lang="english">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>mathletix</title>
    <link rel="shortcut icon" type="image/png" href="/favicon.png">
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
    <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="mathletix Full Atom Feed" />
    <link rel="stylesheet" href="/theme/css/main.css" type="text/css" />
    <link rel="stylesheet" href="/theme/css/pygments.css" type="text/css" />
    <meta name="generator" content="Pelican" />
    <meta name="description" content="" />
    <meta name="author" content="casey durfee" />
</head>
<body>
    <header>
        <nav style="overflow: hidden;">
            <ul>
                <li class="selected"><a href="/">Home</a></li>
                <li><a href="/pages/about.html">About</a></li>
            </ul>
        </nav>
        <div class="header_box" style="height: 50px">
        <h1><a href="/">
            <image src='' class="avatar" width="50px" /><span class="site_title">mathletix</span>
            </a></h1></div>
        </div>
    </header>
    <div id="wrapper">
        <div id="content">            <h4 class="date">Jul 17, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/last-fair-deal-in-the-country.html" rel="bookmark" title="Permanent Link to &quot;Last fair deal in the country&quot;">Last fair deal in the country</a>
                </h2>

                
                

                <p>(This is an excerpt from my book about sports gambling. Code used, and early drafts of some of the chapters can be found at <a href="https://github.com/csdurfee/book">https://github.com/csdurfee/book</a>.)</p>
<h2>Efficiency of betting markets</h2>
<p>The efficient market hypothesis is that given enough time and competition, free markets are able to establish the correct price for a commodity. In the case of sports betting, we could think of it as the price of a money line bet. (On a money line bet, you are betting on who will win the game, and you get a smaller payout for betting on the favorite, and a larger payout betting on the underdog. If the money line is negative, that's how much money you have to risk in order to win $100. If it is positive, that's how much money you win if you risk $100. I go into further detail in the book. If it sounds like a bad way to write the odds, you're correct.)</p>
<p>The market maker will respond to an imbalance in bets by adjusting the price. If CLE -300 is a good value, people will rationally want to take it, driving the price up to, say -400. If it is a bad value, people will rationally want to take the other side and the price will go down to -200. These rational actors will collectively push the price towards the best possible estimate that humans can make. It serves as a sort of collective intelligence.</p>
<p>In the first installment, I showed that humans are irrational when it comes to sports betting, so I was skeptical of how good, or fair, the lines could be. Could I find proof of this collective intelligence in action? Are there any obvious market inefficiencies?</p>
<h3>The data</h3>
<p>Stats are from the NBA season. I screen-scraped the data from <a href="https://www.sportsbookreview.com/betting-odds/nba-basketball/">sportsbookreview.com</a>. All data is from the MGM Grand. Unfortunately, some data is missing from around Christmas time, and a few random days in between. In total, 32 games are missing from the data set out of 1230 total, 2.6% of all games. These are games that don't appear on sportsbookreview's website, or have incomplete data on there.</p>
<p>This is an analysis of the MGM Grand's NBA lines for 2025. It's not a comprehensive guide to how the lines work.</p>
<p>There are always two lines on each game, one for the home team and one for the away team. Each side may have different vigs. Say for instance Bucks @ Pacers starts out at IND +3.5 -110/MIL -3.5 -110. It could close at IND +3.5 -115/MIL -3.5 -105. So it costs more to bet on the Pacers, but the actual line didn't move.  I'm mostly ignoring that, but will point out when it's relevant.</p>
<p>"Line" and "spread" mean the same thing.</p>
<h3>A note about pushes</h3>
<p>When the final score agrees with the line exactly, neither side of the bet can be declared a winner. This is called a push. The bet is cancelled and everybody gets their money back. The casino makes nothing.</p>
<p>The MGM Grand always keeps point spreads on the half point (eg +6.5 or +7.5 rather than +7) so that they will never push. I don't think it's a bad policy, and I'm surprised more sportsbooks don't do it. The sportsbooks know how good their customers are at betting, so they should probably shade the point spread a half a point towards the side of the bet that has the less savvy bettors on it. (More about this in the book.) </p>
<h3>Analysis</h3>
<p>If there is a wisdom of crowds, the final lines should be more accurate than the opening lines. Are they?</p>
<p>My code calculates difference between the final score and the line, called the error.  Because the MGM's lines always end in a half point, that means the error is going to be artificially high -- there will never be a game where it is exactly zero.</p>
<p>The opening and closing lines are essentially a set of predictions. The smaller the difference between the line and reality, the better the prediction. <a href="https://en.wikipedia.org/wiki/Mean_squared_error">Mean Squared Error</a> is a standard way to compare two prediction systems in statistics and machine learning.</p>
<p>The MSE for the opening lines is 191.06, and the closing lines is 184.8. So we can say that in aggregate, the betting market does "know" a little bit more about basketball than the handicappers creating the original lines. </p>
<p>MSE can't tell us how good the closing lines are, though, just that one set of predictions is better than another set. It's a relative measure. As I'll show, the lines <em>should</em> be off by a little bit, because they're a prediction of the mean outcome.</p>
<p>Let's look at how far the lines were off by. the Os are the opening lines, and X's are the closing lines. If the <em>X</em> is closer to the center line than the <em>O</em>, the market action made the line more accurate. I've plotted a random sample of 300 games to make the plot more readable.</p>
<p><img alt="/img/scatter-mess.png" src="/img/scatter-mess.png"></p>
<p>Unfortunately, that doesn't really show us much about how the closing lines are better than the opening ones. Let's dig into the details.</p>
<h3>Adam Smith, Handicapper</h3>
<p>I looked at how often the closing lines were more accurate than the opening lines: </p>
<p>Closing lines better:    467  <br>
Opening lines better:    384  <br>
Tied:                    347    </p>
<p>If the free market were a handicapper, and we interpreted the line movements as a bet on one side, they would have a 54.88% winning percentage (and 347 pushes).</p>
<p>While that's a respectable win percentage for a human trying to beat the spread, I was expecting better from the free market. The market only being right 55% of the time holds true for a couple of previous seasons I have looked at as well. NBA betting, as a market, is not very efficient.</p>
<p>The people that set the opening lines aren't trying that hard to be accurate. It's just a first guess. Only a tiny percentage is wagered at the opening line number. However, there are good reasons why lines tend not to move very much, even when the opening line is a bad one. I talk about this further in my book, though for a truly in-depth explanation, check out <em>The Logic of Sports Betting</em>, by Miller and Davidow.</p>
<h3>Closing Line Value</h3>
<p><a href="https://www.pinnacle.com/betting-resources/en/betting-strategy/using-the-closing-line-to-test-your-skill-in-betting/7e6jwjm5ykejuwkq">The conventional wisdom</a> is that sports betting markets are efficient, so that the only way to make money over the long run is by doing better than the closing lines, picking up on any inefficiencies in the opening lines before the market eliminates them. Anyone else can only make a profit due to chance. From this perspective, the right way to measure a handicapper's skill is how their picks compare to the closing line. This is known as closing line value (CLV). </p>
<p>There's good statistical evidence that beating the closing line is positively correlated with higher profits. But when the market is wrong 45% of the time, overindexing on CLV seems like a bad idea.</p>
<p>CLV gets described as being the best way to test a handicapper's skill, but that also seems silly to me. Statistically, the best way to test a handicapper is to have them write out what they think the lines should be, rather than making a binary decision (favorite or underdog) versus somebody else's line. If a handicapper's lines are closer to the truth than the closing lines, they are good at handicapping. Looking at what bets they took is only a secondary signal of that. If they took Nuggets -7, is it because they thought the true line should be Nuggets -8, or Nuggets -12? </p>
<h3>When the line doesn't move</h3>
<p>Setting aside why the market moves in the wrong direction 45% of the time, I'm curious about the games where the spread didn't move at all. Maybe those lines were perfect as-is? If so, we'd expect to see equal splits of home vs. away winners, and underdog vs. favorite winners.  There shouldn't be any bias to those games. The free market is essentially labelling these the pinnacle of the handicapper's art, impossible to be improved upon. </p>
<p>The difference between the predicted outcome (the line) and the actual outcome is a combination of how much the line maker got it wrong, plus random variation. So the games where the line didn't move should be totally random, right?</p>
<p>They're not. If we look at games where the line didn't move, the away team went 184-163 in those games. Someone betting the away team in every game where the line didn't move would win 53% of their bets, for 4.7 units of profit at full vig, or 11.2 units of profit at "reduced juice" (both "units" and "reduced juice" are explained in detail in the book.)</p>
<p>There's also a bias towards underdogs, who went 186-161 in this situation. Always taking the underdog would give a 53.6% winning percentage, for 8.9 units at full vig, or 15.3 units at reduced juice.</p>
<p>There's an even bigger bias if we combine the two. Away underdogs went 122-92 in these games, which is a 55.2% winning percentage, for 13.1 units of profit at full vig, and 17.06 at reduced juice.</p>
<p>None of these results are statistically significant, but they are very :thinking_face_emoji:</p>
<h3>About the vig</h3>
<p>When the vig is imbalanced, the side with the higher vig should be more likely to win, because they're winning less money in return. Moving the vig from -110 to -115 is a way for the bookmaker to encourage bets on the other side without moving the line. Likewise moving it to -105 is a way to encourage bets on that side.</p>
<p>Since the MGM Grand always keeps their line on the half point, we'd expect them to adjust the vig often rather than change the spread. They do for most of the games where they didn't move the lines, but 39% of the time the vig stays at -110.</p>
<p>If we break down the games where the line didn't move by vig, the underdogs went 62-43 when the vig was high (-115), 74-62 when the vig was at the standard level (-110), and 50-56 at low vig (-105).</p>
<p>Someone taking the underdogs when the line doesn't move, and the vig is -110 or -115, would've gone 136-105 this season, a 56.4% winning percentage, and around 18 units of profit (factoring in the additional -115 vig on some bets).</p>
<p>Now, the strategy is pretty convoluted, and won't necessarily hold for future seasons, but it's definitely proof that there could be irrational factors at work in the market. It certainly doesn't show the market to be the well oiled machine that Closing Line Value assumes it is.</p>
<h3>Underdogs and aways</h3>
<p>Winners ended up being pretty evenly divided between favorites and underdogs by the end of the season, but underdogs were way ahead for most of the year.  </p>
<p>Betting every single underdog against the spread over the first quarter of the season would've been fairly profitable -- a 165-136 record (54.8 winning percentage), and 15.4 units at full vig. People betting favorites got killed at the beginning of the season.</p>
<p>Dogs and favorites were basically even through the middle half of the season, before favorites finished off 167-144 (53.7% win percentage) to even things out.</p>
<p>Here's a plot of the winning percentage of favorites over the course of the season. I skipped the first 50 games because of noise. The yellow line represents the winning percentage necessary for betting all underdogs to be profitable (at standard vig). That happens when the favorites win less than 47.6% of the time (which means underdogs win more than 52.4% of the time.)</p>
<p>It wasn't until the last month of the season that blindly betting all favorites started being a losing proposition, even factoring in the vig.</p>
<p><img alt="/img/wp-vs-gameno.png" src="/img/wp-vs-gameno.png"></p>
<h3>Did the lines improve over time?</h3>
<p>I was curious if there was evidence that the errors were getting smaller, or more predictable over time.</p>
<p>The raw errors are too noisy to see any sort of pattern:</p>
<p><img alt="/img/err-vs-line.png" src="/img/err-vs-line.png"></p>
<p>This is a plot of the 100 game moving average of the absolute error of the closing line. I don't see any trends to suggest the lines got better with time (though perhaps this isn't the best way to visualize it):</p>
<p><img alt="/img/closing-line-err.png" src="/img/closing-line-err.png"></p>
<p>The size of the error against the closing line isn't the ideal metric, because not all points are created equal -- the higher the line, the less surprising the error. (I'm going to skip discussing that for now, but it's explained in the book.)</p>
<h3>Did the lines change over time?</h3>
<p>I wondered whether the size of the lines changed over time -- did the games get more or less competitive over the course of the season?</p>
<p>This is a 100 game moving average of the average size of the spread. As we can see, they did get bigger near the end of the year.</p>
<p><img alt="/img/spread-over-time.png" src="/img/spread-over-time.png"></p>
<p>It's possible the trend is due to scheduling, but the change at the end seems significant -- teams tend to give up near the end of the year. Bad teams want to be as bad as possible in order to get the best odds in the NBA draft, so they're not that competitive.</p>
<h3>What type of games are affected by line movement?</h3>
<p>There are 130 games where the winner flipped from the favorite to the underdog, or the underdog to the favorite, because of the line movement. In other words, these are games where either side could have won the bet, depending on whether you took the opening line or the closing line.</p>
<p>These games were perfectly balanced -- 65 times, the favorite won (vs the closing line); 65 times the underdog won.</p>
<p>What about games where the spread was extremely accurate (off by 3 points or less)? Underdogs went 138-121 in those games (53.2%).</p>
<p>The difference is more dramatic in games where the line was off by 1 point or less. The underdogs went 56-33 (63% win percentage). Of course, there's no way to use that as a betting strategy since we can't identify these games before the fact, but it does show a small potential bias in favor of underdogs. </p>
<h3>What would "perfect" lines even look like?</h3>
<p>It's rare to see NBA lines that are bigger than +15/-15 points. There were 15 this season, about 4.4% of all games. That's around one NBA game a week with a line that high.</p>
<p>By contrast, 31% of NBA games end with a score differential of over 15 points. That's 7x more often, roughly one game a day.</p>
<p>The lines really shouldn't be as large as the final score differential, because they are an estimate of the mean outcome of the game. If the Celtics beat the Raptors by 54 points, that doesn't mean the line <em>should</em> have been Celtics -54. The Celtics and Raptors played 4 times last season (data taken from <a href="https://www.basketball-reference.com/teams/TOR/2025_games.html">basketball-reference</a>). The first game, Boston won by 3. The second, Boston won by 54. The third game, the Raptors won by 13. The last game, Boston won by 10.</p>
<p>Boston won by an average of 13.5 points, so BOS -13.5 would be a reasonable line for all four games, as that's the best estimate we can make of their difference in skill. (A slightly better line would've been BOS -12.5, because then both teams would've gone 2-2 against the spread.)</p>
<p>The actual outcomes might be all over the place, but the spread isn't meant to predict the actual outcome, just the point where both sides are equally likely to win the bet. So the errors against the spread end up being bigger on average than the spreads themselves.</p>
<p>Here's a histogram of the spreads (for the away team) overlaid on a histogram of the errors against the spread:</p>
<p><img alt="/img/spread-vs-score-diff.png" src="/img/spread-vs-score-diff.png"></p>
<p>If we look at just the score differential, we can stick a bell curve over the top and it looks pretty normal:</p>
<p><img alt="/img/score-diff-normal.png" src="/img/score-diff-normal.png"></p>
<h3>Simulating games from the spreads</h3>
<p>The problem is, these aren't outcomes from one distribution. Every game is a sample from a different distribution. Each one has a different mean (the spread) and a different variance (how predictable games are between the two teams). The results end up looking kinda normal (because a lot of things do).</p>
<p>I decided to simulate the NBA, to show how the point differentials are going to be much bigger than the original lines. </p>
<p>For every game, I simulated the point differential by sampling from a normal distribution with the mean set to that game's spread, and the variance equal to the sample variance of all games that season with that spread. That's kind of a rough way to simulate things, but I want to show the overall shape is close to the actual point differentials.</p>
<p>Here's how they match up:</p>
<p><img alt="/img/point-differential.png" src="/img/point-differential.png"></p>
<p>I know that's a pretty rough simulation. NBA games end in a one point difference less often than expected due to tactical reasons, so there's a little notch right in the center of the green curve. If a team is down one, they foul the other team and hope they miss at least one of their free throws. There's also more simulated games than I would expect that end with a differential of +1 or -1.</p>
<p>Setting that aside, hopefully the simulation shows that the lines shouldn't be bigger than they are, even though they are frequently off by many multiples compared to the final result. If the line is Dallas -3 and the other team wins by 27, that doesn't mean the line was off by 30 points. The line is meant to be an estimate of the mean outcome, if the teams played each other a large number of times. We only get one sample, though.</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/last-fair-deal-in-the-country.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/sports-betting.html" rel="tag">sports betting</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/basketball.html" class="tags">basketball</a>
                    &nbsp;<a href="/tag/your-parlay-sucks.html" class="tags">your parlay sucks</a>
                </div>
            </article>            <h4 class="date">Jul 16, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/cool-parlay-bro.html" rel="bookmark" title="Permanent Link to &quot;Cool Parlay, Bro&quot;">Cool Parlay, Bro</a>
                </h2>

                
                

                <p>(This is an excerpt from my book about sports gambling. Code and early drafts of some of the chapters can be found at <a href="https://github.com/csdurfee/book">https://github.com/csdurfee/book</a>.)</p>
<p>Sportsbooks have many ways of encouraging people to lose their money as quickly and efficiently as possible. One of the best ways to do this is a type of bet called the parlay. "Parlez" means "to talk" in French, so it's no surprise dudes always want to talk about them online.</p>
<p>The idea behind a parlay is that you can bet on multiple events at once and if they all win, you make a nice profit, otherwise you lose. On a technical level, if the first bet on the parlay wins, the winnings are immediately placed on the second bet in the parlay, if that wins, it rolls over to the third bet, and so on. It's a sequence of bets, with the stakes going up with each bet. The individual bets in the parlay are known as "legs".   </p>
<p>I'm going to keep asking this question: why would they be offering this bet if it was good for you?  Parlays might be more fun, but that just means they found a way to get you to part with your money easier, which sounds like a bad thing.</p>
<p>We can compare different bets by using Expected Value (EV). EV is the weighted average of all the possible outcomes. If the expected value is positive, we will make money over the long run; if it's negative, we will lose money. </p>
<p><a href="https://www.vegasinsider.com/parlay-calculator/">The traditional payout on a 4 team parlay is 10:1</a>. What is the expected value of such a play? is it higher or lower than taking the individual bets?</p>
<p>It's easy to grind the math on this one, and see which option is better. I can't say "make us more money" because both types of bets are guaranteed losers without some sort of edge.</p>
<p>Parlays are such a bad type of bet on the surface that to understand them, I have to give a little taste of parlay culture first.</p>
<h3>Nephew Doug</h3>
<p>Say you want to place some bets. You just learned about betting on sports, so as a newbie you're trying to learn from experts by listening to gambling podcasts. These guys have been gambling for decades. Surely they must know what's up. Their wisdom will give you the edge for sure. Surely they will keep you from making costly mistakes.</p>
<p>You've listened to Nephew Doug's podcast, and wrote down his Locks of the Week. You're ready to enter them into your betting app, which has been hand-optimized to be as much of a dopamine and money sink as possible.</p>
<p>Because you listen every week, you know Nephew Doug has been burdened by the Gods with the gift of prophecy. Just ask him. He's like a modern day Cassandra, only it's about how the Cowboys are always going to suck. </p>
<p>Now, the Gods like a little competition. The Olympics were invented as a religious ceremony in their honor, after all. But they're not above making a call from on high to nudge the result a little bit. Yes, Zeus is definitely a Chiefs fan.</p>
<p>So you believe ahead of time Nephew Doug's picks will win 55% of the time. Which way of betting these picks will bring you the most money in the long run?</p>
<p>1) "throw 'em all in a 4 team parlay" like Doug and his buddy Jorts Guy do  <br>
2) randomly choose 3 of Nephew Doug's picks and bet them individually. Don't do anything with the 4th one.</p>
<p>Maybe option 2 seems insane to you. But let's game it out. </p>
<p>You listen to Nephew Doug, but I don't. My assumption would be this guy is no better than a coin flip -- he only wins 50% of the time, or close to it. Parlays at old school casinos pay at 10:1 and online sportsbooks pay 12.28:1. Let's see how that works out at 10:1 payout, the ones Jorts Guy and Nephew Doug were cutting their teeth on back in the day.</p>
<p>There are two ways to do the comparison. We could bet $100 on the parlay, and compare to putting $25 on each leg. Or we could compare $100 on the parlay to $100 on each leg.</p>
<p>Neither way of comparing is entirely fair, though, because the stakes increase throughout each leg of the parlay. If a gambler bets $100 on a 4 team parlay, they're risking $100 on the first leg. Assuming they keep winning, they're risking $190 on the 2nd leg, $300ish dollars on the 3rd leg, and $600ish dollars on the 4th leg. </p>
<p>For each leg of the parlay, the gambler should consider the risk of losing out on $600 if they took a 3 team parlay and it won. Risking $100 on the 4 leg parlay is sort of like taking 4 different $600 bets, because each one could cost the gambler that much if it loses.</p>
<p>I will be comparing risking $100 on the parlay versus $25 on each of the legs.</p>
<h3>7x worse</h3>
<p>This difference only matters for bettors with a high degree of skill. For the beginner, who we can reasonably assume will no better than a coin flip, the parlay is always a worse option. Almost 7 times worse. The parlays lose about 30% per bet, versus 4.5% for the straight bets.</p>
<p>Yikes. Maybe parlays are fun, but it's like blowing the whole week's vig budget on Sunday when compared to taking one regular bet a day.</p>
<p>Even a stretch of good luck is going to get swallowed up real fast if you're losing 30% of the stake on average. These types of parlays are a sadness machine.</p>
<h3>Partially blessed</h3>
<p>What if Nephew Doug truly has been partially blessed by the Gods, and can beat the lines 55% of the time? That's pretty good. Only a small percentage of sports bettors can achieve that, in my research.</p>
<p>The gambler should turn a profit either way, but maybe parlays offer a better return? </p>
<p>The parlays have an expected return of +0.66%, versus +5% for the straight bets. The straight bets make 7.6x as much money.</p>
<p>OK, what about if we just don't play the 4th bet? We will bet on the first three legs, and don't play the 4th one. We put the $25 for the fourth bet in our piggy bank and earn a 0% interest rate.</p>
<p>We're throwing out a bet with positive expected value, and risking angering the Gods by ignoring their chosen sports prophet, Nephew Doug. Perhaps that will tilt things in the parlay's favor.</p>
<p>Nope! The straight bets have a return of +3.75%, which is still 5.7x better than the parlays.</p>
<p>Finally, let's say we flip a coin to decide the 4th bet. It will only win 50% of the time, which means it's a guaranteed loser because of the vig -- you win less than you have to risk. (There is much more about the vig in the book.)</p>
<p>Nope! The coin flip hurts our profitability, but we're still clearing +2.6%, which is 4x better than the parlays. We'd have to do 2 of 4 bets by coin flip for the parlays to be more profitable.</p>
<p>To be fair, 55% is just <em>barely</em> profitable for an old-school parlay. The profitability increases exponentially as the win rate goes up. There is a win rate where parlays would make more money than the straight bets. If you win 100% of the time, the parlay is definitely a better deal, right? 10x profits taking the parlay versus 4x taking the original bets. </p>
<p>Successful handicappers who sell their picks on the internet are only winning around 55% of the time. If you have to do as well at something as people who do it for a living just to break even, that's not a great plan.</p>
<h3>Online Parlays</h3>
<p>Online 4 leg parlays pay out $1228 per $100 risked, which make them a little less bad. However, they're still way worse for the average gambler than taking the straight bets. At a 50% win rate, online parlays have an expected return of -17%, versus -4.5% for the straight bets. So they're 3.7x worse. They're half as bad as the old school parlays, but still terrible.</p>
<p>That $1228.33 payout for online parlays was chosen deliberately. It means that online parlays have the same break-even point as the individual bets (at standard vig) -- winning 52.4% of the individual bets. Because parlay profits climb exponentially, that means a skilled bettor with a 55% win rate will have a much higher EV with the parlays. They will have a +21.6% rate of return, versus +5%.</p>
<h3>EV doesn't describe the range of outcomes</h3>
<p>Expected Value is a good way of determining whether you can make money taking a certain type of bet, but it doesn't describe the range of possible outcomes.  With parlays, a lot of those outcomes are bad, even for a gambler with enough skill to make them more profitable on paper.</p>
<p>Simulations are great in this sort of situation, because they can convey the range of possible outcomes in a way EV can't.  I simulated 200 individual bets versus 50 parlays, and ran that 10,000 times. Our virtual gambler wins 55% of the time, and bets $100 on parlays, $25 on each individual bet.</p>
<p>The individual bets made more money (or lost less money) than the parlays 38% of the time. Just because the expected value is higher for the parlays, that doesn't mean they will always be more profitable. </p>
<p>More concerningly, the parlays had big losses (down more than $1000 on $100 bets) 33% of the time. That only happened 0.2% of the time on the straight bets. There were almost no small losses with the parlays, because the payout is so high and the number of bets (50 parlays) is so low. Winning one more parlay could be the difference between being down $1000, and breaking even.</p>
<p>Expected Value can't be the only thing we consider, because we don't live an infinite life. Our whole life is a small sample size, if the variance is high enough. Our bankrolls are always finite. The fact that we might make more money over 100 years is undercut by the fact that we'll die or go broke before then.</p>
<p>Even for the skilled bettor, parlays make it more of a game of luck. Let's say my simulation represents an entire season of betting on basketball. Imagine playing the parlays with a 55% win rate, being better than almost everybody at handicapping, and still having massive losses one season in three? When you'd make more money taking the individual bets 40% of the time?</p>
<h3>Parlay psychology</h3>
<p>There's a weird psychology to the parlay as well. These parlays only win once every couple of weeks, so they'd be kind of a grim strategy in practice. A good bettor taking the individual bets will have winning days over half the time. Is it better to feel like a winner most days, or every other week?</p>
<p>Most people don't have to consider that question, though. Without a huge amount of skill at betting, the only scenario where they might make sense is as a lottery: something that can deliver a tiny chance of massive payouts without any skill. </p>
<p>What happens if we do the same simulation, but the win rate is 50%, like a coin flip, or most sports bettors? The parlays make money 38% of the time! Taking 200 straight bets will only make money 26% of the time. Isn't that a little surprising?  Even though the straight bets have better expected value (well, less bad), they also offer less of an opportunity to make money based on chance alone. </p>
<p>What about over a longer time frame? I simulated 500 parlays versus 2,000 straight bets by flipping a coin. The parlays make money 12% of the time, versus only 1.74% of the time for the straight bets. However, the losses are much, much bigger than the wins:</p>
<p><img alt="img/parlay-500.png" src="img/parlay-500.png"></p>
<p>12% is 1 in 8, which isn't that rare. 500 parlays could end up stretching over multiple seasons, perhaps a lifetime of sports betting. That means somebody who was making picks by flipping a coin could end up looking like a pretty good bettor for a long stretch if they are taking parlays. Of course, 88% of people will lose money, far more money than the 12% of profitable bettors win. In practical terms, it's like a lottery where you have a 12% chance of winning $3617, but an 88% chance of losing $10,221.</p>
<p>It's really, really hard to tell if someone taking bets at long odds is actually good at betting, not without thousands of documented bets. Over 50 parlays, or even 500, it's not that surprising for some people to look smart on parlays by chance alone. It would be much better to assess their skill based on the individual bets they took within the parlays.</p>
<h3>Other parlays</h3>
<p>Parlays with only 2 or 3 legs have higher relative payouts compared to 4 leg parlays, so they're not nearly as bad. They'll also have less variance in outcomes than the 4+ leggers. I'll leave those calculations to the reader, though. While they're one of the least bad bets offered by the average sportsbook, it's extremely rare to see people talking about 2 or 3 leg parlays online. Gamblers love the higher payouts and drama of parlays with a bunch of legs. I will have a lot more to say about how people actually play the parlays in a future installment.</p>
<p>Same Game Parlays (SGPs) are a new type of bet which allows the player to make multiple wagers on the same game. For instance, someone could bet on their favorite team winning and their favorite player scoring over a certain amount of points and the guy they hate on the other team scoring under a certain amount of points, with a big payout if all 3 things happen. SGPs have become the most popular type of bet I see online, and deserve their own lengthy discussion. For now just think of them as the vape pens of betting. They're obviously super addictive, extremely popular with younger people, and you can't really know what's in them, but it's probably bad.</p>
<h3>Gambling gurus</h3>
<p>I've taken up lot of hobbies over the years. It seems like every time I take up a new hobby, I end up spending a lot of money on stupid stuff at the beginning. Then I get into it more, and realize what matters.</p>
<p>There is an adverse selection process, where people who are new to a hobby have no idea what's actually good, what they actually need, or what things should actually cost. Filled with zeal to get started, they end up overpaying for inferior goods. Same thing for travelling in a new country. The guys at the train station trying to hustle you into a taxi are definitely not hooking you up with the cheapest way to get around.</p>
<p>Betting experts, the kind who have podcasts and big followings on social media, are supposed to know more about this stuff than the average person. They're supposed to be like the guidebooks, or the seasoned traveller telling the newbie to walk 2 blocks and take the metro for $2 instead of paying $100 for a taxi. Yet they're pushing parlays and other sucker bets, and pushing sportsbooks that charge full vig and ban anybody who wins too much. The "experts" are pushing beginners into bad situations.</p>
<p>Most of them don't do any better than flipping a coin, so I doubt they're actually making money on their "can't miss locks of the week". Gambling ads, sure. Everybody's taking gambling money right now, regardless of how it will hurt their brand, their audience, and sports long term. Clearly there's a lot of money in talking about it. That gambling money is there because these self-styled experts bring the sportsbooks more customers -- losing customers, specifically. </p>
<p>Where's all that ad money coming from? The sportsbooks wouldn't be throwing money at influencers who were actually winning consistently. Any gambling show they sponsor is pretty much guaranteed to lose you money, or it wouldn't be sponsored. Any bet they're promoting heavily, like they do with parlays, is because it makes them more money that way. You shouldn't need to know any math to figure out why they're pushing teasers and parlays and "profit boosters". I love that last one. It's like saying Idi Amin served mankind. Why would they care about boosting YOUR profits? </p>
<p>Unlike gamblers, sportsbooks don't make negative expected value plays due to emotions or lack of information. Your irrationality is their entire business.</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/cool-parlay-bro.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/sports-betting.html" rel="tag">sports betting</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/your-parlay-sucks.html" class="tags">your parlay sucks</a>
                </div>
            </article>            <h4 class="date">Jul 12, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/sports-betting-and-the-limits-of-rationality.html" rel="bookmark" title="Permanent Link to &quot;Sports betting and the limits of rationality&quot;">Sports betting and the limits of rationality</a>
                </h2>

                
                

                <p>Earlier this year, I wrote most of a book about the psychology and mathematics of sports gambling called <em>Your Parlay Sucks</em>. The book never quite came together, and is probably too weird to ever get published, but it has some interesting bits, so I figured I'd share them here.</p>
<p>Why did I get interested enough in sports betting to write a whole book about it? I think it's because I'm fascinated by the limits of rationality. Philosophers, economists and social scientists would like to treat humans as though they are capable of making rational decisions. That conflicts with the real world, where even pretty smart people make irrational choices. I certainly have. </p>
<p>Sports betting is a sort of rationality lab. You and I might have different values or beliefs. What's crazy to me might be normal to you, or vice versa, but we should both be able to agree that placing bets that are guaranteed to lose money is irrational.</p>
<p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1553935">This paper</a>, "Intuitive Biases in Choice versus Estimation", is a wonderful illustration of cognitive bias and irrationality in the realm of sports betting.  </p>
<p>The researchers had people bet on NFL football against the point spread. If you're not familiar, the idea behind the point spread is to attract an equal amount of action on both sides of the bet by handicapping one of the teams. If you bet on the favorite, they need to win by at least the amount of the spread for the bet to win. The other side side wins if the team loses by less than the spread, or wins the game outright.</p>
<p>Gamblers can bet either side, and if there are more bets on one side than the other, the sportsbook can change the spread to attract equal action. So there's a potential for the wisdom of crowds to kick in, the invisible hand of the market moving the line towards the best estimate possible.</p>
<p>Of course, that depends on gamblers being rational. A rational gambler has to be willing to take either side of a bet (or not bet at all), depending on the spread. If the spread is biased towards the underdog, they should be willing to take the underdog. If it's biased towards the favorite, they should take the favorite. And if the line is perfectly fair, they shouldn't bet at all.</p>
<p>As I showed a while back with <a href="/majority-voting-in-ensemble-learning.html">ensemble learning</a>, the wisdom of crowds only works if the errors that people make are uncorrelated with each other. If most people are wrong about a particular thing, the "wisdom of crowds" will be wrong, too.</p>
<p>This study found that people are consistently irrational when it comes to point spreads. They will tend to bet the favorite, even though both sides should have an equal chance of winning. It's probably easier to focus on which team is better, and assume that the better team is more likely to win against the point spread as well. It's harder to imagine the underdog losing the game but winning the bet, or pulling an upset and winning outright. </p>
<p>The study took things further and adjusted the lines to be biased against the favorite team, so that taking the favorite would be guaranteed to lose more than 50% of the time. They even told the gamblers that they did this. And the gamblers still overwhelmingly picked the favorites. The researchers continued the study for the whole season. Even after weeks and weeks of steadily losing, being told over and over that the lines are unfair, the gamblers still preferred to take the favorites. They never learned. The participants got to keep their winnings, so they had an incentive to be right. And they still couldn't do it.</p>
<p>Sportsbooks have a lot of ways of trick people into taking extra bad bets, as I will show. But they don't really need to. People will consistently take bad bets even if they should know they're bad bets. </p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/sports-betting-and-the-limits-of-rationality.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/sports-betting.html" rel="tag">sports betting</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/football.html" class="tags">football</a>
                    &nbsp;<a href="/tag/your-parlay-sucks.html" class="tags">your parlay sucks</a>
                </div>
            </article>            <h4 class="date">Jun 30, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/the-final-word-on-the-hot-hand-for-now.html" rel="bookmark" title="Permanent Link to &quot;The final word on the hot hand (for now)&quot;">The final word on the hot hand (for now)</a>
                </h2>

                
                

                <p>(Notebooks and other code available at: <a href="https://github.com/csdurfee/hot_hand">https://github.com/csdurfee/hot_hand</a>.)</p>
<p>Last time, we found that there are many players like LeBron, where their FG% is higher when they've missed most of their last 5 shots than when they've made most of them. However, most players don't have enough attempts when they've gone 0 or 5 out of their last 5 for a good statistical analysis.</p>
<p>So instead I will be looking at a binary split -- I will call a player <em>cold</em> when they've made 0, 1 or 2 of their last 5 shots, and <em>hot</em> when they've made 3, 4 or 5 of their last 5. Most players have a FG% between 40 and 60%, so this nicely splits them into times when they're shooting better than average versus worse than average.</p>
<h2>Anthony Edwards</h2>
<p>Anthony Edwards ("Ant") is particularly unstreaky for a young player. He's only completed 5 seasons in the league, but has the 5th biggest z score of the last 20 years. He could definitely catch LeBron someday.</p>
<p>Ant has the LeBron-like pattern of FG% trending downward when he's <em>hot</em>. He doesn't have anywhere near the volume of LeBron, so the spike at 20% (1/5) might just be noise. But overall, he shoots worse when he's been shooting well.</p>
<p><img alt="ant-last-5" src="/img/ant-last-5.png"></p>
<p>The trend appears to be due to shot selection. He takes far more above the break 3 pointers when he's <em>hot</em> than when he's cold. The additional 3 point attempts come at the expense of shots in the restricted area.</p>
<p>Here are the changes in tendencies:</p>
<pre>
| BASIC_ZONE            |   hot |   cold |   diff |
|:----------------------|------:|-------:|-------:|
| Above the Break 3     |  41.5 |   31.7 |    9.8 |
| Corner 3              |   3.6 |    4.8 |   -1.2 |
| In The Paint (Non-RA) |  13.4 |   14.6 |   -1.1 |
| Mid-Range             |  14.1 |   12.2 |    1.9 |
| Restricted Area       |  27.4 |   36.7 |   -9.4 |
</pre>

<p>Of course, this would be justified if Ant shot above the break 3's better when he's <em>hot</em>, but he doesn't. He makes 37% of his above the break 3's when he's <em>cold</em> but that drops to 34% when he's hot. So he's trading restricted area shots, with an expected value of .601 * 2 = 1.202 points, for above the break 3's, with an expected value of .34 * 3 = 1.02 points.</p>
<p>Here are the changes in FG percentages. His FG% on corner 3's goes up, but it's on insignificant volume:</p>
<pre>
| BASIC_ZONE            |   hot |   cold |   diff |
|:----------------------|------:|-------:|-------:|
| Above the Break 3     |  34   |   37.1 |   -3.1 |
| Corner 3              |  45   |   33   |   12   |
| In The Paint (Non-RA) |  40.8 |   34   |    6.8 |
| Mid-Range             |  36.3 |   34.8 |    1.5 |
| Restricted Area       |  60.1 |   65.4 |   -5.2 |
</pre>

<h2>The rest of the league</h2>
<p>I looked at league-wide shot selection in <em>hot</em>/<em>cold</em> situations. I restricted to the last 10 seasons, since the rise of the 3 pointer has dramatically changed shot selection. Here are changes in shot selection for all players:</p>
<pre>
| BASIC_ZONE            |   hot |   cold |   diff |
|:----------------------|------:|-------:|-------:|
| Above the Break 3     |  22.1 |   22.3 |   -0.2 |
| Corner 3              |   6.2 |    7   |   -0.9 |
| In The Paint (Non-RA) |  15.8 |   15.3 |    0.4 |
| Mid-Range             |  25.3 |   23.5 |    1.8 |
| Restricted Area       |  30.7 |   31.8 |   -1.2 |
</pre>

<p>The mid-range shot is the lowest value shot type, so it's notable that the rate goes up when players are <em>hot</em>. These additional mid ranges come at the expense of Corner 3's and Restricted Area shots, the two most valuable types of shots.</p>
<p>As before, changes in shot selection could be justified if players actually shoot differently based on their last 5 results, but they don't. Here are the changes in shooting percentages (hot minus cold) for all players:</p>
<pre>
| BASIC_ZONE            |   hot |   cold |   diff |
|:----------------------|------:|-------:|-------:|
| Above the Break 3     |  34.7 |   35   |   -0.3 |
| Corner 3              |  38.4 |   38.9 |   -0.4 |
| In The Paint (Non-RA) |  41.7 |   41.2 |    0.5 |
| Mid-Range             |  39.8 |   40.1 |   -0.3 |
| Restricted Area       |  62.7 |   60.7 |    2   |
</pre>

<p>For 3 out of 5 shot types, the <em>hot</em> FG percentages are lower than the <em>cold</em> ones. Combined with the changes in shot selection, I think there's evidence that the league as a whole is scoring less efficiently because of the false belief in the hot hand. </p>
<p>The data says that players are essentially trading Restricted Area (.627 * 2 = 1.25 points per shot) and Corner 3 (.384 * 3 = 1.15 points per shot) attempts for Mid-Ranges (.398 * 2 = .796 points per shot) when they think they've got the <em>hot hand</em>. That's clearly bad! If it happens once a game, that's 38 points a year lost, which might be enough to swing a game or two.</p>
<p>The change in restricted area and in the paint (non-RA) FG% is intriguing, but if the hot hand did exist, wouldn't we see it on 3 point or mid-range shots, rather than restricted area shots? The announcer doesn't say "he's heating up" after a guy has made 3 layups in a row, they say it after 3 longer range shots in a row, right?</p>
<h2>Higher volume players</h2>
<p>I decided to focus on players with at least 1000 streaks, which leaves 630 players. Collectively, they are responsible for 84% of all shots in the NBA over the last 20 years.</p>
<p>Their FG percentages are, on average, 1% lower when they are <em>hot</em> than when they are <em>cold</em>. </p>
<p>68% of them shoot worse when they're hot than when they're cold, which is a pretty dramatic split.</p>
<p><img alt="fg-pct-hot-cold" src="/img/fg-pct-hot-cold.png"></p>
<p>Here's a plot of the difference between hot and cold FG% versus z-score:</p>
<p><img alt="z-score-hot-cold" src="/img/z-score-hot-cold.png"></p>
<p>Players with negative values on the x axis shoot better when they're cold, and positive values shoot better when they're hot.</p>
<p>Now, there should be some correlation between z-scores and hot/cold shooting tendency. I've shown simulations where a tendency to shoot <em>better cold</em> produces unstreaky results (skewed towards positive z scores), and <em>better hot</em> will produce streaky results (negative z scores). So there should be more dots in the upper left and bottom right quadrants compared to the other diagonal.</p>
<p>But if players behaved by coin flips, we should see roughly the same number of players with positive and negative z scores, and roughly the same number of players who shoot better when they're hot and better when they're cold.</p>
<p>I simulated all 3.5 million shots by these players, using their career average FG% for every shot. So any streakiness or unstreakiness is going to be totally random. As you can see, the data is much less spread out across both the X and Y axis.</p>
<p><img alt="sim-z-hot-cold" src="/img/sim-z-hot-cold.png"></p>
<p>Here are the crosstabs from the simulation:</p>
<table>
<thead>
<tr>
<th></th>
<th>better cold</th>
<th>better hot</th>
<th>margin</th>
</tr>
</thead>
<tbody>
<tr>
<td>positive z</td>
<td>178</td>
<td>135</td>
<td>313</td>
</tr>
<tr>
<td>negative z</td>
<td>112</td>
<td>210</td>
<td>322</td>
</tr>
<tr>
<td>margin</td>
<td>290</td>
<td>345</td>
<td></td>
</tr>
</tbody>
</table>
<p>As promised, the marginal values are pretty close to one another. That's what happens when "better hot" vs. "better cold" and "positive z" vs. "negative z" are determined purely by chance.</p>
<p>Here are the actual crosstabs. The marginal values are much more imbalanced.</p>
<table>
<thead>
<tr>
<th></th>
<th>better cold</th>
<th>better hot</th>
<th>margin</th>
</tr>
</thead>
<tbody>
<tr>
<td>positive z</td>
<td>343</td>
<td>126</td>
<td>469</td>
</tr>
<tr>
<td>negative z</td>
<td>88</td>
<td>78</td>
<td>166</td>
</tr>
<tr>
<td>margin</td>
<td>431</td>
<td>204</td>
<td></td>
</tr>
</tbody>
</table>
<p>Things to note:</p>
<ul>
<li>68% of the players shoot better when they're cold.</li>
<li>74% of the players have a positive z-score.</li>
<li>Even among players with a negative z score, the majority of them shoot better when they're cold. </li>
<li>Even among players that shoot better when they're hot, the majority of them <em>still</em> produce results that are less streaky than expected by chance.</li>
</ul>
<p>That's all super weird!</p>
<p>As always, these are just general trends. There are 78 players in the "better hot" + "negative z" box, and there should be around 210 players. We can't really say which players are the 130 "missing" players, though.</p>
<p>That's all I've got on the hot hand in the NBA for now. I think I understand it a lot better now, and I hope you do, too. </p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/the-final-word-on-the-hot-hand-for-now.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/sports-analytics.html" rel="tag">sports analytics</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/basketball.html" class="tags">basketball</a>
                    &nbsp;<a href="/tag/the-hot-hand.html" class="tags">the hot hand</a>
                </div>
            </article>            <h4 class="date">Jun 18, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/lesimulation.html" rel="bookmark" title="Permanent Link to &quot;LeSimulation&quot;">LeSimulation</a>
                </h2>

                
                

                <p>(As usual, all code and notebooks are available at <a href="https://github.com/csdurfee/hot_hand">https://github.com/csdurfee/hot_hand</a>)</p>
<p>Last time, we saw that LeBron James was by far the un-streakiest player in the NBA over the last 20 years and found out that it's at least partly caused by shot selection. He takes both lower percentage shots than average when he's shooting well and higher percentage shots than average when he's shooting poorly.</p>
<h2>LeMartingale</h2>
<p>I got the question of why it's OK to use a player's overall FG% to gauge their streakiness. We know that every shot a player takes has a slightly different level of difficulty, and thus a different probability that it will go in. Shouldn't that affect the streakiness?</p>
<p>It's a good question.  Let's say you've got a bag with 2 types of coins inside. One of them comes up heads 40% of the time, the other comes up heads 60% of the time. You can't tell which is which. If you pick a coin randomly out of the bag and flip it, what are the chances, on average, it comes up heads? </p>
<p>It's 50%, right? The selecting of the coin and the flipping of the coin are two independent steps. We can multiply the probabilities at each step together, so the overall chances of heads are <code>(.5 * .4) + (.5 * .6) = .5</code>. If we kept randomly selecting from the bag and flipping a coin, the results would be indistinguishable from just flipping a single fair coin over and over.</p>
<p>In math, this is known as a <a href="https://en.wikipedia.org/wiki/Martingale_(probability_theory)">Martingale</a>. Previous outcomes don't give us information about the next event. (More in depth explanation <a href="https://www.cs.yale.edu/homes/aspnes/pinewiki/Martingales.html">here</a>).  That's different from LeBron. We know he essentially chooses the 60% heads coin when he's been getting a lot of tails recently, and the 60% tails coin when he's been getting a lot of heads recently.</p>
<h2>LeSimulation</h2>
<p>If I create a simulation of LeBron James that uses his exact shooting tendencies and FG percentages, and the shot selection is totally random, it shouldn't show any streaky or unstreaky tendencies beyond expected by chance. Let's see what LeSimulation looks like.</p>
<p>At the end of the last edition, I got LeBron's shooting stats:</p>
<div class="highlight"><pre><span></span><code><span class="nv">Above</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="k">Break</span><span class="w"> </span><span class="mi">3</span><span class="w">        </span><span class="mi">0</span>.<span class="mi">344598</span>
<span class="nv">Backcourt</span><span class="w">                </span><span class="mi">0</span>.<span class="mi">058824</span>
<span class="nv">In</span><span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">Paint</span><span class="w"> </span><span class="ss">(</span><span class="nv">Non</span><span class="o">-</span><span class="nv">RA</span><span class="ss">)</span><span class="w">    </span><span class="mi">0</span>.<span class="mi">401369</span>
<span class="nv">Left</span><span class="w"> </span><span class="nv">Corner</span><span class="w"> </span><span class="mi">3</span><span class="w">            </span><span class="mi">0</span>.<span class="mi">394799</span>
<span class="nv">Mid</span><span class="o">-</span><span class="nv">Range</span><span class="w">                </span><span class="mi">0</span>.<span class="mi">379890</span>
<span class="nv">Restricted</span><span class="w"> </span><span class="nv">Area</span><span class="w">          </span><span class="mi">0</span>.<span class="mi">720138</span>
<span class="nv">Right</span><span class="w"> </span><span class="nv">Corner</span><span class="w"> </span><span class="mi">3</span><span class="w">           </span><span class="mi">0</span>.<span class="mi">370370</span>
</code></pre></div>

<p>And shooting tendencies (what percent of the time he takes each type of shot):</p>
<div class="highlight"><pre><span></span><code><span class="nv">Above</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="k">Break</span><span class="w"> </span><span class="mi">3</span><span class="w">        </span><span class="mi">0</span>.<span class="mi">204940</span>
<span class="nv">Backcourt</span><span class="w">                </span><span class="mi">0</span>.<span class="mi">001160</span>
<span class="nv">In</span><span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">Paint</span><span class="w"> </span><span class="ss">(</span><span class="nv">Non</span><span class="o">-</span><span class="nv">RA</span><span class="ss">)</span><span class="w">    </span><span class="mi">0</span>.<span class="mi">109652</span>
<span class="nv">Left</span><span class="w"> </span><span class="nv">Corner</span><span class="w"> </span><span class="mi">3</span><span class="w">            </span><span class="mi">0</span>.<span class="mi">014431</span>
<span class="nv">Mid</span><span class="o">-</span><span class="nv">Range</span><span class="w">                </span><span class="mi">0</span>.<span class="mi">267715</span>
<span class="nv">Restricted</span><span class="w"> </span><span class="nv">Area</span><span class="w">          </span><span class="mi">0</span>.<span class="mi">386442</span>
<span class="nv">Right</span><span class="w"> </span><span class="nv">Corner</span><span class="w"> </span><span class="mi">3</span><span class="w">           </span><span class="mi">0</span>.<span class="mi">015660</span>
</code></pre></div>

<p>The simulation randomly chooses a shot type, based on the actual tendencies, then attempts a shot at the corresponding FG%.</p>
<p><img alt="le-fake-career" src="/img/le-fake-career.png"></p>
<p>The z-scores look like they should -- mean is very close to 0, standard deviation close to 1. No streaky/unstreaky tendencies, as promised. No evidence that shot attempts were at different FG%.</p>
<h2>LeSimulation 2 - last 5 FG%</h2>
<p>My next simulation uses LeBron's FG% over his last 5 shots. We've seen he shoots the best with 0 makes in his last 5; the worst with 5 makes in his last 5. The simulation uses his exact percentages at each level. For the first 5 shots of every game, it uses his career FG%.</p>
<p>I ran the simulation 1,000 times. Here are the z-scores:</p>
<p><img alt="le-fake-career-2" src="/img/le-fake-career-2.png"></p>
<p>As expected, this simulation is pretty un-streaky:</p>
<div class="highlight"><pre><span></span><code>count    1000.000000
mean        1.635843
std         0.985464
min        -1.665389
25%         1.001550
50%         1.623242
75%         2.346864
max         4.509869
</code></pre></div>

<p>It's still not nearly as unstreaky as the man himself, though -- Lebron's z score of 5.9 would be way bigger than the largest value in 1,000 simulations (4.5). So he'd still be an outlier compared to these simulated un-streaky players.</p>
<h2>LeSimulation 3 -- No resetting streaks</h2>
<p>What about a fake player where the streaks don't reset between games? That should make the simulated player even more unstreaky.</p>
<p>In this version of the simulation, every shot will be influenced by the FG% of the previous 5 shots, even if they happened in the previous game(s).</p>
<p><img alt="le-fake-career-3" src="/img/le-fake-career-3.png"></p>
<p>Here are the corresponding z-scores:</p>
<div class="highlight"><pre><span></span><code>count    1000.000000
mean        2.179821
std         0.963330
min        -1.033468
25%         1.536542
50%         2.203681
75%         2.865350
max         5.073167
</code></pre></div>

<p>So, the mean went from 1.6 to 2.2, and the max z score went from 4.5 to 5.1. That's still not nearly unstreaky enough to match LeReal LeBron, but at least it's closer.</p>
<p>It's possible that if we tracked the last 7 shots, or 9, instead of 5, we would see even more of a dramatic change in FG percentage. Or there's some other factor I haven't considered that is adding unstreakiness, such as the fact that his FG percentage tends to go down the more shots he's taken in a game.</p>
<h2>DoppLeGangers</h2>
<p>I was curious if I could find similar players to LeBron. There's a good way to do that, but I wanted to try my own way first. I found players where, like LeBron, their FG% steadily declines the more shots they've made out of the last 5.  There are 18 such players in the 2004-2024 years: Karl Malone (his last season), Grant Hill, Ben Wallace, Eddie House, Michael Redd, Jarvis Hayes, Andres Nocioni, JJ Redick, Nicolas Batum, Goran Dragic, DeMar DeRozan, Patrick Beverley, Marcus Morris Sr., Bradley Beal, Kelly Oubre Jr., Norman Powell, Donte DiVincenzo, and Landry Shamet.</p>
<p>Overall, these players have a mean z-score of 1.47, which is pretty impressive, but except for Goran Dragic, there isn't much overlap over the players with the highest overall z scores. 18 players is a pretty small sample size, as well.</p>
<p>I also looked at a broader set of players where at least 4 out of the 5 comparisons were decreasing. This gave 180 players, with an average z score of 1.0. </p>
<h3>LeRight way</h3>
<p>The right way to identify LeBron-alikes is probably to use a similarity metric that I didn't invent. The fg percentages after 0,1,2...5/5 makes are sort of like a probability distribution. </p>
<p>In statistics and machine learning, we are often fitting a theoretical distribution to the actual observed data. Is it a good representation of the observed data? Do their distributions have the same sort of shape? The standard measure is relative entropy, also known as <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL divergence</a>.</p>
<p>If I normalize the shooting percentages and compare them to LeBron's, players with a low relative entropy should show the same tendency to shoot better when they're shooting worse than average over their last 5, and vice versa.</p>
<p>For example, LeBron's last 5 percentages are:</p>
<div class="highlight"><pre><span></span><code><span class="mf">0</span><span class="w">    </span><span class="mf">0.564612</span>
<span class="mf">1</span><span class="w">     </span><span class="mf">0.50712</span>
<span class="mf">2</span><span class="w">    </span><span class="mf">0.505937</span>
<span class="mf">3</span><span class="w">    </span><span class="mf">0.496538</span>
<span class="mf">4</span><span class="w">    </span><span class="mf">0.473849</span>
<span class="mf">5</span><span class="w">    </span><span class="mf">0.464052</span>
</code></pre></div>

<p>By normalizing them, they act like a probability distribution (they all add up to one) but still have the same relative proportions.</p>
<div class="highlight"><pre><span></span><code><span class="mf">0</span><span class="w">    </span><span class="mf">0.187448</span>
<span class="mf">1</span><span class="w">     </span><span class="mf">0.16836</span>
<span class="mf">2</span><span class="w">    </span><span class="mf">0.167968</span>
<span class="mf">3</span><span class="w">    </span><span class="mf">0.164847</span>
<span class="mf">4</span><span class="w">    </span><span class="mf">0.157315</span>
<span class="mf">5</span><span class="w">    </span><span class="mf">0.154062</span>
</code></pre></div>

<p>The normalization also corrects for the fact that shooters have different overall FG percentages.</p>
<p>Normalized values can then be compared to other players' values. The lower the entropy, the more similar their shapes are.</p>
<p>I also calculated the Jensen-Shannon distance, which is like relative entropy, but symmetrical (<code>distance(le_bron, le_other_guy) = distance(le_other_guy, le_bron)</code>).</p>
<p>The closest guys to LeBron by this measure are CJ McCollum, Terry Rozier, Andrea Bargnani, Marcus Morris, Richard Hamilton, Nikola Vucevic, Zach Randolph, Lauri Markkanen, Kawhi Leonard, and Kevin Huerter. </p>
<p>Since Richard Hamilton had the streakiest game in the last 20 years, it's not surpring to see him. But except for Randolph and Vucevic, none of the top 10 had exceptional z scores, though they were all positive.</p>
<p>The Jensen-Shannon distance results were extremely similar to entropy. It agreed exactly with the entropy on 73 of the top 100 players. The average z score for those players was 1.16, versus 1.15 for entropy. So, in aggregate, both were better than my homegrown metric at identifying unstreaky players.</p>
<p>This graph shows the shape of the 10 players most similar to LeBron. They all have the same downward trend</p>
<p><img alt="most-similar-last5" src="/img/most-similar-last5.png"></p>
<p>I haven't looked at whether the reason for the trend in last 5 FG% is due to shot selection for these other players, which is probably the interesting part. Some of the players flagged here are inevitably due to chance. It's based on six 50/50 measurements, so 1 in 64 players would get flagged as "LeBron like" even if the data was randomly generated.</p>
<p>None of my queries here turned up the un-streakiest players like Luka Doncic and Anthony Edwards. Whatever causes their extreme unstreakiness (beyond randomness) must be different from LeBron's tendencies. Stay tuned!</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/lesimulation.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/sports-analytics.html" rel="tag">sports analytics</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/basketball.html" class="tags">basketball</a>
                    &nbsp;<a href="/tag/the-hot-hand.html" class="tags">the hot hand</a>
                </div>
            </article>            <h4 class="date">Jun 12, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/lebron-james-the-unstreaky-king.html" rel="bookmark" title="Permanent Link to &quot;LeBron James, the Unstreaky King&quot;">LeBron James, the Unstreaky King</a>
                </h2>

                
                

                <p>In previous installments, I've shown that NBA players are, as a whole, less streaky than they should be. This is apparent in game-level data, and more obvious looking at multi season trends.</p>
<p>So far, I've only looked at the past few seasons of the NBA. I decided to gather as much data as I could, analyzing every single shot taken in the NBA from 2004 to 2024.</p>
<p>Data is taken from https://www.kaggle.com/datasets/mexwell/nba-shots.</p>
<h2>The streakiest games of the past 20 years</h2>
<p>As I showed in the last installment, there are two ways of measuring how relatively streaky each individual game is. We can use the normal approximation from the Wald-Wolfowitz test, or we can calculate the percentile ranks from the exact probabilities.</p>
<p>These two metrics give different answers to what is the streakiest game of the past 20 years.  According to percentile rank, the streakiest ever was Cedi Osman, who in 2022 missed 10 shots in a row, followed by making 6 shots in a row, for an equivalent z-score of -3.6.</p>
<p>According to the normal approximation, the streakiest game ever was Chris Bosh in 2007, who made 15 shots in a row before missing his final 4. Bosh doesn't even make the top 5 by percentile rank. </p>
<p>Other strong performances include Andre Iguodala, who had 16 straight misses followed by 3 makes in 2008, and Willie Green, who had 5 misses followed by 12 makes. The sheer length of those streaks is impressive, but to maximize the number of expected streaks, there need to be similar numbers of makes and misses. A game with 5 makes and 5 misses has a maximum of 10 streaks. A game with 15 makes and 4 misses, like Chris Bosh, has a maximum of 9 streaks.</p>
<p>Kobe Bryant's final game in the NBA also deserves mention. He went an extremely streaky 22 for 50, earning the highest number of expected streaks in the data I have (25.64): <code>11111000100110000101110000101100001100001111100000</code></p>
<h2>The least streaky games</h2>
<p>The least streaky was by Richard Hamilton in 2006, who had 10 makes and 13 misses, no two makes in a row: <code>01001010101010010101010</code></p>
<p>Kyrie Irving, Dejounte Murray (previously covered), and Kevin Martin also had strong showings. </p>
<h1>The un-streaky king</h1>
<p>The 4th most un-streaky game of the past 20 years belongs to LeBron James.  <a href="https://www.basketball-reference.com/boxscores/200511090CLE.html">LeBron scored 31 points in an easy win over the SuperSonics in 2005</a>. Aside from 2 makes in a row at the start of the game, he perfectly alternated makes and misses the rest of the game: <code>110101010101010101</code></p>
<p>In the 20 years of shot data I analyzed, LeBron stands out as by far the most un-streaky player. Here are the career z scores of every player from 2004-2024:</p>
<p><img alt="career-z-scores" src="/img/career-z-scores.png"></p>
<p>LeBron can't even be seen on this chart. He is in a world of his own, with a career z score of 5.9. We have to go to the Jon Bois style scatterplot with one extreme outlier in the corner:</p>
<p><img alt="career-z-scatter" src="/img/career-z-scatter.png"></p>
<p>If this were a Youtube video, imagine me zooming in on the solitary dot in the upper right while the saxophone hook from <a href="https://youtu.be/BO1qcWa6blQ?t=22">Baker Street</a> kicks in.</p>
<p>Which is to say, it's really, really unlikely. The odds are around 1 in 550 million. That puts him in the 99.9999998th percentile.</p>
<p>If all 8.2 Billion people on the planet had LeBron's NBA career, taking over 29,000 shots like he has, at the same FG% he did, we'd expect 15 people to be that unstreaky or more. That's elite company. Not only is LeBron James the LeBron James of basketball, he's also the LeBron James of being unstreaky at basketball.</p>
<p>As both the most unstreaky player of all time, and the most prolific scorer of all time, LeBron James makes a perfect test subject for understanding unstreakiness.</p>
<p>He's had 15,159 shooting streaks in his career so far, which is 504 more streaks than expected.  Say LeBron takes a low percentage shot because he feels like he has the hot hand. It might be lower, but it's probably not dramatically worse than his regular shot. So for him to have 500 more streaks than expected, that's potentially thousands of choices LeBron has made over his career that increased the likelihood of streaks getting broken.</p>
<h2>Streak lengths</h2>
<p>I simulated LeBron's career 1000 times and compared the frequency of streak lengths to his actual career. Here are his actual streaks compared to the expected frequencies:</p>
<p><img alt="lebron-make-streaks" src="/img/lebron-make-streaks.png"></p>
<p><img alt="lebron-miss-streaks" src="/img/lebron-miss-streaks.png"></p>
<p>He has slightly more 1 and 2 shot make/miss streaks than expected, and fewer streaks of 5-6 or more.</p>
<p>Previously I discussed that players could cause unstreakiness because they "go get a bucket" when the "shot isn't falling" -- in other words, they take higher percentage shots when they're on a cold streak. They might try to draw contact from a defender, and if they do get fouled, it only counts as a shot attempt if the shot goes in. On the other hand, they might take risky "heat check" shots when they are performing relatively well because they feel like they can't miss.</p>
<p>To capture "hot" versus "cold", I decided to track the FG% over the previous 5 shots in the game. So, it's undefined for the player's first 5 shots of the game, then defined from the 6th on. Because LeBron is such a high volume scorer and has been for so many years, that's still a lot of data to look at. </p>
<p>here are the number of shot attempts by LeBron by each "last 5" shooting percentage.</p>
<div class="highlight"><pre><span></span><code>NaN    7460
0.6    7222
0.4    6906
0.8    3518
0.2    3090
1.0     612
0.0     503
</code></pre></div>

<p>I have defined <em>cold</em> as making 0 or 1 of the last 5 shots, and <em>hot</em> as making 4 or 5 of the last 5. This was a semi-arbitrary choice based on make/miss streaks longer than 5 happening less frequently than chance would dictate. It also matches how my simulated un-streaky player works.</p>
<p>There's a clear trend. LeBron's FG% is 10% higher when he's missed his last 5 shots than when he's made his last 5.</p>
<p><img alt="lebron-last-5" src="/img/lebron-last-5.png"></p>
<p>That's a pretty big swing.</p>
<h2>LeBron is un-streaky due to shot selection</h2>
<p>What's behind this trend?</p>
<p>LeBron takes a lot more high percentage shots when he's <em>cold</em> versus when he's <em>hot</em>.</p>
<div class="highlight"><pre><span></span><code><span class="nv">Change</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">shot</span><span class="w"> </span><span class="nv">rates</span><span class="w"> </span><span class="ss">(</span><span class="nv">cold</span><span class="w"> </span><span class="nv">minus</span><span class="w"> </span><span class="nv">hot</span><span class="ss">)</span>:

<span class="nv">Above</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="k">Break</span><span class="w"> </span><span class="mi">3</span><span class="w">       </span><span class="o">-</span><span class="mi">0</span>.<span class="mi">119694</span>
<span class="nv">Backcourt</span><span class="w">               </span><span class="o">-</span><span class="mi">0</span>.<span class="mi">001659</span>
<span class="nv">In</span><span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">Paint</span><span class="w"> </span><span class="ss">(</span><span class="nv">Non</span><span class="o">-</span><span class="nv">RA</span><span class="ss">)</span><span class="w">    </span><span class="mi">0</span>.<span class="mi">023637</span>
<span class="nv">Left</span><span class="w"> </span><span class="nv">Corner</span><span class="w"> </span><span class="mi">3</span><span class="w">            </span><span class="mi">0</span>.<span class="mi">000429</span>
<span class="nv">Mid</span><span class="o">-</span><span class="nv">Range</span><span class="w">               </span><span class="o">-</span><span class="mi">0</span>.<span class="mi">056841</span>
<span class="nv">Restricted</span><span class="w"> </span><span class="nv">Area</span><span class="w">          </span><span class="mi">0</span>.<span class="mi">159098</span>
</code></pre></div>

<p>When he's <em>hot</em>, he takes 29% of his shots in the restricted area (right near the basket, which is his highest percentage shot). When LeBron's <em>cold</em>, that jumps up to 45% of his shots. When he's hot, 29% of his shots are above the break 3's, but he only takes that shot 17% of the time when he's <em>cold</em>.</p>
<p>LeBron's FG% at each type of shot doesn't change much between times when he's <em>hot</em> and <em>cold</em> and <em>in between</em>. He's a tiny biy better at corner 3's when he's cold vs. hot, but that's on very small volume. LeBron is usually attacking the middle of the court, not standing in the corner. </p>
<p>He's actually slightly worse at his three most common shot types (above the break 3, mid-range, restricted area) when he's on a cold streak. He's not un-streaky because he suddenly becomes a better shooter. He chooses to "go get a bucket" and seek out a higher percentage shot.</p>
<div class="highlight"><pre><span></span><code><span class="nv">Change</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">FG</span><span class="o">%</span><span class="w"> </span><span class="ss">(</span><span class="nv">cold</span><span class="w"> </span><span class="nv">minus</span><span class="w"> </span><span class="nv">hot</span><span class="ss">)</span>:

<span class="nv">Above</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="k">Break</span><span class="w"> </span><span class="mi">3</span><span class="w">       </span><span class="o">-</span><span class="mi">0</span>.<span class="mi">036856</span>
<span class="nv">In</span><span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">Paint</span><span class="w"> </span><span class="ss">(</span><span class="nv">Non</span><span class="o">-</span><span class="nv">RA</span><span class="ss">)</span><span class="w">    </span><span class="mi">0</span>.<span class="mi">001647</span>
<span class="nv">Left</span><span class="w"> </span><span class="nv">Corner</span><span class="w"> </span><span class="mi">3</span><span class="w">            </span><span class="mi">0</span>.<span class="mi">026525</span>
<span class="nv">Mid</span><span class="o">-</span><span class="nv">Range</span><span class="w">               </span><span class="o">-</span><span class="mi">0</span>.<span class="mi">023709</span>
<span class="nv">Restricted</span><span class="w"> </span><span class="nv">Area</span><span class="w">         </span><span class="o">-</span><span class="mi">0</span>.<span class="mi">013754</span>
<span class="nv">Right</span><span class="w"> </span><span class="nv">Corner</span><span class="w"> </span><span class="mi">3</span><span class="w">           </span><span class="mi">0</span>.<span class="mi">157949</span>
</code></pre></div>

<p>It looks like it cuts both ways. LeBron takes lower percentage shots when he's shooting well, and higher percentage shots when he's shooting poorly over the past 5 shots, compared to the average performance.</p>
<h2>Shot order trends</h2>
<p>LeBron's FG% appears to trend downward with the more shots that he takes in a game. The white line is his career average:</p>
<p><img alt="seq-vs-fg" src="/img/seq-vs-fg.png"></p>
<p>I haven't looked into it yet, but I suspect this is partially due to LeBron often taking the last shot of the game. Final shots of the game should be harder than average if it's a close game. Everybody knows the ball's going to LeBron for the final shot, so the defense is keying in on him. I'll save that for another installment, though.</p>
<h2>Other unstreaky guys</h2>
<p>Kyle Kuzma, Julius Randle, Elton Brand, and Anthony Edwards are all in the 4+ z score club, with Luka Doncic, Giannis, John Henson, Goran Dragic, and Jordan Poole also in the top 10.</p>
<h2>League-wide trends</h2>
<p>I went back and did the same analysis for every non-LeBron shot over the last 20 years. The league as a whole doesn't show the same trends that LeBron does. FG% isn't correlated with number of makes of the last 5. Here are the shooting percentages, graphed on the same scale as the one I used for LeBron:</p>
<p><img alt="league-last-5" src="/img/league-last-5.png"></p>
<p>There's a very slight uptick when a player has made all 5 of their last 5 shots in the game, but otherwise it's remarkably flat.</p>
<p>Looking at the order of of shots taken, the NBA as a whole shows the same rough trend as LeBron's, though less dramatically. Lower FG% on the first shot of the game, and FG% slowly going down as the number of attempts goes up. (Again, I've locked the Y axis to match the scale of LeBron's.)</p>
<p><img alt="league-shot-seq" src="/img/league-shot-seq.png"></p>
<p>Not a lot there in aggregate. I also looked at just higher volume shooters, but there wasn't a trend I could see there.</p>
<p>Finally, I looked at players with a z-score over 2 (aside from LeBron). Now, by artificially selecting players with a high z-score, I need to be careful with my analysis to avoid self-fulfilling prophecy. </p>
<p>By definition, they're going to seem more unstreaky. But it's notable they're unstreaky in the same way as LeBron -- higher shooting percentage when they're <em>cold</em> and lower when they're <em>hot</em>. It's not a strong trend, but it's there. They shoot 47% when they've missed their last 5 in a row, and 44.8% when they've made their last 5 in a row. If the high Z scores were solely due to chance, I wouldn't expect to see such a clear pattern in the last 5 data.</p>
<p><img alt="high-z-last5" src="/img/high-z-last5.png"></p>
<h2>Streaky guys</h2>
<p>There's only one super streaky guy in the last 20 years, Ivica Zubac, with a Z score of -3.98. That's pretty crazy, but still plausibly within the realm of chance, around 1 in 30,000.</p>
<p>The other guys with extremely streaky behavior on high volume are Dwight Powell, Nemanja Bjelica, Erick Dampier, Aaron Nesmith and Rudy Gobert, with z scores around -3. Most of those guys are big men who aren't primarily scorers. I wonder if it has something to do with rebounding their own shot. Sometimes a big man who isn't good at shooting will do what I call the Moses Malone -- miss a shot, get their own rebound, miss that, get their own rebound again, shoot again, etc, which might produce longer streaks of misses than makes.</p>
<p>However, I don't think there's a need to deeply analyze the streaky players at this point, because it could be due to chance alone. </p>
<h2>Goofy Nonsense</h2>
<p>Zydrunas Ilgauskas was a longtime player for the Cleveland Cavaliers who was nicknamed "The Big Z". However, his career z score was only 1.49, so I don't think it's a statistics based nickname. Which is too bad, because the game could use some of those. "Small Z" for Ivica Zubac's -3.98 score might be confusin to people, unfortunately.</p>
<h2>Final thoughts</h2>
<p>If I were LeBron's coach, I'd try to talk him out of believing he has the hot hand, because as we've seen, acting like it exists has caused him to be the most <em>lukewarm handed</em> player of the past 20 years.</p>
<p>Shot selection shouldn't change for the worse just because a player is shooting well. LeBron on a hot streak has roughly the same shooting percentages for each type of shot as when he's not on a hot streak, or when he's on a cold streak. </p>
<p>His innate shooting skill doesn't change, he just takes lower percentage shots, perhaps believing they're not really lower percentage shots when he's <em>feeling it</em>. It's feel vs. real, as it often is in sports, and life in general. Regardless of feel, they're still worse shots than he would normally take.</p>
<p>Going the other way, it's like the old joke about an airplane's black box -- if black boxes are indestructible, why don't they just build the whole airplane out of that material? If LeBron has a higher shooting percentage when he's <em>cold</em> and decides to "go get a bucket", and that works, why doesn't he just do that on every play?</p>
<p>I don't have a statistical answer to that question, but I do have a common sense one. In sports, part of the game is making the other team have to handle as many possibilities at a time. A quarterback in football shouldn't throw deep passes every play, because that's easy to defend. A baseball pitcher shouldn't just throw their best pitch every time, because that's easy for the hitter to anticipate. </p>
<p>Likewise, LeBron probably shouldn't just put his head down and "get a bucket" every possession, because that's easy to plan against. LeBron wouldn't be an all time great if he only shot in the restricted area. While 3 pointers and midrange shots may have a lower expected value versus driving to the hoop, they force the defender to worry about LeBron no matter where he is on the court. But I think both as a hoops fan and a data nerd, trying to create a high percentage shot isn't a bad thing to do when a player is struggling in a game. That's especially true if a player can become less engaged in other aspects of the game when they are shooting poorly.</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/lebron-james-the-unstreaky-king.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/sports-analytics.html" rel="tag">sports analytics</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/basketball.html" class="tags">basketball</a>
                    &nbsp;<a href="/tag/the-hot-hand.html" class="tags">the hot hand</a>
                </div>
            </article>            <h4 class="date">Jun 08, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/approximate-normality-and-continuity-corrections.html" rel="bookmark" title="Permanent Link to &quot;Approximate Normality and Continuity Corrections&quot;">Approximate Normality and Continuity Corrections</a>
                </h2>

                
                

                <p>(Notebooks and other code available at: <a href="https://github.com/csdurfee/hot_hand">https://github.com/csdurfee/hot_hand</a>. As usual, there is stuff in there I'm not covering here.)</p>
<h1>What is "approximately normal"?</h1>
<p>In the last installment, I looked at NBA game-level player data, which involve very small samples.</p>
<p>Like a lot of things in statistics, the Wald Wolfowitz test says that the number of streaks is approximately normal. What does that mean in practical terms? How approximately are we talking?</p>
<p>The number of streaks is a discrete value (0,1,2,3,...). In a small sample like 2 makes and 3 misses, which will be extremely common in player game level shooting data, how could that be <em>approximately normal</em>?</p>
<p>Below is a bar chart of the exact probabilities of each number of streaks, overlaid with the normal approximation in white. Not very normal, is it?</p>
<p><img alt="not very normal" src="/img/not-very-normal.png"></p>
<p>To make things more interesting, let's say the player made 7 shots and missed 4. That's enough for the graph to look more like a proper bell curve.</p>
<p><img alt="exact 7-4 (or 4-7)" src="/img/exact-7-4.png"></p>
<p>The bell curve looks skewed relative to the histogram, right? That's what happens when you model a discrete distribution (the number of streaks) with a continuous one -- the normal distribution.</p>
<p>A continuous distribution has zero probability at any single point, so we calculate the area under the curve between a range of values. The bar for exactly 7 streaks should line up with the probability of between 6.5 and 7.5 streaks in the normal approximation. The curve should be going through the middle of each bar, not the left edge.</p>
<p>We need to shift the curve to the right a half a streak for things to line up. Fixing this is called <a href="https://en.wikipedia.org/wiki/Continuity_correction">continuity correction</a>.</p>
<p>Here's the same graph with the continuity correction applied:</p>
<p><img alt="with cc" src="/img/with-cc.png"></p>
<p>So... better, but there's still a problem. The normal approximation will assign a nonzero probability to impossible things. In this case of 7 makes and 4 misses, the minimum possible number of streaks is 2 and the max is 9 (alternate wins and losses till you run out of losses, then have a string of wins at the end.)</p>
<p>Yet the normal approximation says there's a nonzero chance of -1, 10, or even a million streaks. The odds are tiny, but the normal distribution never ends. These differences go away with big sample sizes, but they may be worth worrying about for small sample sizes.</p>
<p>Is that interfering with my results? It's quite possible. I'm trying to use the mean and the standard deviation to decide how "weird" each player is in the form of a z score. The z score gives the likelihood of the data happening by chance, given certain assumptions. If the assumptions don't hold, the z score, and using it to interpret how <em>weird</em> things are, is suspect.</p>
<h2>Exact-ish odds</h2>
<p>We can easily calculate the exact odds. In the notebook, I showed how to calculate the odds with brute force -- generate all permutations of seven 1's and four 0's, and measure the number of streaks for each one. That's impractical and silly, since the exact counting formula can be worked out using the rules of combinatorics, as this page nicely shows:  <a href="https://online.stat.psu.edu/stat415/lesson/21/21.1">https://online.stat.psu.edu/stat415/lesson/21/21.1</a></p>
<p>In order to compare players with different numbers of makes and misses, we'd want to calculate a percentile value for each one from the exact odds. The percentiles will be based on number of streaks, so 1st percentile would be super streaky, 99th percentile super un-streaky.</p>
<p>Let's say we're looking at the case of 7 makes and 4 misses, and are trying to calculate the percentile value that should go with each number of streaks.  Here are the exact odds of each number of streaks:</p>
<div class="highlight"><pre><span></span><code><span class="mf">2</span><span class="w">    </span><span class="mf">0.006061</span>
<span class="mf">3</span><span class="w">    </span><span class="mf">0.027273</span>
<span class="mf">4</span><span class="w">    </span><span class="mf">0.109091</span>
<span class="mf">5</span><span class="w">    </span><span class="mf">0.190909</span>
<span class="mf">6</span><span class="w">    </span><span class="mf">0.272727</span>
<span class="mf">7</span><span class="w">    </span><span class="mf">0.227273</span>
<span class="mf">8</span><span class="w">    </span><span class="mf">0.121212</span>
<span class="mf">9</span><span class="w">    </span><span class="mf">0.045455</span>
</code></pre></div>

<p>Here are the cumulative odds (the odds of getting that number of streaks or fewer):</p>
<div class="highlight"><pre><span></span><code><span class="mf">2</span><span class="w">    </span><span class="mf">0.006061</span>
<span class="mf">3</span><span class="w">    </span><span class="mf">0.033333</span>
<span class="mf">4</span><span class="w">    </span><span class="mf">0.142424</span>
<span class="mf">5</span><span class="w">    </span><span class="mf">0.333333</span>
<span class="mf">6</span><span class="w">    </span><span class="mf">0.606061</span>
<span class="mf">7</span><span class="w">    </span><span class="mf">0.833333</span>
<span class="mf">8</span><span class="w">    </span><span class="mf">0.954545</span>
<span class="mf">9</span><span class="w">    </span><span class="mf">1.000000</span>
</code></pre></div>

<p>Let's say we get 6 streaks. Exactly 6 streaks happens 27% of the time. 5 or fewer streaks happens 33% of the time. So we could say 6 streaks is equal to the 33rd percentile, the <code>33.3%+27.3% = 61</code>st percentile, or some value in between those two numbers.</p>
<p>The obvious way of deciding the <a href="https://en.wikipedia.org/wiki/Percentile_rank">percentile rank</a> is to take the average of the upper and lower values, in this case <code>mean(.333, .606) = .47</code>. You could also think of it as taking the probability of <code>streaks &lt;=5</code> and adding half the probability of <code>streaks=6</code>.</p>
<p>If we want to compare the percentile ranks from the exact odds to Wald-Wolfowitz, we could convert them to an equivalent z score. Or, we can take the z-scores from the Wald Wolfowitz test and convert them to percentiles.</p>
<p>The two are bound to be a little different because the normal approximation is a bell curve, whereas we're getting the percentile rank from a linear interpolation of two values.</p>
<p>Here's an illustration of what I mean. This is a graph of the percentile ranks vs the CDF of the normal approximation.</p>
<p><img alt="cdf-normal-exact2" src="/img/cdf-normal-exact2.png"></p>
<p>Let's zoom in on the section between 4.5 and 5.5 streaks. Where the white line hits the red line is the percentile estimate we'd get from the z-score (.475).</p>
<p><img alt="cdf-zoom" src="/img/cdf-zoom.png"></p>
<p>The green line is a straight line that represents calculating the percentile rank. It goes from the middle of the top of the <code>runs &lt;= 5</code> bar to the middle of the top of the <code>runs &lt;=6</code> bar. Where it hits the red line is the average of the two, which is percentile rank (.470).</p>
<p>In other situations, the Wald-Wolfowitz estimate will be less than the exact percentile rank. We can see that on the first graph. The green lines and white line are very close to each other, but sometimes the green is higher (like at runs=4), and sometimes the white is higher (like at runs=8).</p>
<h2>Is Wald-Wolfowitz unbiased?</h2>
<p>Yeah. The test provides the exact expected value of the number of streaks. It's not just a pretty good estimate. It is the (weighted) mean of the exact probabilities.</p>
<p>From the exact odds, the mean of all the streak lengths is 6.0909:</p>
<div class="highlight"><pre><span></span><code>count    330.000000
mean       6.090909
std        1.445329
min        2.000000
25%        5.000000
50%        6.000000
75%        7.000000
max        9.000000
</code></pre></div>

<p>The Wald-Wolfowitz test says the expected value is 1 plus the harmonic mean of 7 and 4, which is 6.0909... on the nose.</p>
<h2>Is the normal approximation throwing off my results?</h2>
<p>Quite possibly. So I went back and calculated the percentile ranks for every player-game combo over the course of the season.</p>
<p>Here's a scatter plot of the two ways to calculate the percentile on actual NBA player games. The dots above the x=y line are where the Wald-Wolfowitz percentile is bigger than the percentile rank one.</p>
<p><img alt="percentile-vs-ww" src="/img/percentile-vs-ww.png"></p>
<p>59% of the time, the Wald-Wolfowitz estimate produces a higher percentile value than the percentile rank. The same trend occurs if I restrict the data set to only high volume shooters (more than 10 makes or misses on the game).</p>
<p>Here's a bar chart of the differences between the W-W percentile and the percentile rank:</p>
<p><img alt="ww-minus-pr" src="/img/ww-minus-pr.png"></p>
<p>A percentile over 50, or a positive z score, means more streaks than average, thus less streaky than average. In other words, <em>on this specific data set</em>, the Wald-Wolfowitz z-scores will be more un-streaky compared to the exact probabilities.</p>
<h2>Interlude: our un-streaky king</h2>
<p>For the record, the un-streakiest NBA game of the 2023-24 season was by Dejounte Murray on 4/9/2024. My dude went 12 for 31 and managed 25 streaks, the most possible for that number of makes and misses, by virtue of never making 2 shots in a row.</p>
<p>It was a crazy game all around for Murray. A 29-13-13 triple double with 4 steals, and a Kobe-esque 29 points on 31 shots. He could've gotten more, too. The game went to double overtime, and he missed his last 4 in a row. If he had made the 2nd and the 4th of those, he could've gotten 4 more streaks on the game.</p>
<p>The summary of the game doesn't mention this exceptional achievement. Of course they wouldn't. There's no clue of it in the box score. You couldn't bet on it. Why would anyone notice?</p>
<p><a href="https://www.basketball-reference.com/boxscores/202404090ATL.html">box score on bbref</a>    </p>
<p>Look at that unstreakiness. Isn't it beautiful?</p>
<div class="highlight"><pre><span></span><code><span class="n">makes</span><span class="w">                                                  </span><span class="mi">12</span>
<span class="n">misses</span><span class="w">                                                 </span><span class="mi">19</span>
<span class="n">total_streaks</span><span class="w">                                          </span><span class="mi">25</span>
<span class="n">raw_data</span><span class="w">                  </span><span class="n">LWLWLWLWLWLWLLWLLLWLWLWLWLWLLLL</span>
<span class="n">expected_streaks</span><span class="w">                                </span><span class="mf">15.709677</span>
<span class="n">variance</span><span class="w">                                         </span><span class="mf">6.722164</span>
<span class="n">z_score</span><span class="w">                                          </span><span class="mf">3.583243</span>
<span class="n">exact_percentile_rank</span><span class="w">                           </span><span class="mf">99.993423</span>
<span class="n">z_from_percentile_rank</span><span class="w">                           </span><span class="mf">3.823544</span>
<span class="n">ww_percentile</span><span class="w">                                   </span><span class="mf">99.983032</span>
</code></pre></div>

<p>On the other end, the streakiest performance of the year belonged to Jabari Walker of the Portland Trail Blazers. Made his first 6 shots in a row, then missed his last 8 in a row.</p>
<div class="highlight"><pre><span></span><code><span class="n">makes</span><span class="w">                                  </span><span class="mi">6</span>
<span class="n">misses</span><span class="w">                                 </span><span class="mi">8</span>
<span class="n">total_streaks</span><span class="w">                          </span><span class="mi">2</span>
<span class="n">raw_data</span><span class="w">                  </span><span class="n">WWWWWWLLLLLLLL</span>
<span class="n">expected_streaks</span><span class="w">                </span><span class="mf">7.857143</span>
<span class="n">variance</span><span class="w">                        </span><span class="mf">3.089482</span>
<span class="n">z_score</span><span class="w">                        </span><span class="o">-</span><span class="mf">3.332292</span>
<span class="n">exact_percentile_rank</span><span class="w">             </span><span class="mf">0.0333</span>
<span class="n">z_from_percentile_rank</span><span class="w">         </span><span class="o">-</span><span class="mf">3.403206</span>
<span class="n">ww_percentile</span><span class="w">                   </span><span class="mf">0.043067</span>
</code></pre></div>

<h2>Actual player performances</h2>
<p>Let's look at actual NBA games where a player had exactly 7 makes and 4 misses. (We can also include the flip side, 4 makes and 7 misses, because it will be the same distribution of streak lengths)</p>
<p>The green areas are where the players had more streaks than the exact probabilities; the red areas are where players had fewer streaks. The two are very close, except for a lot more games with 9 streaks in the player data, and fewer 6 streak games.</p>
<p>The exact mean is 6.09 streaks. The mean for player performances is 6.20 streaks. Even in this little slice of data, there's a slight tendency towards unstreakiness.</p>
<p><img alt="streaks-vs-probs" src="/img/streaks-vs-probs.png"></p>
<h2>Percentile ranks are still unstreaky, though</h2>
<p>Well, for all that windup, the game-level percentile ranks didn't turn out all that different when I calcualted them for all 18,000+ player-game combos. The mean and median are still shifted to the un-streaky side, to a significant degree.</p>
<p><img alt="z-from-percentile" src="/img/z-from-percentile.png"></p>
<p>Plotting the deciles shows an interesting tendency: a lot more values in the 60-70th percentile range than expected. the shift to the un-streaky side comes pretty much from these values.</p>
<p><img alt="perc-rank-deciles" src="/img/perc-rank-deciles.png"></p>
<p>The bias towards the unstreaky side is still there, and still significant:</p>
<div class="highlight"><pre><span></span><code>count    18982.000000
mean         0.039683
std          0.893720
min         -3.403206
25%         -0.643522
50%          0.059717
75%          0.674490
max          3.823544
</code></pre></div>

<h2>A weird continuity correction that seems obviously bad</h2>
<p>SAS, the granddaddy of statistics software, applies a continuity correction to the runs test whenever the count is less than 50.</p>
<p>While it's true that we should be careful with normal approximations and small sample size, this ain't the way.</p>
<p>The exact code used is here: <a href="https://support.sas.com/kb/33/092.html">https://support.sas.com/kb/33/092.html</a></p>
<div class="highlight"><pre><span></span><code><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nv">N</span><span class="w"> </span><span class="nv">GE</span><span class="w"> </span><span class="mi">50</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="nv">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">(</span><span class="nv">Runs</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nv">mu</span><span class="ss">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nv">sigma</span><span class="c1">;</span>
<span class="w">        </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nv">Runs</span><span class="o">-</span><span class="nv">mu</span><span class="w"> </span><span class="nv">LT</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="nv">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">(</span><span class="nv">Runs</span><span class="o">-</span><span class="nv">mu</span><span class="o">+</span><span class="mi">0</span>.<span class="mi">5</span><span class="ss">)</span><span class="o">/</span><span class="nv">sigma</span><span class="c1">;</span>
<span class="w">          </span><span class="k">else</span><span class="w"> </span><span class="nv">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">(</span><span class="nv">Runs</span><span class="o">-</span><span class="nv">mu</span><span class="o">-</span><span class="mi">0</span>.<span class="mi">5</span><span class="ss">)</span><span class="o">/</span><span class="nv">sigma</span><span class="c1">;</span>
</code></pre></div>

<p>Other implementations I looked at, like the one in R's <a href="https://www.rdocumentation.org/packages/randtests/versions/1.0.1/topics/runs.test"><code>randtests</code> package</a>, don't do the correction.</p>
<p>What does this sort of correction look like?</p>
<p>For starters, it gives us something that doesn't look like a z score. The std is way too small.</p>
<div class="highlight"><pre><span></span><code>count    18982.000000
mean        -0.031954
std          0.687916
min         -3.047828
25%         -0.401101
50%          0.000000
75%          0.302765
max          3.390395
</code></pre></div>

<p><img alt="sas-cc" src="/img/sas-cc.png"></p>
<h3>What does this look like on random data?</h3>
<p>It could just be this dataset, though. I will generate a fake season of data like in the last installment, but the players will have no unstreaky/streaky tendencies. They will behave like a coin flip, weighted to their season FG%. So the results should be distributed like we expect z scores to be (mean=0, std=1)</p>
<p>Here are the z-scores. They're not obviously bad, but the center is a bit higher than it should be.</p>
<p><img alt="sas-sim" src="/img/sas-sim.png"></p>
<p>However, the continuity correction especially stands out when looking at small sample sizes (in this case, simulated players with fewer than 30 shooting streaks over the course of the season).</p>
<p>In the below graph, red are the SAS corrected z-scores, green are the wald-wolfowitz z scores, brown are the overlap.</p>
<p><img alt="sas-low-vol" src="/img/sas-low-vol.png"></p>
<p>Continuity corrections are at best an imperfect substitute for calculating the exact odds. These days, there's no reason not to use exact odds for smaller sample sizes. Even though it ended up not mattering much, I should've started with the percentile rank for individual games. However, I don't think that the game level results are as important to the case I'm making as the career-long shooting results.</p>
<p>Next time, I will look at the past 20 years of NBA data. Who is the un-streakiest player of all time?</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/approximate-normality-and-continuity-corrections.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/statistics.html" rel="tag">statistics</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/basketball.html" class="tags">basketball</a>
                    &nbsp;<a href="/tag/the-hot-hand.html" class="tags">the hot hand</a>
                </div>
            </article>            <h4 class="date">May 28, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/simulating-hot-and-lukewarm-hands.html" rel="bookmark" title="Permanent Link to &quot;Simulating hot and lukewarm hands&quot;">Simulating hot and lukewarm hands</a>
                </h2>

                
                

                <p>(Notebooks and other code available at: <a href="https://github.com/csdurfee/hot_hand">https://github.com/csdurfee/hot_hand</a>. There's a bunch of stuff in the notebook about the Wald-Wolfowitz test that I will save for another week.)</p>
<p>In my last installment, I was looking at season long shooting records from the NBA, and I concluded that NBA players were less streaky than expected. They have fewer long strings of makes and misses than a series of coin flips would.</p>
<p>I've been thinking this could be due to "heat check" shots -- a player has made a bunch of shots in a row, or are having a good shooting game in general, so they take harder shots than they normally take. 
It would explain some players that fans consider streaky or "heat check" players who are actually super un-streaky. Jordan Poole was the least streaky player over the last 4 seasons, which defies my expectations. Say he believes he is streaky, so tends to take bad shots when</p>
<p>Or it could be due to "get a bucket" shots -- a player is having a bad shooting game, so they force higher percentage shots and potentially free throws. </p>
<p>There's a quirk of NBA stats to remember: if a player is fouled while shooting, it only counts as a field goal attempt if they make the shot. So driving to the hoop is guaranteed to not decrease a player's field goal percentage if they successfully draw a foul, or get called for an offensive foul.</p>
<p>I'm not sure I've made an airtight case for the <em>lukewarm hand</em>. Combining every game in a season could hide the hot hand effect. What about individual games?</p>
<h2>Game-level shooting statistics show a lukewarm tendency</h2>
<p>I am using the complete shooting statistics available from this kaggle project: <a href="https://www.kaggle.com/datasets/mexwell/nba-shots">https://www.kaggle.com/datasets/mexwell/nba-shots</a></p>
<p>I'm looking at the 2023-2024 season, since the current season isn't included yet.</p>
<p>I went through every game that every player played in the NBA season and calculated the expected vs. actual number of streaks.  </p>
<p>There are 24,895 player+game combos. 10,285 of them had more streaks than expected against 8,977 who had fewer streaks than expected (and around 5,000 that are exactly as expected). This is a significant imbalance towards the "lukewarm hand" side.</p>
<p>Here's the histogram of individual game z-scores:</p>
<p><img alt="individual game z-scores, 2023" src="/img/game-zscores-2023.png"></p>
<p>And the breakdown:</p>
<div class="highlight"><pre><span></span><code><span class="nx">count</span><span class="w">    </span><span class="m m-Double">18982.000000</span>
<span class="nx">mean</span><span class="w">         </span><span class="m m-Double">0.051765</span>
<span class="nx">std</span><span class="w">          </span><span class="m m-Double">0.988789</span>
<span class="nx">min</span><span class="w">         </span><span class="o">-</span><span class="m m-Double">3.332292</span>
<span class="mi">25</span><span class="o">%</span><span class="w">         </span><span class="o">-</span><span class="m m-Double">0.707107</span>
<span class="mi">50</span><span class="o">%</span><span class="w">          </span><span class="m m-Double">0.104103</span>
<span class="mi">75</span><span class="o">%</span><span class="w">          </span><span class="m m-Double">0.816497</span>
<span class="nx">max</span><span class="w">          </span><span class="m m-Double">3.583243</span>
<span class="nx">Name</span><span class="p">:</span><span class="w"> </span><span class="nx">z_score</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="p">:</span><span class="w"> </span><span class="nx">float64</span>
</code></pre></div>

<p>Limiting to higher volume games (at least 10 makes or 10 misses) shows the same tendency.</p>
<p><img alt="high attempt games, 2023-24" src="/img/high-attempt-games.png"></p>
<div class="highlight"><pre><span></span><code><span class="nx">count</span><span class="w">    </span><span class="m m-Double">2536.000000</span>
<span class="nx">mean</span><span class="w">        </span><span class="m m-Double">0.055925</span>
<span class="nx">std</span><span class="w">         </span><span class="m m-Double">1.010195</span>
<span class="nx">min</span><span class="w">        </span><span class="o">-</span><span class="m m-Double">3.079575</span>
<span class="mi">25</span><span class="o">%</span><span class="w">        </span><span class="o">-</span><span class="m m-Double">0.616678</span>
<span class="mi">50</span><span class="o">%</span><span class="w">         </span><span class="m m-Double">0.072404</span>
<span class="mi">75</span><span class="o">%</span><span class="w">         </span><span class="m m-Double">0.750366</span>
<span class="nx">max</span><span class="w">         </span><span class="m m-Double">3.583243</span>
<span class="nx">Name</span><span class="p">:</span><span class="w"> </span><span class="nx">z_score</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="p">:</span><span class="w"> </span><span class="nx">float64</span>
</code></pre></div>

<p>There definitely appears to be a bias towards the lukewarm hand in individual game data. The mean z scores aren't that much bigger than zero, but it's a huge sample size.</p>
<h2>Simulating streaky and non-streaky players</h2>
<p>I coded up a simulation of a non-streaky player. When they have hit a minimum number of attempts in the game, if their shooting percentage goes above a certain level, they get a penalty. If it goes below a certain level, they get a boost.</p>
<p>I was able to create results that look like NBA players in aggregate with an extremely simplified model. The parameters were arbitrarily chosen</p>
<p>By default, the thresholds are 20% and 80%, and the boost/penalty is 20%. So a 50% shooter who has taken at least 4 shots and is shooting 80% or better for the game will get their FG% knocked down to 30% till their game percentage drops below the threshold. Likewise if they hit 20% or less, they get a boost until they're over the threshold.</p>
<p>I used the game level shooting statistics I got for the individual game-by-game analysis. I then replayed every shot in the NBA in the 2023-24 season using the simulated lukewarm player (and the actual fg% and number of shots attempted in each game). This is what I got:</p>
<p><img alt="sim-z-scores" src="/img/sim-z-scores.png"></p>
<div class="highlight"><pre><span></span><code><span class="nx">count</span><span class="w">    </span><span class="m m-Double">526.000000</span>
<span class="nx">mean</span><span class="w">       </span><span class="m m-Double">0.218032</span>
<span class="nx">std</span><span class="w">        </span><span class="m m-Double">0.965737</span>
<span class="nx">min</span><span class="w">       </span><span class="o">-</span><span class="m m-Double">2.397958</span>
<span class="mi">25</span><span class="o">%</span><span class="w">       </span><span class="o">-</span><span class="m m-Double">0.491051</span>
<span class="mi">50</span><span class="o">%</span><span class="w">        </span><span class="m m-Double">0.241554</span>
<span class="mi">75</span><span class="o">%</span><span class="w">        </span><span class="m m-Double">0.836839</span>
<span class="nx">max</span><span class="w">        </span><span class="m m-Double">3.787951</span>
<span class="nx">Name</span><span class="p">:</span><span class="w"> </span><span class="nx">z_score</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="p">:</span><span class="w"> </span><span class="nx">float64</span>
</code></pre></div>

<p>My simulation was actually less biased to the right than the actual results:</p>
<p><img alt="actual-2023-24" src="/img/actual-2023-24.png"></p>
<p>Several big things to note:</p>
<ol>
<li>I simulated every player in the league as being a little un-streaky.</li>
<li>I simulated them being un-streaky in both directions</li>
<li>The boost/penalty are pretty big -- going from 50% FG percentage to 30% is going from a good NBA player to a bad college player level, and the boost to 70% FG percentage has no precedent. The most accurate shooters in the NBA are usually big men who only shoot dunks and layups, and they still usually end up in the 60-65% range.</li>
</ol>
<p>Which is to say, my simulation is kind of silly and seemingly over-exaggerated. And it's still not as lukewarm as real NBA players are.  Wild, isn't it?</p>
<h2>Streakiness in only one direction</h2>
<p>I also simulated players who were only streaky in one direction: "get a bucket" players who get a boost to shooting percentage when they are shooting poorly, but no penalty when they are doing well, and "heat check" players who only get the penalty.</p>
<p>The results were biased to the unstreaky side, but about half as much as the ones that are streaky in both directions. I had to crank the penalties/boosts up to unrealistic levels to get the bias of the z-scores up to the .2-.3 range I'm seeing with real season-level data.</p>
<h2>The truly streaky player</h2>
<p>Of course, I had to simulate the hot hand. The <code>TrulyStreakyPlayer</code> is the exact opposite of the <code>LukewarmPlayer</code>. They get a 20% boost when they're shooting well on the game, and a 20% penalty when they're shooting poorly.</p>
<p>What stands out to me here is how much it affects the z-score. I was expecting the z-scores to be biased to the negative side by about as much as the unstreaky player was to the positive side. But the effect was a lot more dramatic:</p>
<div class="highlight"><pre><span></span><code>count    524.000000
mean      -0.455522
std        1.144570
min       -4.413268
25%       -1.225128
50%       -0.458503
75%        0.404549
max        2.486584
</code></pre></div>

<p><img alt="truly-streaky-player" src="/img/truly-streaky-player.png"></p>
<p>Unlike the un-streaky simulations, the streaky behavior increased the dispersion (<code>std</code>), like we saw with the real shot data. There are many more outliers to the negative side than we'd expect.</p>
<h2>What next?</h2>
<p>I could certainly sim a mixture of streaky and unstreaky players, and eventually maybe get something that matches the real numbers pretty closely. But there are so many parameters to fit that it would be pretty arbitrary. Someone else could produce a different model that works just as well. </p>
<p>Most importantly, it couldn't tell us which players might be streaky due to chance versus streaky due to behavior/shot selection. So I think the next step is looking at the shot selection in the "hot hand" vs. "get a bucket" situations -- do players switch to higher percentage shots when they're having a bad game, and worse shots when they're shooting better than usual?</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/simulating-hot-and-lukewarm-hands.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/sports-analytics.html" rel="tag">sports analytics</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/basketball.html" class="tags">basketball</a>
                    &nbsp;<a href="/tag/the-hot-hand.html" class="tags">the hot hand</a>
                </div>
            </article>            <h4 class="date">May 23, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/what-are-the-most-important-events-at-the-nfl-combine.html" rel="bookmark" title="Permanent Link to &quot;What are the most important events at the NFL Combine?&quot;">What are the most important events at the NFL Combine?</a>
                </h2>

                
                

                <p>(the code used is available at <a href="https://github.com/csdurfee/nfl_combine_data/">https://github.com/csdurfee/nfl_combine_data/</a>).</p>
<h2>Intro</h2>
<p>Every year, the National Football League hosts an event called the Combine, where teams can evaluate the top prospects before the upcoming draft.</p>
<p>Athletes are put through a series of physical and mental tests over the course of four days. There is a lot of talk of hand size, arm length, and whether a guy looks athletic enough when he's running with his shirt off. It's basically the world's most invasive job interview. </p>
<p>NFL teams have historically put a lot of stock in the results of the combine. A good showing at the combine can improve a player's career prospects, and a bad showing can significantly hurt them. For that reason, some players will opt out of attending the combine, but that can backfire as well.</p>
<p>I was curious about which events in the combine correlate most strongly with draft position. There are millions of dollars at stake. The first pick in the NFL draft gets a $43 Million dollar contract, the 33rd pick gets $9.6 Million, and the 97th pick gets $4.6 Million.</p>
<p>The main events of the combine are the 40 yard dash, vertical leap, bench press, broad jump, 3 cone drill and shuttle drill. The shuttle drill and the 3 cone drill are pretty similar -- a guy running between some cones as fast as possible. The other drills are what they sound like.</p>
<p>I'm taking the data from Pro Football Reference. Example page: <a href="https://www.pro-football-reference.com/draft/2010-combine.htm">https://www.pro-football-reference.com/draft/2010-combine.htm</a>. I'm only looking at players who got drafted.</p>
<h2>Position Profiles</h2>
<p>It makes no sense to compare a cornerback's bench press numbers to a defensive lineman's. There are vast differences in the job requirements. A player in the combine is competing against other players at the same position. </p>
<p>The graph shows a position's performance on each exercise relative to all players. The color indicates how the position as a whole compares to the league as a whole. You can change the selected position with the dropdown.</p>
<iframe src="/img/position_view_2025.html" width="550" height="450" frameborder="0"></iframe>

<p>Cornerbacks are exceptional on the 40 yard dash and shuttle drills compared to NFL athletes as a whole, whereas defensive linemen are outliers when it comes high bench press numbers, and below average at every other event. Tight Ends and Linebackers are near the middle in every single event, which makes sense because both positions need to be strong enough to deal with the strong guys, and fast enough to deal with the fast guys.</p>
<h2>Importance of Events by Position</h2>
<p>I analyzed how a player's performance relative to others at their position correlates with draft rank. Pro-Football-Reference has combine data going back to 2000.  I have split the data up into 2000-2014 and 2015-2025 to look at how things have changed. </p>
<p>For each position, the exercises are ranked from most to least important. The tooltip gives the exact r^2 value.</p>
<p>Here are the results up to 2014:</p>
<iframe src="/img/before_2015.html" width="800" height="700" frameborder="0"></iframe>

<p>Here are the last 10 years:</p>
<iframe src="/img/after_2015.html" width="800" height="700" frameborder="0"></iframe>

<p>Some things I notice:</p>
<p>The main combine events matter that much either way for offensive and defensive linemen. That's held true for 25 years.</p>
<p>The shuttle and 3 cone drill have gone up significantly in importance for tight ends.</p>
<p>Broad jump and 40 yard dash are important for just about every position. However, the importance of the 40 yard dash time has gone down quite a bit for running backs. </p>
<p>As a fan, it used to be a huge deal when a running back posted an exceptional 40 yard time. It seemed Chris Johnson's legendary 4.24 40 yard time was referenced every year. But I remember there being lot of guys who got drafted in the 2000's primarily based on speed who turned out to not be very good. </p>
<p>The bench press is probably the least important exercise across the board. There's almost no correlation between performance and draft order, for every position. Offensive and defensive linemen basically bench press each other for 60 minutes straight; for everybody else, that sort of strength is less relevant.  Here's one of the greatest guys at throwing the football in human history, Tom Brady:</p>
<p><img alt="behold" src="/img/Tom-Brady-Combine.png"></p>
<p>Compared to all quarterbacks who have been drafted since 2000, Brady's shuttle time was in the top 25%, his 3 cone time was in the top 50%, and his broad jump, vertical leap and 40 yard dash were all in the bottom 25%.</p>
<h2>Changes in combine performance over time</h2>
<p>Athlete performance has changed over time. </p>
<p>I've plotted average performance by year for each of the events. For the 40 yard dash, shuttle, and 3 cone drills, lower is better, and for the other events, higher is better.</p>
<p><img alt="change over time" src="/img/combine-trends.png"></p>
<p>40 yard dash times and broad jump distances have clearly improved, whereas shuttle times and bench press reps have gotten slightly worse.</p>
<p>There's a cliche in sports that "you can't coach speed".  While some people are innately faster than others, the 40 yard dash is partly a skill exercise -- learning to get off the block as quickly as possible without faulting, for starters. The high priority given to the 40 yard dash should lead to prospects practicing it more, and thus getting better numbers.</p>
<p>The bench press should be going down or staying level, since it's not very important to draft position.</p>
<p>There's been a significant improvement in the broad jump - about 7.5% over 25 years. As with the 40 yard dash, I'd guess it's better coaching and preparation. Perhaps it's easier to improve than some of the other events. I don't think there's more broad jumping in an NFL game than there was 25 years ago.</p>
<p>Shuttle times getting slightly worse is a little surprising. It's very similar to the 3 Cone drill, which has slightly improved. But as we saw, neither one is particularly important as far as draft position, and it's not a strong trend.</p>
<h2>Caveats</h2>
<p>Some of the best athletes skip the combine entirely, because their draft position is already secure. And some athletes will only choose to do the exercises they think they will do well at, and skip their weak events. This is known as <a href="https://www.ncbi.nlm.nih.gov/books/NBK493614/">MNAR data</a> (missing, not at random). All analysis of MNAR data is potentially biased.</p>
<p>I'm assuming a linear relationship between draft position and performance. It's possible that a good performance helps more than a bad performance hurts, or vice versa.</p>
<p>I didn't calculate statistical significance for anything. Some correlations will occur even in random data. This isn't meant to be rigorous.</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/what-are-the-most-important-events-at-the-nfl-combine.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/sports-analytics.html" rel="tag">sports analytics</a>
                    &nbsp;&middot;
                    &nbsp;<a href="/tag/football.html" class="tags">football</a>
                </div>
            </article>            <h4 class="date">May 22, 2025</h4>

            <article class="post">
                <h2 class="title">
                    <a href="/majority-voting-in-ensemble-learning.html" rel="bookmark" title="Permanent Link to &quot;Majority Voting in Ensemble Learning&quot;">Majority Voting in Ensemble Learning</a>
                </h2>

                
                

                <p>(notebook is available at <a href="https://github.com/csdurfee/ensemble_learning/blob/main/ensemble_voting.ipynb">github.com/csdurfee/ensemble_learning</a>.)</p>
<h2>Ensemble Learning</h2>
<p>AI and machine learning systems are often used for classification. Is this email spam or not? Is this person a good credit risk or not? Is this a photo of a cat or not?</p>
<p>There are a lot of ways to build classifiers, and they all potentially have different strengths and weaknesses. It's natural to try combining multiple models together to produce better results than the individual models would. </p>
<p>Model A might be bad at classifying black cats but good at orange ones, model B might be bad at classifying orange cats but good at black ones, model C is OK at both. So if we average together the results of the three classifiers, or go with the majority opinion between them, the results might be better than the individual classifiers.</p>
<p>This is called an ensemble. Random forests and gradient boosting are two popular machine learning techniques that use ensembles of <em>weak learners</em> -- a large number of deliberately simple models that are all trained on different subsets of the data. This strategy can lead to systems that are more powerful than their individual components. While each little tree in a random forest is weak and prone to overfitting, the forest as a whole can be robust and give high quality predictions.</p>
<h2>Majority Voting</h2>
<p>We can also create ensembles of <em>strong learners</em> -- combining multiple powerful models together. Each individual model is powerful enough to do the entire classification on its own, but we hope to achieve higher accuracy by combining their results.  The most common way to do that is with voting. Query several classifiers, and have the ensemble return the majority pick, or otherwise combine the results.</p>
<p>There are some characteristics of ensembles that seem pretty common sense [1]. The classifiers in the ensemble need to be <em>diverse</em>: as different as possible in the mistakes they make. If they all make the same mistakes, then there's no way for the ensemble to correct for that. </p>
<p>The more classification categories, the more classifiers are needed in the ensemble. However, in real world settings, there's usually a point where adding more classifiers doesn't improve the ensemble. </p>
<h2><a name="model"></a>The Model</h2>
<p>I like building really simple models. They can illustrate fundamental characteristics, and show what happens at the extremes. </p>
<p>So I created an extremely simple model of majority voting (see <a href="https://github.com/csdurfee/ensemble_learning/blob/main/ensemble_voting.ipynb">notebook</a>). I'm generating a random list of 0's and 1's, indicating the ground truth of some binary classification problem. Then I make several copies of the ground truth and randomly flip <code>x%</code> of the bits. Each of those copies represent the responses from an individual classifier within the ensemble. Each fake classifier will have <code>100-x%</code> accuracy. There's no correlation between the wrong answers that each classifier gives, because the changes were totally random. </p>
<p>For every pair of fake classifiers with 60% accuracy, they will both be right <code>60% * 60% = 36%</code> of the time, and both wrong <code>40% * 40% = 16%</code>. So they will agree <code>36% + 16% = 52%</code> of the time at minimum.</p>
<p>That's different from the real world. Machine learning algorithms trained on the same data will make a lot of the same mistakes and get a lot of the same questions right. If there are outliers in the data, any classifier can overfit on them. And they're all going to find the same basic trends in the data. If there aren't a lot of good walrus pictures in the training data, every model is probably going to be bad at recognizing walruses. There's no way to make up for what isn't there.</p>
<h2>Theory vs Reality</h2>
<p>In the real world, there seem to be limits on how much an ensemble can improve classification. On paper, there are none, as the simulation shows.</p>
<p>What is the probability of the ensemble being wrong about a particular classification?</p>
<p>That's the probability that the majority of the classifiers predict 0, given that the true value is 1 (and vice versa). If each classifier is more likely to be right than wrong, as the number of classifiers goes to infinity, the probability of the majority of predictions being wrong goes to 0.</p>
<p>If each binary classifier has a probability &gt; .5 of being right, we can make the ensemble arbitrarily precise if we add enough classifiers to the ensemble (assuming their errors are independent). We could grind the math using the normal approximation to get the exact number if need be.</p>
<p>Let's say each classifier is only right 50.5% of the time. We might have to add 100,000 of them to the ensemble, but we can make the error rate arbitrarily small.</p>
<h2>Correlated errors ruin ensembles</h2>
<p>The big difference between my experiment and reality is that the errors the fake classifiers make are totally uncorrelated with each other. I don't think that would ever happen in the real world. </p>
<p>The more the classifiers' wrong answers are correlated with each other, the less useful the ensemble becomes. If they are 100% correlated with each other, the ensemble will give the exact same results as the individual classifiers, right? An ensemble doesn't <em>have to</em> improve results.</p>
<p>To put it in human terms, the "wisdom of the crowd" comes from people in the crowd having wrong beliefs about uncorrelated things (and being right more often than not overall). If most people are wrong in the same way, there's no way to overcome that with volume. </p>
<p>My experience has been that different models tend to make the same mistakes, even if they're using very different AI/machine learning algorithms, and a lot of that is driven by weaknesses in the training data used.</p>
<p>For a more realistic scenario, I created fake classifiers with correlated answers, so that they agree with the ground truth 60% of the time, and with each other 82% of the time, instead of the minimum 52% of the time. 
The Cohen kappa score is .64, on a scale from -1 to 1, so they aren't as correlated as they could be.</p>
<p>The simulation shows that if the responses are fairly strongly correlated with each other, there's a hard limit to how much the ensemble can improve things. </p>
<p>Even with 99 classifiers in the ensemble, the simulation only achieves an f1 score of .62. That's just a slight bump from the .60 achieved individually. There is no marginal value to adding more than 5 classifiers to the ensemble at this level of correlation.</p>
<h2>Ensembles: The Rich Get Richer</h2>
<p>I've seen voting ensembles suggested for especially tricky classification problems, where the accuracy of even the  best models is pretty low. I haven't found that to be true, though, and the simulation backs that up. Ensembles are only going to give a significant boost for binary classification if the individual classifiers are significantly better than 50% accuracy.</p>
<p>The more accurate the individual classifiers, the bigger the boost from the ensemble. These numbers are for an ensemble of 3 classifiers (in the ideal case of no correlation between their responses):</p>
<table>
<thead>
<tr>
<th>Classifier Accuracy</th>
<th>Ensemble Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>55%</td>
<td>57%</td>
</tr>
<tr>
<td>60%</td>
<td>65%</td>
</tr>
<tr>
<td>70%</td>
<td>78%</td>
</tr>
<tr>
<td>80%</td>
<td>90%</td>
</tr>
</tbody>
</table>
<h2>Hard vs. soft voting</h2>
<p>There are two different ways of doing majority voting, hard and soft. This choice can have an impact on how well an ensemble works, but I haven't seen a lot of guidance on when to use each. </p>
<p><em>Hard voting</em> is where we convert the outputs of each binary classifier into a boolean yes/no, and go with the majority opinion. If there are an odd number of components and it's a binary classification, there's always going to be a clear winner. That's what I've been simulating so far.</p>
<p><em>Soft voting</em> is where we combine the raw outputs of all the components, and then round the combined result to make the prediction. <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier">sklearn's documentation</a> advises to use soft voting "for an ensemble of well-calibrated classifiers".</p>
<p>In the real world, binary classifiers don't return a nice, neat 0 or 1 value. They return some value between 0 or 1 indicating a relative level of confidence in the prediction, and we round that value to 0 or 1. A lot of models will never return a 0 or 1 -- for them, nothing is impossible, just extremely unlikely.</p>
<p>If a classifier returns <code>.2</code>, we can think of it as the model giving a <code>20%</code> chance that the answer is <code>1</code> and an <code>80%</code> chance it's <code>0</code>. That's not really true, but the big idea is that there's potentially additional context that we're throwing away by rounding the individual results.</p>
<p>For instance, say the raw results are <code>[.3,.4,.9]</code>. With hard voting, these would get rounded to <code>[0,0,1]</code>, so it would return <code>0</code>. With soft voting, it would take the average of <code>[.3,.4,.9]</code>, which is <code>.53</code>, which rounds to <code>1</code>. So the two methods can return different answers.</p>
<p>To emulate the soft voting case, I flipped a percentage of the bits, as before. Then I replaced every 0 with a number chosen randomly from the uniform distribution from <code>[0,.5]</code> and every <code>1</code> with a sample from <code>[.5,1]</code>. The values will still round to what they did before, but there's additional noise on top. </p>
<p>In this simulation (3 classifiers), the soft voting ensemble gives less of a boost than the hard voting ensemble -- about half the benefits. As with hard voting, the more accurate the individual classifiers are, the bigger the boost the ensemble gives. </p>
<table>
<thead>
<tr>
<th>Classifier Accuracy</th>
<th>Ensemble Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>55%</td>
<td>56%</td>
</tr>
<tr>
<td>60%</td>
<td>62%</td>
</tr>
<tr>
<td>70%</td>
<td>74%</td>
</tr>
<tr>
<td>80%</td>
<td>85%</td>
</tr>
</tbody>
</table>
<h2>Discussion</h2>
<p>Let's say a classifier returns <code>.21573</code> and I round that down to 0. How much of the <code>.21573</code> that got lost was noise, and how much was signal? If a classification task is truly binary, it could be all noise. Let's say we're classifying numbers as odd or even. Those are unambiguous categories, so a perfect classifier should always return exactly 0 or 1. It shouldn't say that three is odd, with 90% confidence. In that case, it clearly means the classifier is 10% wrong. There's no good reason for uncertainty.</p>
<p>On the other hand, say we're classifying whether photos contain a cat or not. What if a cat is wearing a walrus costume in one of the photos? Shouldn't the classifier return a value greater than 0 for the possibility of it not being a cat, even if there really is a cat in the photo? Isn't it somehow less cat-like than another photo where it's not wearing a walrus costume? In this case, the <code>.21573</code> at least partially represents signal, doesn't it? It's saying "this is pretty cat-like, but not as cat-like as another photo that scored <code>.0001</code>".</p>
<p>When I'm adding noise to emulate the soft voting case, is that <em>fair</em>? A different way of fuzzing the numbers (selecting the noise from a non-uniform distribution, for instance) might reduce the gap in performance between hard and soft voting ensembles, and it would probably be more realistic. But the point of a model like this is to show the extremes -- it's possible that hard voting will give better results than soft voting, so it's worth testing.</p>
<h2>Big Takeaways</h2>
<ol>
<li>Ensembles aren't magic; they can only improve things significantly if the underlying classifiers are diverse and fairly accurate.</li>
<li>Hard and soft voting aren't interchangeable. If there's a lot of random noise in the responses, hard voting is probably a better option, otherwise soft voting is probably better. It's definitely worth testing both options when building an ensemble.</li>
<li>Anyone thinking of using an ensemble should look at the amount of correlation between the responses from different classifiers. If the classifiers are all making basically the same mistakes, an ensemble won't help regardless of hard vs. soft voting. If models with very different architectures are failing in the same ways, that could be a weakness in the training data that can't be fixed by an ensemble.</li>
</ol>
<h3>References</h3>
<p>[1] Bonab, Hamed; Can, Fazli (2017). "Less is More: A Comprehensive Framework for the Number of Components of Ensemble Classifiers". arXiv:1709.02925</p>
<p>Tsymbal, A., Pechenizkiy, M., &amp; Cunningham, P. (2005). Diversity in search strategies for ensemble feature selection. Information Fusion, 6(1), 83–98. doi:10.1016/j.inffus.2004.04.003 </p>
                <div class="clear"></div>

                <div class="info">
                    <a href="/majority-voting-in-ensemble-learning.html">posted at 10:20</a>
                    &nbsp;&middot;&nbsp;<a href="/category/machine-learning.html" rel="tag">machine learning</a>
                </div>
            </article>

                <div class="clear"></div>
                <div class="pages">


                    <a href="/index2.html" class="next_page">Next&nbsp;&rarr;</a>

                    <span>Page 1 of 2</span>
                </div>

            <div class="clear"></div>
            <footer>
                <p>
                <a href="https://github.com/tcarwash/blue-penguin-dark">Blue Penguin Dark</a> Theme
                &middot;
                Powered by <a href="http://getpelican.com">Pelican</a>
                &middot;
                <a href="/feeds/all.atom.xml" rel="alternate">Atom Feed</a>
            </footer>
        </div>
        <div class="clear"></div>
    </div>
</body>
</html>