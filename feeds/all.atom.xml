<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>mathletix</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2025-07-26T10:20:00-10:00</updated><entry><title>Riding the waves</title><link href="/riding-the-waves.html" rel="alternate"></link><published>2025-07-26T10:20:00-10:00</published><updated>2025-07-26T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-07-26:/riding-the-waves.html</id><summary type="html">&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=ko8cJucsbBU" target="_blank"&gt;&lt;img alt="Roy of the Ravers, &amp;quot;Emotinium&amp;quot;" src="https://img.youtube.com/vi/ko8cJucsbBU/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After spending several weeks in the degenerate world of sports gambling, I figured we should go get some fresh air in the land of pure statistics.&lt;/p&gt;
&lt;h2&gt;The Abnormal Distribution&lt;/h2&gt;
&lt;p&gt;Everybody knows what the normal distribution looks like, even if they don't know it as such. You know, the bell curve …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=ko8cJucsbBU" target="_blank"&gt;&lt;img alt="Roy of the Ravers, &amp;quot;Emotinium&amp;quot;" src="https://img.youtube.com/vi/ko8cJucsbBU/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After spending several weeks in the degenerate world of sports gambling, I figured we should go get some fresh air in the land of pure statistics.&lt;/p&gt;
&lt;h2&gt;The Abnormal Distribution&lt;/h2&gt;
&lt;p&gt;Everybody knows what the normal distribution looks like, even if they don't know it as such. You know, the bell curve? The one from the memes?&lt;/p&gt;
&lt;p&gt;In traditional statistics, the One Big Thing you need to know is called the Central Limit Theorem. It says, if you collect some data and take the average of it, that average (the sample mean) will behave in nice, predictable ways. It's the basis of basically all experimental anything.  If you take a bunch of random samples and calculate the sample mean over and over again, those sample means will look like a normal distribution, if the sample sizes are big enough. That makes it possible to draw big conclusions from relatively small amounts of data.&lt;/p&gt;
&lt;p&gt;How big is "big enough"? Well, it partly depends on the shape of the data being sampled from. If the data itself is distributed like a normal distribution, it makes sense that the sample means would also be normally shaped. It takes a smaller sample size to get the sampling distributions looking like a normal distribution.&lt;/p&gt;
&lt;p&gt;While a lot of things in life are normally distributed, some of them aren't. The uniform distribution is when every possible outcome is equally likely. Rolling a single die, for instance. 1-6 are all equally likely. Imagine we're trying to estimate the mean value for rolling a standard 6 sided die. &lt;/p&gt;
&lt;p&gt;A clever way would be to team up sets of sides - 6 goes with 1, 5 goes with 2, 4 goes with 3. Clearly the mean value has to be 3.5, right?&lt;/p&gt;
&lt;p&gt;A less clever way would be to roll a 6 sided die a bunch of times and take the average. We could repeat that process, and track all of these averages. Those averages will make a nice bell curve, with the center at 3.5.&lt;/p&gt;
&lt;p&gt;The uniform distribution is sort of obnoxious if you want to calculate the sample mean. The normal distribution, and a lot of other distributions, have a big peak in the middle and tail off towards the edges. If you pick randomly from one of these distributions, it's far more likely to be close to the middle than it is to be far from the middle. With the uniform distribution, every outcome is equally likely:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/uniform.png" src="/img/uniform.png"&gt;&lt;/p&gt;
&lt;p&gt;Couldn't we do even worse than the uniform distribution, though? What if the tails/outliers were even higher than the center? When I first learned about the Central Limit Theorem, I remember thinking about that - how could you define a distribution to be the most obnoxious one possible? The normal distribution is like a frowny face. The Uniform distribution is like a "not impressed" face. Couldn't we have a smiley face distribution to be the anti-normal distribution?&lt;/p&gt;
&lt;h2&gt;Waveforms and probabilities.&lt;/h2&gt;
&lt;p&gt;All synthesizers in electronic music use a mix of different types of simple waveforms. The sublime &lt;a href="https://en.wikipedia.org/wiki/Roland_TB-303"&gt;TB-303&lt;/a&gt; synth line in the song at the top is very simple. The TB-303 a monophonic synth -- a single sawtooth wave (or square wave) with a bunch of filters on top that, in the right hands, turn it from buzzy electronic noise to an emotionally expressive instrument, almost like a digitial violin or human voice.&lt;/p&gt;
&lt;p&gt;This got me thinking about what probability distributions based on different types of waveforms would look like. How likely is the waveform to be at each amplitude?&lt;/p&gt;
&lt;p&gt;Here's the sawtooth waveform:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/sawtooth.png" src="/img/sawtooth.png"&gt;&lt;/p&gt;
&lt;p&gt;If we randomly sample from this wave (following a uniform distribution -- all numbers on the x axis are equally likely) and record the y value, then plot the values as a histogram, what would it look like? Think of it like we put a piece of toast on the Y axis of the graph, the X axis is time. How will the butter be distributed? &lt;/p&gt;
&lt;p&gt;It should be a flat line, like the Uniform distribution, since each stroke of butter is at a constant rate. We're alternating between a very fast wipe and a slower one, but in both cases, it doesn't spend any more time on one section of bread than another because it's a straight line.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/sawtooth-distro.png" src="/img/sawtooth-distro.png"&gt;&lt;/p&gt;
&lt;h2&gt;Advanced breakfast techniques&lt;/h2&gt;
&lt;p&gt;A square wave spends almost no time in the middle of the bread, so nearly all the butter will be at the edges. That's not a very interesting graph. What about a sine wave?&lt;/p&gt;
&lt;p&gt;The sawtooth wave always has a constant slope, so the butter is evenly applied. With the sine wave, the slope changes over time. Because of that, the butter knife ends up spending more time at the extreme ends of the bread, where the slope is shallow, compared to the middle of the bread. The more vertical the slope, the faster the knife passes over that bit of bread, and the less butter it gets.&lt;/p&gt;
&lt;p&gt;If we sample a bunch of values from the sine wave and plot their Y values as a histogram, we'll get something that looks like a smiley face -- lots of butter near the edges, less butter near the center of the toast. Or perhaps, in tribute to Ozzy, the index and pinky fingers of someone throwing the devil horns.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/arcsine-from-sine.png" src="/img/arcsine-from-sine.png"&gt;&lt;/p&gt;
&lt;p&gt;That's a perfectly valid buttering strategy in my book. The crust near the edges tends to be drier, and so can soak up more butter. You actually want to go a bit thinner in the middle, to maintain the structural integrity of the toast.&lt;/p&gt;
&lt;p&gt;This distribution of butter forms a probability distribution called the arcsine distribution. It's an anti-normal distribution -- fat in the tails, skinny in the middle. A "why so serious?" distribution the Joker might appreciate. The mean is the least likely value, rather than the most likely value. And yet, the Central Limit Theorem still holds. The mean of even a fairly small number of values will behave like a Normal distribution.&lt;/p&gt;
&lt;p&gt;Here are 1,000 iterations of an average of two samples from the arcsine distribution:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/arcsin-approx-2.png" src="/img/arcsin-approx-2.png"&gt;&lt;/p&gt;
&lt;p&gt;And averages of 5 samples:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/arcsin-approx-5.png" src="/img/arcsin-approx-5.png"&gt;&lt;/p&gt;
&lt;p&gt;And 30 samples at a time. Notice how the x range has shrunk down.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/arcsin-approx-30.png" src="/img/arcsin-approx-30.png"&gt;&lt;/p&gt;
&lt;p&gt;There are a lot of distributions that produce that U-type shape. They're known as &lt;a href="https://en.wikipedia.org/wiki/Bathtub_curve"&gt;bathtub curves&lt;/a&gt;. They come up when plotting the failure rates of devices (or people). For a lot of things, there's an elevated risk of failure near the beginning and the end, with lower risk in the middle. The curve is showing conditional probability -- for an iPhone to fail on day 500, it has to have not failed on the first 499 days.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/Bathtub_curve.svg" src="/img/Bathtub_curve.svg"&gt;&lt;/p&gt;
&lt;p&gt;(source: Wikipedia/Public Domain, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=7458336"&gt;https://commons.wikimedia.org/w/index.php?curid=7458336&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;Particle man vs triangle man&lt;/h2&gt;
&lt;p&gt;The Uniform distribution isn't really that ab-Normal. It's flat, but it's very malleable. It turns into the normal distribution almost instantly. The symmetry helps.&lt;/p&gt;
&lt;p&gt;If we take a single sample from a Uniform distribution over and over again, and plot a histogram, it's going to look flat, because every outcome is equally likely.&lt;/p&gt;
&lt;p&gt;If we take the sum (or average) of two Uniform random variables, what would that look like? We're going to randomly select two numbers between 0 and 1 and sum them up. The result will be between 0 and 2. But some outcomes will be more likely than others.  The extremes (0 and 2) should be extremely unlikely, right? Both the random numbers would have to be close to 0 for the sum to be, and vice versa. There are a lot of ways to get a sum of .5, though. It could be .9 and .1, or .8 and .2, and so on.&lt;/p&gt;
&lt;p&gt;If you look online, you can find many explanations of how to get the PDF of the sum of two Uniform distributions using calculus. (&lt;a href="https://courses.cs.washington.edu/courses/cse312/20su/files/student_drive/5.5.pdf"&gt;Here's a good one&lt;/a&gt;). While formal proofs are important, it's not very intuitive. So, here's another way to think of it.&lt;/p&gt;
&lt;p&gt;Let's say we're taking the sum of two dice instead of two Uniform random variables.  We're gonna start with two 4 sided dice. It will be obvious that we can scale the number of faces up, and the pattern will hold.&lt;/p&gt;
&lt;p&gt;What are the possible combinations of dice? The dice are independent, so each combination is equally likely. Let's write them out by columns according to their totals:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;(1, 1)&lt;/td&gt;
&lt;td&gt;(1,2)&lt;/td&gt;
&lt;td&gt;(1,3)&lt;/td&gt;
&lt;td&gt;(1,4)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(2,1)&lt;/td&gt;
&lt;td&gt;(2,2)&lt;/td&gt;
&lt;td&gt;(2,3)&lt;/td&gt;
&lt;td&gt;(2,4)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(3,1)&lt;/td&gt;
&lt;td&gt;(3,2)&lt;/td&gt;
&lt;td&gt;(3,3)&lt;/td&gt;
&lt;td&gt;(3,4)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(4,1)&lt;/td&gt;
&lt;td&gt;(4,2)&lt;/td&gt;
&lt;td&gt;(4,3)&lt;/td&gt;
&lt;td&gt;(4,4)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;If we write all the possibilities out like this, it's gonna look like a trapezoid, whether there are 4 faces on the dice, or 4 bajillion. Each row will have one more column that's blank than the one before, and one column that's on its own off to the right. &lt;/p&gt;
&lt;p&gt;If we consolidate the elements, we're gonna get a big triangle, right? Each column up to the mean will have one more combo, and each column after will have one less.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;(1, 1)&lt;/td&gt;
&lt;td&gt;(1,2)&lt;/td&gt;
&lt;td&gt;(1,3)&lt;/td&gt;
&lt;td&gt;(1,4)&lt;/td&gt;
&lt;td&gt;(2,4)&lt;/td&gt;
&lt;td&gt;(3,4)&lt;/td&gt;
&lt;td&gt;(4,4)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(2,1)&lt;/td&gt;
&lt;td&gt;(2,2)&lt;/td&gt;
&lt;td&gt;(2,3)&lt;/td&gt;
&lt;td&gt;(3,3)&lt;/td&gt;
&lt;td&gt;(4,3)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(3,1)&lt;/td&gt;
&lt;td&gt;(3,2)&lt;/td&gt;
&lt;td&gt;(4,2)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(4,1)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With a slight re-arrangement of values, it's clear the triangle builds up with each extra face we add to the dice.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;(1, 1)&lt;/td&gt;
&lt;td&gt;(1,2)&lt;/td&gt;
&lt;td&gt;(2,2)&lt;/td&gt;
&lt;td&gt;(2,3)&lt;/td&gt;
&lt;td&gt;(3,3)&lt;/td&gt;
&lt;td&gt;(3,4)&lt;/td&gt;
&lt;td&gt;(4,4)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(2,1)&lt;/td&gt;
&lt;td&gt;(1,3)&lt;/td&gt;
&lt;td&gt;(3,2)&lt;/td&gt;
&lt;td&gt;(2,4)&lt;/td&gt;
&lt;td&gt;(4,3)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(3,1)&lt;/td&gt;
&lt;td&gt;(1,4)&lt;/td&gt;
&lt;td&gt;(4,2)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;(4,1)&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The results for two 2 sided dice are embedded in the left 3 columns of table, then the results for two 3 sided dice on top of them, then two 4 sided dice. Each additional face will add 2 columns to the right. I'm not gonna formally prove anything, but hopefully it's obvious that it will always make a triangle.&lt;/p&gt;
&lt;p&gt;That's the &lt;a href="https://en.wikipedia.org/wiki/Triangular_distribution#Distribution_of_the_mean_of_two_standard_uniform_variables"&gt;triangular distribution&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's a simulation, calculating the sum of two random uniform variables over and over, and counting their frequencies:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/shaggy-triangle.png" src="/img/shaggy-triangle.png"&gt;&lt;/p&gt;
&lt;h1&gt;3 is the magic number&lt;/h1&gt;
&lt;p&gt;The sum (or average) of 3 Uniform random variables looks a whole lot like the normal distribution. The sides of the triangle round out, and we get something more like a parabola. Here's what it looks like in simulation:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/shaggy-parabola.png" src="/img/shaggy-parabola.png"&gt;&lt;/p&gt;
&lt;p&gt;Here are three 5 sided dice. It's no longer going up and down by one step per column. The slope is changing as we go up and down the sides.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;3&lt;/th&gt;
&lt;th style="text-align: left;"&gt;4&lt;/th&gt;
&lt;th style="text-align: left;"&gt;5&lt;/th&gt;
&lt;th style="text-align: left;"&gt;6&lt;/th&gt;
&lt;th style="text-align: left;"&gt;7&lt;/th&gt;
&lt;th style="text-align: left;"&gt;8&lt;/th&gt;
&lt;th style="text-align: left;"&gt;9&lt;/th&gt;
&lt;th style="text-align: left;"&gt;10&lt;/th&gt;
&lt;th style="text-align: left;"&gt;11&lt;/th&gt;
&lt;th style="text-align: left;"&gt;12&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;(1, 1, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 1, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 2, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 2, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 3, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 3, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 3, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 4, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 4, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 4, 4)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 2, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 1, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 2, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 2, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 2, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 4, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 3, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 3, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 1, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 2, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 1, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 1, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 3, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 3, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 2, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 4, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 1, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 3, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 3, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 3, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 2, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 4, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 3, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 1, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 2, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 2, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 1, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 3, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 1, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 3, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 3, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 1, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 4, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 4, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 2, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 2, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 4, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 2, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 1, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(4, 1, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(3, 1, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 4, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 4, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 4, 1)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 4, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 3, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 1, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 1, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(2, 2, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 4, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 4, 2)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 4, 3)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 2, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;(1, 3, 4)&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;td style="text-align: left;"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The notebook has a function to print it for any number of faces and dice. Go crazy if you like, but it quickly becomes illegible.&lt;/p&gt;
&lt;p&gt;Here's the results of three 12 sided dice:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/three-twelves.png" src="/img/three-twelves.png"&gt;&lt;/p&gt;
&lt;p&gt;This isn't a Normal distribution, but it sure looks close to one.   &lt;/p&gt;
&lt;h2&gt;Toast triangles&lt;/h2&gt;
&lt;p&gt;What if we feed the triangular distribution through the &lt;code&gt;sin()&lt;/code&gt; function? To keep the toast analogy going, I guess we're spreading the butter with a sine wave pattern, but changing how hard we're pressing down on the knife to match the triangular distribution -- slow at first, then ramping up, then ramping down.&lt;/p&gt;
&lt;p&gt;Turns out, if we take the sine of the sum of two uniform random variables (defined from the range of -pi to +pi), we'll get the arcsin distribution again! I don't know if that's surprising or not, but there you go.&lt;/p&gt;
&lt;h2&gt;Knowing your limits&lt;/h2&gt;
&lt;p&gt;There's a problem with the toast analogy. (Well, at least one. There may be more, but I ate the evidence.)&lt;/p&gt;
&lt;p&gt;The probability density function of the arcsine distribution looks like this:&lt;/p&gt;
&lt;p&gt;It goes up to infinity at the edges!&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/arcsine-pdf.png" src="/img/arcsine-pdf.png"&gt;&lt;/p&gt;
&lt;p&gt;The derivative of the &lt;code&gt;arcsin&lt;/code&gt; function is &lt;code&gt;1/sqrt(1-x**2)&lt;/code&gt; which goes to infinity as x approaches 0 or 1. That's what gives the arcsine distribution its shape. That also sort of breaks the toast analogy. Are we putting an infinite amount of butter on the bread for an infinetesimal amount of time at the ends of the bread? You can break your brain thinking about that, but we can be confident that we put a finite amount of butter on the toast between any two intervals of time. We're always concerned with the defined amount of area underneath the PDF, not the value at a singular point.&lt;/p&gt;
&lt;p&gt;Here's a histogram of the actual arcsine distribution -- 100,000 sample points put into 1,000 bins:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/arcsine-hist.png" src="/img/arcsine-hist.png"&gt;&lt;/p&gt;
&lt;p&gt;About 9% of the total probability is in the leftmost and rightmost 0.5% of the distribution, so the bins at the edges get really, really tall, but they're also really, really skinny. &lt;/p&gt;
&lt;p&gt;The CDF (area under the curve of the PDF) of the arcsine distribution is well behaved, but its slope goes to infinity at the very edges.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/arcsine-cdf.png" src="/img/arcsine-cdf.png"&gt;&lt;/p&gt;
&lt;h2&gt;One for the road&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;sinc()&lt;/code&gt; function is defined as &lt;code&gt;sin(x)/x&lt;/code&gt;. It doesn't lead to a well-known distribution as far as I know, but it looks cool, like the logo of some aerospace company from the 1970's, so here you go:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/sinc.png" src="/img/sinc.png"&gt;&lt;/p&gt;
&lt;p&gt;Would I buy a Camaro with that painted on the hood? Yes, I would.&lt;/p&gt;
&lt;h2&gt;An arcsine of things to come&lt;/h2&gt;
&lt;p&gt;The arcsine distribution is extremely important in the field of random walks. Say you flip a coin to decide whether to turn north or south every block. How far north or south of where you started will you end up?&lt;/p&gt;
&lt;p&gt;I showed with the hot hand research that our intuitions about randomness are bad. When it comes to random walks, I think we do even worse. Certain &lt;em&gt;sensible&lt;/em&gt; things almost never happen, while &lt;em&gt;weird&lt;/em&gt; things happen all the time, and the arcsine distribution explains a lot of that.&lt;/p&gt;
&lt;h3&gt;References/further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.johndcook.com/blog/2009/02/12/sums-of-uniform-random-values/"&gt;https://www.johndcook.com/blog/2009/02/12/sums-of-uniform-random-values/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jstor.org/stable/2287407"&gt;https://www.jstor.org/stable/2287407&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://archive.org/details/dli.ernet.5666/"&gt;https://archive.org/details/dli.ernet.5666/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="statistics"></category><category term="some educational value"></category></entry><entry><title>Small stakes give you the minimum blues</title><link href="/small-stakes-give-you-the-minimum-blues.html" rel="alternate"></link><published>2025-07-24T10:20:00-10:00</published><updated>2025-07-24T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-07-24:/small-stakes-give-you-the-minimum-blues.html</id><summary type="html">&lt;p&gt;(This is an excerpt from a larger project about sports gambling. Code and early drafts of some of the materials can be found at &lt;a href="https://github.com/csdurfee/book"&gt;https://github.com/csdurfee/book&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=x8nF8L5Fgzc" target="_blank"&gt;&lt;img alt="Spoon, &amp;quot;Small Stakes&amp;quot;" src="https://img.youtube.com/vi/x8nF8L5Fgzc/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I'll be talking about "the public" in this installment, by which I mean the side of a wager that gets the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(This is an excerpt from a larger project about sports gambling. Code and early drafts of some of the materials can be found at &lt;a href="https://github.com/csdurfee/book"&gt;https://github.com/csdurfee/book&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=x8nF8L5Fgzc" target="_blank"&gt;&lt;img alt="Spoon, &amp;quot;Small Stakes&amp;quot;" src="https://img.youtube.com/vi/x8nF8L5Fgzc/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I'll be talking about "the public" in this installment, by which I mean the side of a wager that gets the most number of bets placed on it.&lt;/p&gt;
&lt;p&gt;I talk about the vig a lot without explaining it. It's explained in the book, but the short version is on standard bets, a gambler needs to win at least 52.4% of the time against the spread to break even due to needing to risk $110 to win $100. That $10 difference is the vig -- how the sportsbook makes their money.&lt;/p&gt;
&lt;p&gt;In gambling circles, bets are often framed as &lt;em&gt;Vegas&lt;/em&gt; or &lt;em&gt;the sharps&lt;/em&gt; versus &lt;em&gt;the public&lt;/em&gt;. &lt;em&gt;Sharp&lt;/em&gt; started out as a term for cheaters -- dishonest bookies setting unfair lines, or &lt;em&gt;card sharps&lt;/em&gt; who win thru deception rather than skill. The meaning has changed a bit over time. In modern parlance, a &lt;em&gt;sharp&lt;/em&gt; is someone who wagers on sports as a game of skill, making money over the long term by placing bets with positive expected value. But the negative connotation persists in popular chatter about gambling.&lt;/p&gt;
&lt;p&gt;Say there's a game between the Lakers and the Charlotte Hornets, and the Hornets win against the spread. &lt;em&gt;The public&lt;/em&gt; lost. What degenerate is betting the Hornets? Sharps, that's who. You'd think &lt;em&gt;the public&lt;/em&gt; wouldn't have a problem with &lt;em&gt;the sharps&lt;/em&gt; -- at least someone won money off &lt;em&gt;Vegas&lt;/em&gt; tonight. Without the &lt;em&gt;sharps&lt;/em&gt;, all the money that the public lost would go to Vegas. But &lt;em&gt;Vegas&lt;/em&gt; and &lt;em&gt;sharps&lt;/em&gt; are often conflated together. It's &lt;em&gt;the public&lt;/em&gt; versus everybody.&lt;/p&gt;
&lt;p&gt;It seems unlikely to me that it's always &lt;em&gt;the public&lt;/em&gt; on one side of the bet and &lt;em&gt;sharps&lt;/em&gt; on the other. The public is still right around 50% of the time, right? They can't be drastically worse than a coin flip, so taking the opposite bets can't be drastically better than a coin flip. That means that &lt;em&gt;sharps&lt;/em&gt; are going to agree with &lt;em&gt;the public&lt;/em&gt; at least some of the time. They might &lt;em&gt;fade the public&lt;/em&gt; (bet the opposite side) more often than they agree with the public, but there's probably a fair amount of both.&lt;/p&gt;
&lt;h3&gt;How do bettors do against the spread as the season goes on?&lt;/h3&gt;
&lt;p&gt;Does the public side do better over time? If records against the spread were random and the lines totally fair, we'd expect the public's winning percentage to bounce around pretty close to 50%, spending about as much time on both sides of the line -- sometimes doing a little better than 50%, sometimes a little worse. Over the course of the season, the public's cumulative record against the spread should get closer and closer to 50%, as the sample variance gets smaller.&lt;/p&gt;
&lt;p&gt;Here's the 2024-2025 data. This is the public's winning percentage, graphed as a 100 game moving average:&lt;/p&gt;
&lt;p&gt;&lt;img alt="2024-ma" src="/img/2024-ma.png"&gt;&lt;/p&gt;
&lt;p&gt;The white line is the start of the All-Star break. The public was winning well below 50% of their bets until a surge in the 100 or so games before the break, as we can see on the cumulative graph:&lt;/p&gt;
&lt;p&gt;&lt;img alt="2024-cumu" src="/img/2024-cumu.png"&gt;&lt;/p&gt;
&lt;p&gt;The public ended up going 584-614 on the season. Someone taking the public side of every bet against the closing line would have lost 91.4 units on the season, for a 48.75% winning percentage.&lt;/p&gt;
&lt;p&gt;The yellow line is the break-even point for &lt;em&gt;fading the public&lt;/em&gt; -- taking the non-public side on every bet over the season. Up until that surge before the All Star break, it would've been extremely profitable to do so. Even by the end of the year, the public's win percentage didn't get close to 50%. Someone betting at -105 reduced juice could have made .8 units by fading the public on every single bet.&lt;/p&gt;
&lt;p&gt;The public were 369-388 when betting on the favorite, and 215-226 betting on the underdog. They went 293-311 when the away team won, and 291-303 when the home team won. They were bad no matter how you slice it.&lt;/p&gt;
&lt;p&gt;While that's all super weird, it's only one season. My data source (sportsbookreview.com) only has spotty data for the 2023-24 NBA season, but they do have mostly complete data for 2021-22 and 2022-23. (Nothing before that, unfortunately.)&lt;/p&gt;
&lt;h3&gt;2021-22 season&lt;/h3&gt;
&lt;p&gt;I have data for 1108 out of 1230 regular season games for 2021-22.&lt;/p&gt;
&lt;p&gt;The public went 566-542 on the season, for a loss of 30.2 units, much better than 2024-25.&lt;/p&gt;
&lt;p&gt;Here's the 100 game moving average:&lt;/p&gt;
&lt;p&gt;&lt;img alt="2021-ma" src="/img/2021-ma.png"&gt;&lt;/p&gt;
&lt;p&gt;Except for a dip in early March, the public did consistently fairly well. Not well enough to make money, but better than 50% win percentage.&lt;/p&gt;
&lt;p&gt;On the cumulative graph, while fading the public (yellow line) would have been profitable for the first month or so, the graph spends most of the season over the 50% line. However, it never gets over 52.4%.&lt;/p&gt;
&lt;p&gt;&lt;img alt="2021-cumu" src="/img/2021-cumu.png"&gt;&lt;/p&gt;
&lt;h3&gt;2022-23 season&lt;/h3&gt;
&lt;p&gt;I have data for 1176 off 1230 games in 2022-23.&lt;/p&gt;
&lt;p&gt;The public went 587-589 for the season, for a loss of 61 units on the season. Here's the moving average:&lt;/p&gt;
&lt;p&gt;&lt;img alt="2022-ma" src="/img/2022-ma.png"&gt;&lt;/p&gt;
&lt;p&gt;And the cumulative:&lt;/p&gt;
&lt;p&gt;&lt;img alt="2022-cumu" src="/img/2022-cumu.png"&gt;&lt;/p&gt;
&lt;p&gt;This one is similar to the 2023-24 graph, where the public pretty consistently lost a little bit more the 50% of the time, but not often enough to make fading the public a viable strategy.&lt;/p&gt;
&lt;h3&gt;Are team records against the spread a Martingale?&lt;/h3&gt;
&lt;p&gt;I started to answer this last time, but didn't have time to go deeper. If betting records are random, previous performance gives no information about future performance. Each game is like a coin flip, with equal chances of heads and tails. Teams will have good or bad records against the spread due to chance alone.&lt;/p&gt;
&lt;p&gt;However, I gave some plausible reasons why this might not be the case.&lt;/p&gt;
&lt;p&gt;The simplest way to test this I could think of was comparing records against the spread in the 1st half of the season to the 2nd half of the season. If the records are random, there should be no correlation between 1st half and 2nd half records.&lt;/p&gt;
&lt;p&gt;I found there was a positive correlation between 1st half and 2nd half records in all three seasons I have data for. In 2023-24, the correlation coefficient was .10. In 2022-23, it was .40, and in 2021-22 it was .27. Only 2022023 was statistically significant. Assuming randomness, positive and negative correlation should be equally likely. So all three being positive is suspicious. I definitely can't rule out there being a non-random aspect to records against the spread over time.&lt;/p&gt;
&lt;p&gt;It's not quite good enough for an automated betting strategy, though it's close. Say we track which teams had winning records against the spread over the 1st half of the season, then bet on those teams for the 2nd half of the season. (I didn't bother to filter out the games where teams with winning records play each other, so this analysis isn't perfect.)&lt;/p&gt;
&lt;p&gt;In 2024-25, that would give a record of 297-297 ATS -- can't get more fair than that.&lt;/p&gt;
&lt;p&gt;In 2022-23, it would have gone 279-241, for a profit of 13.9 units at standard vig, and a 53.7% winning percentage.&lt;/p&gt;
&lt;p&gt;In 2021-22, it would have gone 247-225, for a loss of .5 units and a 52.3% winning percentage.&lt;/p&gt;
&lt;p&gt;So, it's definitely not enough to be profitable as a strategy on its own. But for such a simple strategy to be close to profitable in 2/3 years is interesting. &lt;/p&gt;
&lt;p&gt;A gambler needs to win at least 52.4% of the time to break even against the vig. Say they're  picking from a subset of bets that have a 52.3% chance of winning, as the naive strategy achieved in 2021-22. They'd just barely need to do better than flipping a coin to be profitable. That could be much easier than picking from a set of bets with a 50% chance of winning, right?&lt;/p&gt;
&lt;h3&gt;Final thoughts&lt;/h3&gt;
&lt;p&gt;In all three seasons, the public did a little worse in the first half of the season than the second half. In the two most recent seasons, the cumulative winning percentage was below 50% for nearly the whole season.&lt;/p&gt;
&lt;p&gt;That doesn't seem random to me. It makes sense that sportsbooks would offer slightly more favorable odds to the less popular team in order to attract equal money on both sides. It also makes sense that sportsbooks would be happy if the team with more money on it lost over 50% of the time. The difference between the public winning 50% of the time and the public winning 48.5% of the time could be significant on enough betting volume.&lt;/p&gt;
&lt;p&gt;In all three seasons, there was a positive correlation between a team's record against the spread over the first half of the season and the second half. The correlation is strong enough that over 3 seasons, it's almost possible to make money by betting on teams with a good first half record.&lt;/p&gt;
&lt;p&gt;On both points, I don't have nearly enough data to draw grand conclusions about how "the market" operates -- this is just one sportsbook, and an unknown one at that. Yahoo and DraftKings also provide betting percentage data, which would be useful for cross-checking these trends. I'm going to hold off for now, though -- there are too many other interesting things in the world.&lt;/p&gt;</content><category term="sports betting"></category><category term="basketball"></category><category term="your parlay sucks"></category></entry><entry><title>The public wants what the public gets</title><link href="/the-public-wants-what-the-public-gets.html" rel="alternate"></link><published>2025-07-18T10:20:00-10:00</published><updated>2025-07-18T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-07-18:/the-public-wants-what-the-public-gets.html</id><summary type="html">&lt;p&gt;(This is an excerpt from a larger project about sports gambling. Code and early drafts of some of the materials can be found at &lt;a href="https://github.com/csdurfee/book"&gt;https://github.com/csdurfee/book&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=AE1ct5yEuVY" target="_blank"&gt;&lt;img alt="The Jam, &amp;quot;Going Underground&amp;quot;" src="https://img.youtube.com/vi/AE1ct5yEuVY/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Two types of people&lt;/h3&gt;
&lt;p&gt;Lots of sportsbooks publish info on how much &lt;em&gt;action&lt;/em&gt; they've gotten on each side.&lt;/p&gt;
&lt;p&gt;Here's DraftKings':  &lt;a href="https://dknetwork.draftkings.com/draftkings-sportsbook-betting-splits/"&gt;https …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;(This is an excerpt from a larger project about sports gambling. Code and early drafts of some of the materials can be found at &lt;a href="https://github.com/csdurfee/book"&gt;https://github.com/csdurfee/book&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=AE1ct5yEuVY" target="_blank"&gt;&lt;img alt="The Jam, &amp;quot;Going Underground&amp;quot;" src="https://img.youtube.com/vi/AE1ct5yEuVY/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Two types of people&lt;/h3&gt;
&lt;p&gt;Lots of sportsbooks publish info on how much &lt;em&gt;action&lt;/em&gt; they've gotten on each side.&lt;/p&gt;
&lt;p&gt;Here's DraftKings':  &lt;a href="https://dknetwork.draftkings.com/draftkings-sportsbook-betting-splits/"&gt;https://dknetwork.draftkings.com/draftkings-sportsbook-betting-splits/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It's a smart move. It's good for SEO (to the extent that still matters). And I'm sure they get a lot of people who decide to take bets from that page. &lt;/p&gt;
&lt;p&gt;For example, the Pacers were playing Brooklyn the night I wrote this. 27% of the bets were on Brooklyn at +10.5. 73% are on Pacers -10.5.&lt;/p&gt;
&lt;p&gt;Somebody who sees that and decides to make a bet based on that information could bet either way. They could either tell themselves, "Everybody's taking the Pacers, so it must be a good bet" or "Everybody's taking the Pacers, so it must be a bad bet". &lt;/p&gt;
&lt;p&gt;What are those two groups like when they're not betting on basketball, do you think? Do they use the same kind of toothpaste? Watch the same kind of TV shows? Vote the same way?&lt;/p&gt;
&lt;h3&gt;The public gets what the public wants&lt;/h3&gt;
&lt;p&gt;One bit of gambling lore is that there are "public" teams that get bet on more frequently, regardless of the line. Like, your cousin who's a Cowboys fan is going to bet the Cowboys on Thanksgiving regardless of whether it's a fair line or not.  He'd watch the game and root for the Cowboys anyway, but it's a little more fun that way. The Cowboys aren't just a random number generator to him.&lt;/p&gt;
&lt;p&gt;There's a social aspect to gambling now that I imagine didn't exist when it was underground. Lots of gamblers will "follow" bets that other people have placed. If the bet wins, I'm sure it's a cool communal thing to be a part of. But social media can act in opposition to the "wisdom of crowds" -- in places like reddit where users vote content up and down, the conventional wisdom is going to be amplified, and people with minority opinions are going to be suppressed. If well over 90% of sports gamblers lose money long term, the majority opinions are going to be bad.&lt;/p&gt;
&lt;p&gt;I scraped betting percentage data from &lt;a href="https://www.sportsbookreview.com/betting-odds/nba-basketball/"&gt;sportsbookreview&lt;/a&gt; (SBR) for the 2024-5 season. They don't say where they get the betting percentages from. If I had to guess, it would be MGM Grand, their primary source of other data. The SBR numbers seemed to indicate more &lt;em&gt;action&lt;/em&gt; overall than a couple other sources I found -- the betting percentages were closer together. Other sites had games where there's 10% action on one side and 90% on the other, which seems implausible on a large volume of bets. So it's probably a pretty big site, whatever it is.&lt;/p&gt;
&lt;p&gt;As with the data from the previous installment, there are 32 games out of 1230 missing data.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;money_percents&lt;/code&gt; column is the median amount bet on each team. The &lt;code&gt;money_game_winners&lt;/code&gt; column tracks the number of games where that team got the majority of the money bet on their side. Both of these can be taken as indicators of how much teams are favored by the public.&lt;/p&gt;
&lt;p&gt;Here are the teams sorted by money_percents. The teams near the top were less popular with gamblers, the teams at the bottom more popular.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;&lt;/th&gt;
&lt;th style="text-align: right;"&gt;winner&lt;/th&gt;
&lt;th style="text-align: right;"&gt;loser&lt;/th&gt;
&lt;th style="text-align: right;"&gt;ats_win_pct&lt;/th&gt;
&lt;th style="text-align: right;"&gt;money_percents&lt;/th&gt;
&lt;th style="text-align: right;"&gt;money_game_winners&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;New Orleans&lt;/td&gt;
&lt;td style="text-align: right;"&gt;34&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;39.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Charlotte&lt;/td&gt;
&lt;td style="text-align: right;"&gt;36&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;24&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Miami&lt;/td&gt;
&lt;td style="text-align: right;"&gt;39&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;td style="text-align: right;"&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Philadelphia&lt;/td&gt;
&lt;td style="text-align: right;"&gt;26&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Portland&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;58&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Orlando&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;40&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Utah&lt;/td&gt;
&lt;td style="text-align: right;"&gt;39&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Sacramento&lt;/td&gt;
&lt;td style="text-align: right;"&gt;35&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;td style="text-align: right;"&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;L.A. Clippers&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;34&lt;/td&gt;
&lt;td style="text-align: right;"&gt;58&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;27&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;San Antonio&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;31&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Chicago&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;New York&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Phoenix&lt;/td&gt;
&lt;td style="text-align: right;"&gt;29&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;td style="text-align: right;"&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Washington&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;L.A. Lakers&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;59&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Indiana&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Atlanta&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Boston&lt;/td&gt;
&lt;td style="text-align: right;"&gt;39&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Minnesota&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Dallas&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Detroit&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Brooklyn&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;35&lt;/td&gt;
&lt;td style="text-align: right;"&gt;55&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Toronto&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;td style="text-align: right;"&gt;28&lt;/td&gt;
&lt;td style="text-align: right;"&gt;64&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Golden State&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;40&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Houston&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Oklahoma City&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;td style="text-align: right;"&gt;29&lt;/td&gt;
&lt;td style="text-align: right;"&gt;65&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Milwaukee&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;td style="text-align: right;"&gt;56.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;56&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Cleveland&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;59&lt;/td&gt;
&lt;td style="text-align: right;"&gt;57&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Memphis&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;50&lt;/td&gt;
&lt;td style="text-align: right;"&gt;57&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Denver&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;td style="text-align: right;"&gt;58.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;63&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;The public favorites&lt;/h3&gt;
&lt;p&gt;The most popular teams with NBA gamblers were Denver, Cleveland, Memphis, Milwaukee, and Oklahoma City.&lt;/p&gt;
&lt;p&gt;Cleveland, OKC and Memphis were dominant for most of the season.&lt;/p&gt;
&lt;p&gt;Denver and Milwaukee have two of the best and most entertaining players in the league. Both Giannis for Milwaukee and Jokic for Denver are fun to root for. People like to take bets on games that are fun to follow. &lt;/p&gt;
&lt;h3&gt;The ugly dogs&lt;/h3&gt;
&lt;p&gt;The bottom teams were New Orleans, Charlotte, Miami, Philadelphia and Portland. All these teams except for Portland were totall bummers to watch and cheer for this year. They all had injuries and organizational dysfunction that led to wasted seasons. People don't like to take bets on games that are a bummer to follow.&lt;/p&gt;
&lt;h3&gt;Against the spread&lt;/h3&gt;
&lt;p&gt;Here's the same data sorted by record against the spread.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;&lt;/th&gt;
&lt;th style="text-align: right;"&gt;winner&lt;/th&gt;
&lt;th style="text-align: right;"&gt;loser&lt;/th&gt;
&lt;th style="text-align: right;"&gt;ats_win_pct&lt;/th&gt;
&lt;th style="text-align: right;"&gt;money_percents&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Philadelphia&lt;/td&gt;
&lt;td style="text-align: right;"&gt;26&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Phoenix&lt;/td&gt;
&lt;td style="text-align: right;"&gt;29&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Washington&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;New Orleans&lt;/td&gt;
&lt;td style="text-align: right;"&gt;34&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;39.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Sacramento&lt;/td&gt;
&lt;td style="text-align: right;"&gt;35&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Denver&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;td style="text-align: right;"&gt;58.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Dallas&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Charlotte&lt;/td&gt;
&lt;td style="text-align: right;"&gt;36&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Minnesota&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;New York&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Indiana&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Atlanta&lt;/td&gt;
&lt;td style="text-align: right;"&gt;37&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;San Antonio&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Boston&lt;/td&gt;
&lt;td style="text-align: right;"&gt;39&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Miami&lt;/td&gt;
&lt;td style="text-align: right;"&gt;39&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Memphis&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;50&lt;/td&gt;
&lt;td style="text-align: right;"&gt;57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Orlando&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;40&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Utah&lt;/td&gt;
&lt;td style="text-align: right;"&gt;39&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Golden State&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;40&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Detroit&lt;/td&gt;
&lt;td style="text-align: right;"&gt;41&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Chicago&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;52&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Houston&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Milwaukee&lt;/td&gt;
&lt;td style="text-align: right;"&gt;44&lt;/td&gt;
&lt;td style="text-align: right;"&gt;38&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54&lt;/td&gt;
&lt;td style="text-align: right;"&gt;56.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Brooklyn&lt;/td&gt;
&lt;td style="text-align: right;"&gt;42&lt;/td&gt;
&lt;td style="text-align: right;"&gt;35&lt;/td&gt;
&lt;td style="text-align: right;"&gt;55&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;L.A. Clippers&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;34&lt;/td&gt;
&lt;td style="text-align: right;"&gt;58&lt;/td&gt;
&lt;td style="text-align: right;"&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Portland&lt;/td&gt;
&lt;td style="text-align: right;"&gt;45&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;58&lt;/td&gt;
&lt;td style="text-align: right;"&gt;43.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;L.A. Lakers&lt;/td&gt;
&lt;td style="text-align: right;"&gt;48&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;59&lt;/td&gt;
&lt;td style="text-align: right;"&gt;51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Cleveland&lt;/td&gt;
&lt;td style="text-align: right;"&gt;47&lt;/td&gt;
&lt;td style="text-align: right;"&gt;33&lt;/td&gt;
&lt;td style="text-align: right;"&gt;59&lt;/td&gt;
&lt;td style="text-align: right;"&gt;57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Toronto&lt;/td&gt;
&lt;td style="text-align: right;"&gt;49&lt;/td&gt;
&lt;td style="text-align: right;"&gt;28&lt;/td&gt;
&lt;td style="text-align: right;"&gt;64&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Oklahoma City&lt;/td&gt;
&lt;td style="text-align: right;"&gt;53&lt;/td&gt;
&lt;td style="text-align: right;"&gt;29&lt;/td&gt;
&lt;td style="text-align: right;"&gt;65&lt;/td&gt;
&lt;td style="text-align: right;"&gt;54.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Philadelphia, Washington and Phoenix were just as terrible at the sportsbook as they were on the basketball court. OKC and Cleveland had outstanding seasons in both places.&lt;/p&gt;
&lt;p&gt;However, there's only a rough correlation between how good the teams were at actual basketball, and at beating the spread. Minnesota, New York and Denver were in the bottom 10 by winning % against the spread, even though they had good records and were doing their best to win. Toronto and Brooklyn weren't really trying to win a lot of basketball games, but ended up in the top 10.&lt;/p&gt;
&lt;h3&gt;Which teams should the public love and hate?&lt;/h3&gt;
&lt;p&gt;I calculated the amount of units a gambler would win if they bet on each team when they got the majority of the bets.  &lt;code&gt;public_units&lt;/code&gt; is the amount won/lost betting in favor of the team, and &lt;code&gt;fade_units&lt;/code&gt; by betting against them, when they are the public team. (The two values are different because of the vig.)&lt;/p&gt;
&lt;p&gt;Phoenix, Sacramento, Dallas, Denver and Indiana disappointed the public the most.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;&lt;/th&gt;
&lt;th style="text-align: right;"&gt;public_units&lt;/th&gt;
&lt;th style="text-align: right;"&gt;fade_units&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Phoenix&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-16.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;12.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Sacramento&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-14.2&lt;/td&gt;
&lt;td style="text-align: right;"&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Dallas&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-13.6&lt;/td&gt;
&lt;td style="text-align: right;"&gt;9.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Denver&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-12.6&lt;/td&gt;
&lt;td style="text-align: right;"&gt;6.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Indiana&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-12.6&lt;/td&gt;
&lt;td style="text-align: right;"&gt;8.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Atlanta&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-11.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;7.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Utah&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-11.1&lt;/td&gt;
&lt;td style="text-align: right;"&gt;7.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Chicago&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-10.2&lt;/td&gt;
&lt;td style="text-align: right;"&gt;6.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Minnesota&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-9.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;5.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Detroit&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-7.4&lt;/td&gt;
&lt;td style="text-align: right;"&gt;3.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Philadelphia&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-6.7&lt;/td&gt;
&lt;td style="text-align: right;"&gt;3.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;New York&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-6.1&lt;/td&gt;
&lt;td style="text-align: right;"&gt;2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Brooklyn&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-5.2&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Washington&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Boston&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-3.2&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-1.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;New Orleans&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-3.1&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Memphis&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-1.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-3.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Charlotte&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-1.2&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-1.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Miami&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-1&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;San Antonio&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-0.5&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-2.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Orlando&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-0.4&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-2.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Milwaukee&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1.4&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Golden State&lt;/td&gt;
&lt;td style="text-align: right;"&gt;2.7&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-7.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;L.A. Lakers&lt;/td&gt;
&lt;td style="text-align: right;"&gt;4.2&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-8.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Houston&lt;/td&gt;
&lt;td style="text-align: right;"&gt;4.9&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-9.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Cleveland&lt;/td&gt;
&lt;td style="text-align: right;"&gt;6.8&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-12.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Portland&lt;/td&gt;
&lt;td style="text-align: right;"&gt;10.3&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-12.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Toronto&lt;/td&gt;
&lt;td style="text-align: right;"&gt;11.3&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;L.A. Clippers&lt;/td&gt;
&lt;td style="text-align: right;"&gt;12.3&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;Oklahoma City&lt;/td&gt;
&lt;td style="text-align: right;"&gt;18.3&lt;/td&gt;
&lt;td style="text-align: right;"&gt;-23.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This is a pretty random list of teams, in both directions. It's a good illustration that gamblingball is different from basketball. It's not clear whether gamblingball is a game with an element of skill, or if it's all chance.&lt;/p&gt;
&lt;h3&gt;Are records against the spread due to chance?&lt;/h3&gt;
&lt;p&gt;If we assume that all variations are due to randomess, each game should be a coin flip whether the underdog or favorite wins against the spread.&lt;/p&gt;
&lt;p&gt;Calculating exact odds using the binomial distribution, 94% of NBA teams should have between 33 and 49 wins against the spread over an 82 game season.&lt;/p&gt;
&lt;p&gt;We'd expect 2 teams to be outside that range, and there are 3. Philadelphia went 26-52 in 78 games we have data for. Even if they won the other 4 games that are missing data, they'd only have 30 wins. So that record was definitely an outlier, but overall the season was about what we'd expect based on chance.&lt;/p&gt;
&lt;p&gt;I find it very believable that some teams are more likely to have a winning record against the spread, because they are underestimated by the handicappers or the betting public. They end up getting lines that are too generous, and thus do better than expected against the spread. Toronto could be an example of that. They were bad, but they weren't really as bad as people thought.&lt;/p&gt;
&lt;p&gt;Other teams could be inherently worse against the spread, as well. Perhaps they are super popular to bet on, so the lines tend to move against them -- a &lt;em&gt;public team&lt;/em&gt;. Or perhaps gamblers and sportsbooks overvalue the team -- the conventional wisdom is that they'll be good when they're not. That definitely describes Philadelphia and Phoenix.&lt;/p&gt;
&lt;p&gt;In both cases, &lt;em&gt;the teams themselves&lt;/em&gt; aren't necessarily doing anything to be better or worse against the spread than an average team would be. It's about the perceptions of the bookmakers and gamblers.&lt;/p&gt;
&lt;h3&gt;Do gamblers follow the record against the spread?&lt;/h3&gt;
&lt;p&gt;If a team's record against the spread is due solely to random error, then we've got a &lt;a href="/LeSimulation.html"&gt;LeMartingale&lt;/a&gt; on our hands. The current record would have no bearing on the future record. So gamblers shouldn't factor it in when deciding to take a bet or not.&lt;/p&gt;
&lt;p&gt;By the end of the season, there was a significant correlation between money percents and win percentage against the spread. I wanted to see how that might've changed over time. So I generated the table shown above for every single day of the season, and calculated the Spearman rank correlation on that day.  Here's what that looks like over time:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/money-ats-win-pct.png" src="/img/money-ats-win-pct.png"&gt;&lt;/p&gt;
&lt;p&gt;The money percentages are cumulative,the mean of all games in the season that have come before -- it's not showing gamblers' betting behavior on a particular day, compared to records against the spread on that day. The graph is a lot smoother that way, but we're losing something.&lt;/p&gt;
&lt;p&gt;It also doesn't show whether records against the spread are a Martingale or not. The correlation between betting percentages and win records increases over time, but that doesn't mean this is because gamblers are behaving &lt;em&gt;rationally&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;The jump in correlation around mid-Februrary corresponds to the All-Star break, which is curious.&lt;/p&gt;
&lt;p&gt;Stay tuned; I'll have more on this.&lt;/p&gt;</content><category term="sports betting"></category><category term="basketball"></category><category term="your parlay sucks"></category></entry><entry><title>Last fair deal in the country</title><link href="/last-fair-deal-in-the-country.html" rel="alternate"></link><published>2025-07-17T10:20:00-10:00</published><updated>2025-07-17T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-07-17:/last-fair-deal-in-the-country.html</id><summary type="html">&lt;p&gt;(This is an excerpt from a larger project about sports gambling. Code used, and early drafts of some of the chapters can be found at &lt;a href="https://github.com/csdurfee/book"&gt;https://github.com/csdurfee/book&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=0UGvyPnuLtQ" target="_blank"&gt;&lt;img alt="The Grateful Dead, &amp;quot;Loser&amp;quot;" src="https://img.youtube.com/vi/0UGvyPnuLtQ/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Efficiency of betting markets&lt;/h2&gt;
&lt;p&gt;The efficient market hypothesis says that given enough time and competition, free markets are able to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(This is an excerpt from a larger project about sports gambling. Code used, and early drafts of some of the chapters can be found at &lt;a href="https://github.com/csdurfee/book"&gt;https://github.com/csdurfee/book&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=0UGvyPnuLtQ" target="_blank"&gt;&lt;img alt="The Grateful Dead, &amp;quot;Loser&amp;quot;" src="https://img.youtube.com/vi/0UGvyPnuLtQ/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Efficiency of betting markets&lt;/h2&gt;
&lt;p&gt;The efficient market hypothesis says that given enough time and competition, free markets are able to establish the correct price for a commodity. In the case of sports betting, we could think of it as the price of a money line bet. &lt;/p&gt;
&lt;p&gt;On a money line bet, you are betting on who will win the game straight up. You get a smaller payout for betting on the favorite, and a larger payout betting on the underdog. If the money line is negative, that's how much money you have to risk in order to win $100. For example, -200 indicates you have to risk $200 to win $100. If it is positive, that's how much money you win if you risk $100. If it sounds like a bad way to write the odds, you're correct.&lt;/p&gt;
&lt;p&gt;A market maker will respond to an imbalance in bets by adjusting the price. If CLE -300 is a good value, people will rationally want to take it, driving the price up to, say -400. If it is a bad value, people will rationally want to take the other side and the price might go down to -200. These rational actors will collectively push the price towards the best possible estimate that humans can make. It serves as a sort of collective intelligence.&lt;/p&gt;
&lt;p&gt;In the first installment, I showed that humans are irrational when it comes to sports betting, so I was skeptical of how good, or fair, the lines could be. Could I find proof of this collective intelligence in action? Are there any obvious market inefficiencies?&lt;/p&gt;
&lt;h3&gt;The data &amp;amp; stuff to know&lt;/h3&gt;
&lt;p&gt;Stats are from the NBA season. I screen-scraped the data from &lt;a href="https://www.sportsbookreview.com/betting-odds/nba-basketball/"&gt;sportsbookreview.com&lt;/a&gt;. All data is from the MGM Grand. Unfortunately, some data is missing from around Christmastime, and a few random days in between. 32 games are missing from the data set out of 1230 total, 2.6% of all games. These are games that don't appear on sportsbookreview's website, or have incomplete data on there.&lt;/p&gt;
&lt;p&gt;This is an analysis of the MGM Grand's NBA lines for 2025. It's not a comprehensive guide to how the lines work.&lt;/p&gt;
&lt;p&gt;There are always two lines on each game, one for the home team and one for the away team. Each side may have different vigs. Say for instance Bucks @ Pacers starts out at IND +3.5 -110/MIL -3.5 -110. It could close at IND +3.5 -115/MIL -3.5 -105. So it costs more to bet on the Pacers, but the actual line didn't move.  I'm mostly ignoring that, but will point out when it's relevant.&lt;/p&gt;
&lt;p&gt;"Line" and "spread" mean the same thing.&lt;/p&gt;
&lt;p&gt;"Reduced juice" means risking -105 or -106 instead of the usual -110 to win 100. A "unit" is a gambler's standard betting size. "4.1 units of profit" would mean +$410 for a gambler betting $100 a game. Both are explained in much more detail in the book.&lt;/p&gt;
&lt;h3&gt;A note about pushes&lt;/h3&gt;
&lt;p&gt;When the final score agrees with the line exactly, neither side of the bet can be declared a winner. This is called a push. The bet is cancelled and everybody gets their money back. The casino makes nothing.&lt;/p&gt;
&lt;p&gt;The MGM Grand always keeps point spreads on the half point (eg +6.5 or +7.5 rather than +7) so that they will never push. I don't think it's a bad policy, and I'm surprised more sportsbooks don't do it. The sportsbooks know how good their customers are at betting, so they should probably shade the point spread a half a point towards the side of the bet that has the less savvy bettors on it. (This assumes the sportsbook can identify and ban arbitrage gamblers, but more about that in the book.) &lt;/p&gt;
&lt;h3&gt;Analysis&lt;/h3&gt;
&lt;p&gt;If there is a wisdom of crowds, the final lines should be more accurate than the opening lines. Are they?&lt;/p&gt;
&lt;p&gt;My code calculates the difference between the final score and the line, called the error.  Because the MGM's lines always end in a half point, that means the error is going to be artificially high -- there will never be a game where it is exactly zero.&lt;/p&gt;
&lt;p&gt;The opening and closing lines are a set of predictions. The smaller the difference between the line and reality, the better the prediction. &lt;a href="https://en.wikipedia.org/wiki/Mean_squared_error"&gt;Mean Squared Error&lt;/a&gt; is a standard way to compare two prediction systems in statistics and machine learning.&lt;/p&gt;
&lt;p&gt;The MSE for the opening lines is 191.06, and the closing lines is 184.8. So we can say that in aggregate, the closing lines are more accurate than the opening lines.&lt;/p&gt;
&lt;p&gt;MSE can't tell us how good the closing lines are, though, just that one set of predictions is better than another set. It's a relative measure, not an absolute one. We're squaring the error, so the MSE will always be positive. The errors in one direction don't cancel out ones in the other direction. &lt;/p&gt;
&lt;p&gt;Let's look at how far the lines were off by. the Os are the opening lines, and X's are the closing lines. If the &lt;em&gt;X&lt;/em&gt; is closer to the center line than the &lt;em&gt;O&lt;/em&gt;, the market action made the line more accurate. I've plotted a random sample of 300 games to make the plot more readable.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/scatter-mess.png" src="/img/scatter-mess.png"&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, that doesn't really show us much about how or when the closing lines are better than the opening ones. &lt;/p&gt;
&lt;h3&gt;Adam Smith, Handicapper&lt;/h3&gt;
&lt;p&gt;When were the closing lines more accurate than the opening lines?&lt;/p&gt;
&lt;p&gt;Closing lines better:    467  &lt;br&gt;
Opening lines better:    384
Tied:                    347    &lt;/p&gt;
&lt;p&gt;If the free market were a handicapper, and we interpreted the line movements as a bet on one side, they would have a 54.88% winning percentage (and 347 pushes).&lt;/p&gt;
&lt;p&gt;While that's a respectable win percentage for a human trying to beat the spread, I was expecting better from the free market. The market only being right 55% of the time holds true for a couple of previous seasons I have looked at as well. NBA betting, as a market, is not very efficient.&lt;/p&gt;
&lt;p&gt;There are good reasons for that. Sportsbooks that set the opening lines aren't trying that hard to be accurate. It's just a first guess. Only a tiny percentage of money is wagered at the opening line number. However, there are good reasons why lines tend not to move very much, even when the opening line is a bad one. For an in-depth explanation, check out &lt;em&gt;The Logic of Sports Betting&lt;/em&gt;, by Miller and Davidow.&lt;/p&gt;
&lt;h3&gt;The myth of closing line value&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.pinnacle.com/betting-resources/en/betting-strategy/using-the-closing-line-to-test-your-skill-in-betting/7e6jwjm5ykejuwkq"&gt;The conventional wisdom&lt;/a&gt; is that sports betting markets are efficient, so that the only way to make money over the long run is by doing better than the closing lines, picking up on any flaws in the opening lines before the market eliminates them. Anyone else can only make a profit due to chance. From this perspective, the right way to measure a handicapper's skill is how their picks compare to the closing line. Say the opening line is Nuggets -3, and I take the bet at that number. The closing line is Nuggets -6. Then I captured 3 points of value against the closing line. This is known as closing line value (CLV). (We can figure out how valuable those 3 points are, and I show how in the book.)&lt;/p&gt;
&lt;p&gt;Beating the closing line might be positively correlated with higher profits when analyzing betting records of touts -- people who sell betting picks for money. But when the market is wrong 45% of the time, focusing too much on CLV seems like a bad idea. There's no good reason to believe that a gambler is destined to lose money by picking against the closing lines. What if their strategy is to mostly bet against the prevailing wisdom on the 45% of games where the market is wrong?&lt;/p&gt;
&lt;p&gt;CLV is a prime example of &lt;a href="https://en.wikipedia.org/wiki/Goodhart's_law"&gt;Goodhart's Law&lt;/a&gt;. As a measure of a handicapper's skill, it's probably fine (though not ideal). But it shouldn't be the target. A gambler shouldn't make picks explicitly to capture as much CLV as possible.&lt;/p&gt;
&lt;p&gt;Say the opening line is Nuggets -3 against the Timberwolves. I like the Nuggets in this matchup, but I think the public will go for the Timberwolves and it will finish at Nuggets -1/Timberwolves +1.&lt;/p&gt;
&lt;p&gt;If I was trying to capture as much CLV as possible on this bet, I should take the Timberwolves +3 on the opening line, even though that's not the side I actually like! &lt;/p&gt;
&lt;p&gt;If I was trying to actually win the bet, I should take the Nuggets at the closing line, hoping maybe I can get Nuggets -1 or even Nuggets +1. I can never get positive CLV on the Nuggets, because the market was wrong about them. Not me, the market!&lt;/p&gt;
&lt;p&gt;CLV gets described as being the best way to test a handicapper's skill, but it's obviously non-optimal. Maybe it's the contrarian in me, but Opening Line Value -- identifying bets where the market is going to be wrong, and waiting till the last minute to place the bet -- is more impressive.&lt;/p&gt;
&lt;p&gt;The best way to test a handicapper is to have them write out what they think the lines should be, rather than making a binary decision about somebody else's line (favorite or underdog). If a handicapper's lines are closer to the truth than the closing lines, they are good at handicapping. Looking at what bets they took is only a secondary signal of that. If they took Nuggets -7, is it because they thought the true line should be Nuggets -8, or Nuggets -12? &lt;/p&gt;
&lt;h3&gt;When the line doesn't move&lt;/h3&gt;
&lt;p&gt;Setting aside why the market moves in the wrong direction 45% of the time, I'm curious about the games where the spread didn't move at all. Maybe those lines were perfect as-is? If so, we'd expect to see equal splits of home vs. away winners, and underdog vs. favorite winners.  There shouldn't be any bias to those games. The free market is essentially labelling these the pinnacle of the handicapper's art, impossible to be improved upon. &lt;/p&gt;
&lt;p&gt;The difference between the predicted outcome (the line) and the actual outcome is a combination of how much the line maker got it wrong, plus random variation. So the games where the line didn't move should be totally random, right?&lt;/p&gt;
&lt;p&gt;They're not. If we look at games where the line didn't move, the away team went 184-163 in those games. Someone betting the away team in every game where the line didn't move would win 53% of their bets, for 4.7 units of profit at full vig, or 11.2 units of profit at &lt;em&gt;reduced juice&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There's also a bias towards underdogs, who went 186-161 in this situation. Always taking the underdog would give a 53.6% winning percentage, for 8.9 units at full vig, or 15.3 units at reduced juice.&lt;/p&gt;
&lt;p&gt;There's an even bigger bias if we combine the two. Away underdogs went 122-92 in these games, which is a 55.2% winning percentage, for 13.1 units of profit at full vig, and 17.1 at reduced juice.&lt;/p&gt;
&lt;p&gt;None of these results are statistically significant, but they are very :thinking_face_emoji:&lt;/p&gt;
&lt;h3&gt;About the vig&lt;/h3&gt;
&lt;p&gt;When the vig is imbalanced, the side with the higher vig should be more likely to win, because they're winning less money in return. Moving the vig from -110 to -115 is a way for the bookmaker to discourage bets on one side without moving the line. Likewise moving it to -105 is a way to encourage bets on that side.&lt;/p&gt;
&lt;p&gt;Since the MGM Grand always keeps their lines on the half point, we'd expect them to adjust the vig often rather than change the spread. They do for most of the games where they didn't move the lines, but 39% of the time the vig stays at -110.&lt;/p&gt;
&lt;p&gt;If we break down the games where the line didn't move by vig, the underdogs went 62-43 when the vig was high (-115), 74-62 when the vig was at the standard level (-110), and 50-56 at low vig (-105).&lt;/p&gt;
&lt;p&gt;Someone taking the underdogs when the line doesn't move, and the vig is -110 or -115, would've gone 136-105 this season, a 56.4% winning percentage, and around 18 units of profit (factoring in the additional -115 vig on some bets).&lt;/p&gt;
&lt;p&gt;Now, the strategy is pretty convoluted, and won't necessarily hold for future seasons, but it's definitely evidence there could be irrational factors at work in the market. It certainly doesn't show the market to be the well oiled machine that Closing Line Value assumes it is.&lt;/p&gt;
&lt;h3&gt;Must love dogs&lt;/h3&gt;
&lt;p&gt;Winners ended up being pretty evenly divided between favorites and underdogs by the end of the season, but underdogs were way ahead for most of the year.  &lt;/p&gt;
&lt;p&gt;Betting every single underdog against the spread over the first quarter of the season would've been fairly profitable -- a 165-136 record (54.8% winning percentage), and 15.4 units profit at full vig. People betting favorites got killed at the beginning of the season.&lt;/p&gt;
&lt;p&gt;Dogs and favorites were basically even through the middle half of the season, before favorites finished off 167-144 (53.7% win percentage) to even things out.&lt;/p&gt;
&lt;p&gt;Here's a plot of the winning percentage of favorites over the course of the season. I skipped the first 50 games because of noise. The yellow line represents the winning percentage necessary for betting all underdogs to be profitable (at standard vig). That happens when the favorites win less than 47.6% of the time (which means underdogs win more than 52.4% of the time.)&lt;/p&gt;
&lt;p&gt;It wasn't until the last month of the season that blindly betting all underdogs started being a losing proposition, even factoring in the vig.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/wp-vs-gameno.png" src="/img/wp-vs-gameno.png"&gt;&lt;/p&gt;
&lt;h3&gt;Did the lines improve over time?&lt;/h3&gt;
&lt;p&gt;I was curious if there was evidence that the errors were getting smaller, or more predictable over time.&lt;/p&gt;
&lt;p&gt;The raw errors are too noisy to see any sort of pattern:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/err-vs-line.png" src="/img/err-vs-line.png"&gt;&lt;/p&gt;
&lt;p&gt;This is a plot of the 100 game moving average of the absolute error of the closing line. I don't see any trends to suggest the lines got more accurate with time.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/closing-line-err.png" src="/img/closing-line-err.png"&gt;&lt;/p&gt;
&lt;p&gt;The size of the error against the closing line isn't the ideal metric, because not all points are created equal -- the higher the line, the less surprising the error. (I'm going to skip discussing that for now, but it's explained in the book.)&lt;/p&gt;
&lt;h3&gt;Did the lines change over time?&lt;/h3&gt;
&lt;p&gt;I wondered whether the size of the lines changed over time -- did the games get more or less competitive over the course of the season?&lt;/p&gt;
&lt;p&gt;This is a 100 game moving average of the average size of the spread. As we can see, the lines did get bigger near the end of the year.&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/spread-over-time.png" src="/img/spread-over-time.png"&gt;&lt;/p&gt;
&lt;p&gt;It's possible the trend is due to scheduling, but the change at the end seems significant -- teams tend to give up near the end of the year. Bad teams want to be as bad as possible in order to get the best odds in the NBA draft, so they're not that competitive.&lt;/p&gt;
&lt;h3&gt;What type of games are affected by line movement?&lt;/h3&gt;
&lt;p&gt;There were 130 games where the winner flipped from the favorite to the underdog, or the underdog to the favorite, because of the line movement. In other words, these are games where either side could have won the bet, depending on whether you took the opening line or the closing line.&lt;/p&gt;
&lt;p&gt;These games were perfectly balanced -- 65 times, the favorite won (vs the closing line); 65 times the underdog won.&lt;/p&gt;
&lt;p&gt;What about games where the spread was extremely accurate (off by 3 points or less)? Underdogs went 138-121 in those games (53.2%).&lt;/p&gt;
&lt;p&gt;The difference is more dramatic in games where the line was off by 1 point or less. The underdogs went 56-33 (63% win percentage). Of course, there's no way to use that as a betting strategy since we can't identify these games before the fact, but it does show a small potential bias in favor of underdogs. &lt;/p&gt;
&lt;h3&gt;What would "perfect" lines even look like?&lt;/h3&gt;
&lt;p&gt;It's rare to see NBA lines that are bigger than +15/-15 points. There were 15 this season, about 4.4% of all games. That's around one NBA game a week with a line that high.&lt;/p&gt;
&lt;p&gt;By contrast, 31% of NBA games end with a score differential of over 15 points. That's 7x more often, roughly one game a day.&lt;/p&gt;
&lt;p&gt;The lines really shouldn't be as large as the final score differential, because they are an estimate of the mean outcome of the game. If the Celtics beat the Raptors by 54 points, that doesn't mean the line &lt;em&gt;should&lt;/em&gt; have been Celtics -54. The Celtics and Raptors played 4 times last season (data taken from &lt;a href="https://www.basketball-reference.com/teams/TOR/2025_games.html"&gt;basketball-reference&lt;/a&gt;). I'm going to ignore home court advantage -- imagine these are played at a neutral gym. The first game, Boston won by 3. The second, Boston won by 54. The third game, the Raptors won by 13. The last game, Boston won by 10.&lt;/p&gt;
&lt;p&gt;Boston won by an average of 13.5 points, so BOS -13.5 would be a reasonable line for all four games, as that's the best estimate we can make of their difference in skill. Only 1 of the 4 games ended up close to that line. For the other 3 games, the error was at least 10 points. And Boston -- despite being the better team -- would have gone 1-3 against the spread. If the line for all four games was BOS -9.5, they would have gone 2-2, but the error would stukk be 44.5 points on the second game, and 23.5 on the third one.&lt;/p&gt;
&lt;p&gt;The actual outcomes might be all over the place, but the spread isn't meant to predict the actual outcome, just the point where both sides are equally likely to win the bet. &lt;/p&gt;
&lt;p&gt;Here's a histogram of the spreads (for the away team) overlaid on a histogram of the errors against the spread:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/spread-vs-score-diff.png" src="/img/spread-vs-score-diff.png"&gt;&lt;/p&gt;
&lt;p&gt;If we look at just the score differential, we can stick a bell curve over the top and it looks pretty normal:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/score-diff-normal.png" src="/img/score-diff-normal.png"&gt;&lt;/p&gt;
&lt;h3&gt;Simulating games from the spreads&lt;/h3&gt;
&lt;p&gt;The problem is, these aren't outcomes from one distribution. Every game is essentially a sample from a different distribution. Each game has a different mean (the spread, or rather the ideal version of it) and a different variance (how predictable games are between the two teams). Combining them all together, the results end up looking kinda normal (because a lot of things do).&lt;/p&gt;
&lt;p&gt;I decided to simulate the entire season to show how the point differentials are going to be much bigger than the original lines.&lt;/p&gt;
&lt;p&gt;I simulated every game by sampling from a normal distribution with the mean set to that game's spread, and the variance equal to the sample variance of all games that season with that spread. &lt;/p&gt;
&lt;p&gt;Here's how they match up:&lt;/p&gt;
&lt;p&gt;&lt;img alt="/img/point-differential.png" src="/img/point-differential.png"&gt;&lt;/p&gt;
&lt;p&gt;I know that's a pretty rough simulation. There's some weirdness in the middle. NBA games never end in a tie, and they end in a one point difference less often than expected due to tactical reasons, so there's a little notch right in the center of the green curve. If a team is down one, they foul the other team and hope they miss at least one of their free throws. There's also more simulated games than I would expect that end with a differential of +1 or -1. There very well may be a bug in my code -- it is in the "ep 2 LAST FAIR DEAL.ipynb" notebook. So there's a big discrepancy in the middle. But the spread of the data is the same, which is the main thing I'm trying to show.&lt;/p&gt;
&lt;p&gt;Hopefully the simulation shows that the lines shouldn't be bigger than they are, even though they are frequently off by many multiples compared to the final result. If the line is Dallas -3 and the other team wins by 27, that doesn't mean the line was off by 30 points. The line is meant to be an estimate of the mean outcome, if the teams played each other a large number of times. We only ever see one sample, though, and a lot of times it is far from the mean.&lt;/p&gt;</content><category term="sports betting"></category><category term="basketball"></category><category term="your parlay sucks"></category></entry><entry><title>Cool Parlay, Bro</title><link href="/cool-parlay-bro.html" rel="alternate"></link><published>2025-07-16T10:20:00-10:00</published><updated>2025-07-16T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-07-16:/cool-parlay-bro.html</id><summary type="html">&lt;p&gt;(This is an excerpt from my book about sports gambling. Code and early drafts of some of the chapters can be found at &lt;a href="https://github.com/csdurfee/book"&gt;https://github.com/csdurfee/book&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Sportsbooks have many ways of encouraging people to lose their money as quickly and efficiently as possible. One of the best ways …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(This is an excerpt from my book about sports gambling. Code and early drafts of some of the chapters can be found at &lt;a href="https://github.com/csdurfee/book"&gt;https://github.com/csdurfee/book&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Sportsbooks have many ways of encouraging people to lose their money as quickly and efficiently as possible. One of the best ways to do this is a type of bet called the parlay. "Parlez" means "to talk" in French, so it's no surprise dudes always want to talk about them online.&lt;/p&gt;
&lt;p&gt;The idea behind a parlay is that you can bet on multiple events at once and if they all win, you make a nice profit, otherwise you lose. On a technical level, if the first bet on the parlay wins, the winnings are immediately placed on the second bet in the parlay, if that wins, it rolls over to the third bet, and so on. It's a sequence of bets, with the stakes going up with each bet. The individual bets in the parlay are known as "legs".   &lt;/p&gt;
&lt;p&gt;I'm going to keep asking this question: why would they be offering this bet if it was good for you?  Parlays might be more fun, but that just means they found a way to get you to part with your money easier, which sounds like a bad thing.&lt;/p&gt;
&lt;p&gt;We can compare different bets by using Expected Value (EV). EV is the weighted average of all the possible outcomes. If the expected value is positive, we will make money over the long run; if it's negative, we will lose money. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.vegasinsider.com/parlay-calculator/"&gt;The traditional payout on a 4 team parlay is 10:1&lt;/a&gt;. What is the expected value of such a play? is it higher or lower than taking the individual bets?&lt;/p&gt;
&lt;p&gt;It's easy to grind the math on this one, and see which option is better. I can't say "make us more money" because both types of bets are guaranteed losers without some sort of edge.&lt;/p&gt;
&lt;p&gt;Parlays are such a bad type of bet on the surface that to understand them, I have to give a little taste of parlay culture first.&lt;/p&gt;
&lt;h3&gt;Nephew Doug&lt;/h3&gt;
&lt;p&gt;Say you want to place some bets. You just learned about betting on sports, so as a newbie you're trying to learn from experts by listening to gambling podcasts. These guys have been gambling for decades. Surely they must know what's up. Their wisdom will give you the edge for sure. Surely they will keep you from making costly mistakes.&lt;/p&gt;
&lt;p&gt;You've listened to Nephew Doug's podcast, and wrote down his Locks of the Week. You're ready to enter them into your betting app, which has been hand-optimized to be as much of a dopamine and money sink as possible.&lt;/p&gt;
&lt;p&gt;Because you listen every week, you know Nephew Doug has been burdened by the Gods with the gift of prophecy. Just ask him. He's like a modern day Cassandra, only it's about how the Cowboys are always going to suck. &lt;/p&gt;
&lt;p&gt;Now, the Gods like a little competition. The Olympics were invented as a religious ceremony in their honor, after all. But they're not above making a call from on high to nudge the result a little bit. Yes, Zeus is definitely a Chiefs fan.&lt;/p&gt;
&lt;p&gt;So you believe ahead of time Nephew Doug's picks will win 55% of the time. Which way of betting these picks will bring you the most money in the long run?&lt;/p&gt;
&lt;p&gt;1) "throw 'em all in a 4 team parlay" like Doug and his buddy Jorts Guy do  &lt;br&gt;
2) randomly choose 3 of Nephew Doug's picks and bet them individually. Don't do anything with the 4th one.&lt;/p&gt;
&lt;p&gt;Maybe option 2 seems insane to you. But let's game it out. &lt;/p&gt;
&lt;p&gt;You listen to Nephew Doug, but I don't. My assumption would be this guy is no better than a coin flip -- he only wins 50% of the time, or close to it. Parlays at old school casinos pay at 10:1 and online sportsbooks pay 12.28:1. Let's see how that works out at 10:1 payout, the ones Jorts Guy and Nephew Doug were cutting their teeth on back in the day.&lt;/p&gt;
&lt;p&gt;There are two ways to do the comparison. We could bet $100 on the parlay, and compare to putting $25 on each leg. Or we could compare $100 on the parlay to $100 on each leg.&lt;/p&gt;
&lt;p&gt;Neither way of comparing is entirely fair, though, because the stakes increase throughout each leg of the parlay. If a gambler bets $100 on a 4 team parlay, they're risking $100 on the first leg. Assuming they keep winning, they're risking $190 on the 2nd leg, $300ish dollars on the 3rd leg, and $600ish dollars on the 4th leg. &lt;/p&gt;
&lt;p&gt;For each leg of the parlay, the gambler should consider the risk of losing out on $600 if they took a 3 team parlay and it won. Risking $100 on the 4 leg parlay is sort of like taking 4 different $600 bets, because each one could cost the gambler that much if it loses.&lt;/p&gt;
&lt;p&gt;I will be comparing risking $100 on the parlay versus $25 on each of the legs.&lt;/p&gt;
&lt;h3&gt;7x worse&lt;/h3&gt;
&lt;p&gt;This difference only matters for bettors with a high degree of skill. For the beginner, who we can reasonably assume will no better than a coin flip, the parlay is always a worse option. Almost 7 times worse. The parlays lose about 30% per bet, versus 4.5% for the straight bets.&lt;/p&gt;
&lt;p&gt;Yikes. Maybe parlays are fun, but it's like blowing the whole week's vig budget on Sunday when compared to taking one regular bet a day.&lt;/p&gt;
&lt;p&gt;Even a stretch of good luck is going to get swallowed up real fast if you're losing 30% of the stake on average. These types of parlays are a sadness machine.&lt;/p&gt;
&lt;h3&gt;Partially blessed&lt;/h3&gt;
&lt;p&gt;What if Nephew Doug truly has been partially blessed by the Gods, and can beat the lines 55% of the time? That's pretty good. Only a small percentage of sports bettors can achieve that, in my research.&lt;/p&gt;
&lt;p&gt;The gambler should turn a profit either way, but maybe parlays offer a better return? &lt;/p&gt;
&lt;p&gt;The parlays have an expected return of +0.66%, versus +5% for the straight bets. The straight bets make 7.6x as much money.&lt;/p&gt;
&lt;p&gt;OK, what about if we just don't play the 4th bet? We will bet on the first three legs, and don't play the 4th one. We put the $25 for the fourth bet in our piggy bank and earn a 0% interest rate.&lt;/p&gt;
&lt;p&gt;We're throwing out a bet with positive expected value, and risking angering the Gods by ignoring their chosen sports prophet, Nephew Doug. Perhaps that will tilt things in the parlay's favor.&lt;/p&gt;
&lt;p&gt;Nope! The straight bets have a return of +3.75%, which is still 5.7x better than the parlays.&lt;/p&gt;
&lt;p&gt;Finally, let's say we flip a coin to decide the 4th bet. It will only win 50% of the time, which means it's a guaranteed loser because of the vig -- you win less than you have to risk. (There is much more about the vig in the book.)&lt;/p&gt;
&lt;p&gt;Nope! The coin flip hurts our profitability, but we're still clearing +2.6%, which is 4x better than the parlays. We'd have to do 2 of 4 bets by coin flip for the parlays to be more profitable.&lt;/p&gt;
&lt;p&gt;To be fair, 55% is just &lt;em&gt;barely&lt;/em&gt; profitable for an old-school parlay. The profitability increases exponentially as the win rate goes up. There is a win rate where parlays would make more money than the straight bets. If you win 100% of the time, the parlay is definitely a better deal, right? 10x profits taking the parlay versus 4x taking the original bets. &lt;/p&gt;
&lt;p&gt;Successful handicappers who sell their picks on the internet are only winning around 55% of the time. If you have to do as well at something as people who do it for a living just to break even, that's not a great plan.&lt;/p&gt;
&lt;h3&gt;Online Parlays&lt;/h3&gt;
&lt;p&gt;Online 4 leg parlays pay out $1228 per $100 risked, which make them a little less bad. However, they're still way worse for the average gambler than taking the straight bets. At a 50% win rate, online parlays have an expected return of -17%, versus -4.5% for the straight bets. So they're 3.7x worse. They're half as bad as the old school parlays, but still terrible.&lt;/p&gt;
&lt;p&gt;That $1228.33 payout for online parlays was chosen deliberately. It means that online parlays have the same break-even point as the individual bets (at standard vig) -- winning 52.4% of the individual bets. Because parlay profits climb exponentially, that means a skilled bettor with a 55% win rate will have a much higher EV with the parlays. They will have a +21.6% rate of return, versus +5%.&lt;/p&gt;
&lt;h3&gt;EV doesn't describe the range of outcomes&lt;/h3&gt;
&lt;p&gt;Expected Value is a good way of determining whether you can make money taking a certain type of bet, but it doesn't describe the range of possible outcomes.  With parlays, a lot of those outcomes are bad, even for a gambler with enough skill to make them more profitable on paper.&lt;/p&gt;
&lt;p&gt;Simulations are great in this sort of situation, because they can convey the range of possible outcomes in a way EV can't.  I simulated 200 individual bets versus 50 parlays, and ran that 10,000 times. Our virtual gambler wins 55% of the time, and bets $100 on parlays, $25 on each individual bet.&lt;/p&gt;
&lt;p&gt;The individual bets made more money (or lost less money) than the parlays 38% of the time. Just because the expected value is higher for the parlays, that doesn't mean they will always be more profitable. &lt;/p&gt;
&lt;p&gt;More concerningly, the parlays had big losses (down more than $1000 on $100 bets) 33% of the time. That only happened 0.2% of the time on the straight bets. There were almost no small losses with the parlays, because the payout is so high and the number of bets (50 parlays) is so low. Winning one more parlay could be the difference between being down $1000, and breaking even.&lt;/p&gt;
&lt;p&gt;Expected Value can't be the only thing we consider, because we don't live an infinite life. Our whole life is a small sample size, if the variance is high enough. Our bankrolls are always finite. The fact that we might make more money over 100 years is undercut by the fact that we'll die or go broke before then.&lt;/p&gt;
&lt;p&gt;Even for the skilled bettor, parlays make it more of a game of luck. Let's say my simulation represents an entire season of betting on basketball. Imagine playing the parlays with a 55% win rate, being better than almost everybody at handicapping, and still having massive losses one season in three? When you'd make more money taking the individual bets 40% of the time?&lt;/p&gt;
&lt;h3&gt;Parlay psychology&lt;/h3&gt;
&lt;p&gt;There's a weird psychology to the parlay as well. These parlays only win once every couple of weeks, so they'd be kind of a grim strategy in practice. A good bettor taking the individual bets will have winning days over half the time. Is it better to feel like a winner most days, or every other week?&lt;/p&gt;
&lt;p&gt;Most people don't have to consider that question, though. Without a huge amount of skill at betting, the only scenario where they might make sense is as a lottery: something that can deliver a tiny chance of massive payouts without any skill. &lt;/p&gt;
&lt;p&gt;What happens if we do the same simulation, but the win rate is 50%, like a coin flip, or most sports bettors? The parlays make money 38% of the time! Taking 200 straight bets will only make money 26% of the time. Isn't that a little surprising?  Even though the straight bets have better expected value (well, less bad), they also offer less of an opportunity to make money based on chance alone. &lt;/p&gt;
&lt;p&gt;What about over a longer time frame? I simulated 500 parlays versus 2,000 straight bets by flipping a coin. The parlays make money 12% of the time, versus only 1.74% of the time for the straight bets. However, the losses are much, much bigger than the wins:&lt;/p&gt;
&lt;p&gt;&lt;img alt="img/parlay-500.png" src="img/parlay-500.png"&gt;&lt;/p&gt;
&lt;p&gt;12% is 1 in 8, which isn't that rare. 500 parlays could end up stretching over multiple seasons, perhaps a lifetime of sports betting. That means somebody who was making picks by flipping a coin could end up looking like a pretty good bettor for a long stretch if they are taking parlays. Of course, 88% of people will lose money, far more money than the 12% of profitable bettors win. In practical terms, it's like a lottery where you have a 12% chance of winning $3617, but an 88% chance of losing $10,221.&lt;/p&gt;
&lt;p&gt;It's really, really hard to tell if someone taking bets at long odds is actually good at betting, not without thousands of documented bets. Over 50 parlays, or even 500, it's not that surprising for some people to look smart on parlays by chance alone. It would be much better to assess their skill based on the individual bets they took within the parlays.&lt;/p&gt;
&lt;h3&gt;Other parlays&lt;/h3&gt;
&lt;p&gt;Parlays with only 2 or 3 legs have higher relative payouts compared to 4 leg parlays, so they're not nearly as bad. They'll also have less variance in outcomes than the 4+ leggers. I'll leave those calculations to the reader, though. While they're one of the least bad bets offered by the average sportsbook, it's extremely rare to see people talking about 2 or 3 leg parlays online. Gamblers love the higher payouts and drama of parlays with a bunch of legs. I will have a lot more to say about how people actually play the parlays in a future installment.&lt;/p&gt;
&lt;p&gt;Same Game Parlays (SGPs) are a new type of bet which allows the player to make multiple wagers on the same game. For instance, someone could bet on their favorite team winning and their favorite player scoring over a certain amount of points and the guy they hate on the other team scoring under a certain amount of points, with a big payout if all 3 things happen. SGPs have become the most popular type of bet I see online, and deserve their own lengthy discussion. For now just think of them as the vape pens of betting. They're obviously super addictive, extremely popular with younger people, and you can't really know what's in them, but it's probably bad.&lt;/p&gt;
&lt;h3&gt;Gambling gurus&lt;/h3&gt;
&lt;p&gt;I've taken up lot of hobbies over the years. It seems like every time I take up a new hobby, I end up spending a lot of money on stupid stuff at the beginning. Then I get into it more, and realize what matters.&lt;/p&gt;
&lt;p&gt;There is an adverse selection process, where people who are new to a hobby have no idea what's actually good, what they actually need, or what things should actually cost. Filled with zeal to get started, they end up overpaying for inferior goods. Same thing for travelling in a new country. The guys at the train station trying to hustle you into a taxi are definitely not hooking you up with the cheapest way to get around.&lt;/p&gt;
&lt;p&gt;Betting experts, the kind who have podcasts and big followings on social media, are supposed to know more about this stuff than the average person. They're supposed to be like the guidebooks, or the seasoned traveller telling the newbie to walk 2 blocks and take the metro for $2 instead of paying $100 for a taxi. Yet they're pushing parlays and other sucker bets, and pushing sportsbooks that charge full vig and ban anybody who wins too much. The "experts" are pushing beginners into bad situations.&lt;/p&gt;
&lt;p&gt;Most of them don't do any better than flipping a coin, so I doubt they're actually making money on their "can't miss locks of the week". Gambling ads, sure. Everybody's taking gambling money right now, regardless of how it will hurt their brand, their audience, and sports long term. Clearly there's a lot of money in talking about it. That gambling money is there because these self-styled experts bring the sportsbooks more customers -- losing customers, specifically. &lt;/p&gt;
&lt;p&gt;Where's all that ad money coming from? The sportsbooks wouldn't be throwing money at influencers who were actually winning consistently. Any gambling show they sponsor is pretty much guaranteed to lose you money, or it wouldn't be sponsored. Any bet they're promoting heavily, like they do with parlays, is because it makes them more money that way. You shouldn't need to know any math to figure out why they're pushing teasers and parlays and "profit boosters". I love that last one. It's like saying Idi Amin served mankind. Why would they care about boosting YOUR profits? &lt;/p&gt;
&lt;p&gt;Unlike gamblers, sportsbooks don't make negative expected value plays due to emotions or lack of information. Your irrationality is their entire business.&lt;/p&gt;</content><category term="sports betting"></category><category term="basketball"></category><category term="your parlay sucks"></category></entry><entry><title>Sports betting and the limits of rationality</title><link href="/sports-betting-and-the-limits-of-rationality.html" rel="alternate"></link><published>2025-07-12T10:20:00-10:00</published><updated>2025-07-12T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-07-12:/sports-betting-and-the-limits-of-rationality.html</id><summary type="html">&lt;p&gt;Earlier this year, I wrote most of a book about the psychology and mathematics of sports gambling called &lt;em&gt;Your Parlay Sucks&lt;/em&gt;. The book never quite came together, and is probably too weird to ever get published, but it has some interesting bits, so I figured I'd share them here.&lt;/p&gt;
&lt;p&gt;Why …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Earlier this year, I wrote most of a book about the psychology and mathematics of sports gambling called &lt;em&gt;Your Parlay Sucks&lt;/em&gt;. The book never quite came together, and is probably too weird to ever get published, but it has some interesting bits, so I figured I'd share them here.&lt;/p&gt;
&lt;p&gt;Why did I get interested enough in sports betting to write a whole book about it? I think it's because I'm fascinated by the limits of rationality. Philosophers, economists and social scientists would like to treat humans as though they are capable of making rational decisions. That conflicts with the real world, where even pretty smart people make irrational choices. I certainly have. &lt;/p&gt;
&lt;p&gt;Sports betting is a sort of rationality lab. You and I might have different values or beliefs. What's crazy to me might be normal to you, or vice versa, but we should both be able to agree that placing bets that are guaranteed to lose money is irrational.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1553935"&gt;This paper&lt;/a&gt;, "Intuitive Biases in Choice versus Estimation", is a wonderful illustration of cognitive bias and irrationality in the realm of sports betting.  &lt;/p&gt;
&lt;p&gt;The researchers had people bet on NFL football against the point spread. If you're not familiar, the idea behind the point spread is to attract an equal amount of action on both sides of the bet by handicapping one of the teams. If you bet on the favorite, they need to win by at least the amount of the spread for the bet to win. The other side side wins if the team loses by less than the spread, or wins the game outright.&lt;/p&gt;
&lt;p&gt;Gamblers can bet either side, and if there are more bets on one side than the other, the sportsbook can change the spread to attract equal action. So there's a potential for the wisdom of crowds to kick in, the invisible hand of the market moving the line towards the best estimate possible.&lt;/p&gt;
&lt;p&gt;Of course, that depends on gamblers being rational. A rational gambler has to be willing to take either side of a bet (or not bet at all), depending on the spread. If the spread is biased towards the underdog, they should be willing to take the underdog. If it's biased towards the favorite, they should take the favorite. And if the line is perfectly fair, they shouldn't bet at all.&lt;/p&gt;
&lt;p&gt;As I showed a while back with &lt;a href="/majority-voting-in-ensemble-learning.html"&gt;ensemble learning&lt;/a&gt;, the wisdom of crowds only works if the errors that people make are uncorrelated with each other. If most people are wrong about a particular thing, the "wisdom of crowds" will be wrong, too.&lt;/p&gt;
&lt;p&gt;This study found that people are consistently irrational when it comes to point spreads. They will tend to bet the favorite, even though both sides should have an equal chance of winning. It's probably easier to focus on which team is better, and assume that the better team is more likely to win against the point spread as well. It's harder to imagine the underdog losing the game but winning the bet, or pulling an upset and winning outright. &lt;/p&gt;
&lt;p&gt;The study took things further and adjusted the lines to be biased against the favorite team, so that taking the favorite would be guaranteed to lose more than 50% of the time. They even told the gamblers that they did this. And the gamblers still overwhelmingly picked the favorites. The researchers continued the study for the whole season. Even after weeks and weeks of steadily losing, being told over and over that the lines are unfair, the gamblers still preferred to take the favorites. They never learned. The participants got to keep their winnings, so they had an incentive to be right. And they still couldn't do it.&lt;/p&gt;
&lt;p&gt;Sportsbooks have a lot of ways of trick people into taking extra bad bets, as I will show. But they don't really need to. People will consistently take bad bets even if they should know they're bad bets. &lt;/p&gt;</content><category term="sports betting"></category><category term="football"></category><category term="your parlay sucks"></category></entry><entry><title>The final word on the hot hand (for now)</title><link href="/the-final-word-on-the-hot-hand-for-now.html" rel="alternate"></link><published>2025-06-30T10:20:00-10:00</published><updated>2025-06-30T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-06-30:/the-final-word-on-the-hot-hand-for-now.html</id><summary type="html">&lt;p&gt;(Notebooks and other code available at: &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Last time, we found that there are many players like LeBron, where their FG% is higher when they've missed most of their last 5 shots than when they've made most of them. However, most players don't have enough attempts …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(Notebooks and other code available at: &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Last time, we found that there are many players like LeBron, where their FG% is higher when they've missed most of their last 5 shots than when they've made most of them. However, most players don't have enough attempts when they've gone 0 or 5 out of their last 5 for a good statistical analysis.&lt;/p&gt;
&lt;p&gt;So instead I will be looking at a binary split -- I will call a player &lt;em&gt;cold&lt;/em&gt; when they've made 0, 1 or 2 of their last 5 shots, and &lt;em&gt;hot&lt;/em&gt; when they've made 3, 4 or 5 of their last 5. Most players have a FG% between 40 and 60%, so this nicely splits them into times when they're shooting better than average versus worse than average.&lt;/p&gt;
&lt;h2&gt;Anthony Edwards&lt;/h2&gt;
&lt;p&gt;Anthony Edwards ("Ant") is particularly unstreaky for a young player. He's only completed 5 seasons in the league, but has the 5th biggest z score of the last 20 years. He could definitely catch LeBron someday.&lt;/p&gt;
&lt;p&gt;Ant has the LeBron-like pattern of FG% trending downward when he's &lt;em&gt;hot&lt;/em&gt;. He doesn't have anywhere near the volume of LeBron, so the spike at 20% (1/5) might just be noise. But overall, he shoots worse when he's been shooting well.&lt;/p&gt;
&lt;p&gt;&lt;img alt="ant-last-5" src="/img/ant-last-5.png"&gt;&lt;/p&gt;
&lt;p&gt;The trend appears to be due to shot selection. He takes far more above the break 3 pointers when he's &lt;em&gt;hot&lt;/em&gt; than when he's cold. The additional 3 point attempts come at the expense of shots in the restricted area.&lt;/p&gt;
&lt;p&gt;Here are the changes in tendencies:&lt;/p&gt;
&lt;pre&gt;
| BASIC_ZONE            |   hot |   cold |   diff |
|:----------------------|------:|-------:|-------:|
| Above the Break 3     |  41.5 |   31.7 |    9.8 |
| Corner 3              |   3.6 |    4.8 |   -1.2 |
| In The Paint (Non-RA) |  13.4 |   14.6 |   -1.1 |
| Mid-Range             |  14.1 |   12.2 |    1.9 |
| Restricted Area       |  27.4 |   36.7 |   -9.4 |
&lt;/pre&gt;

&lt;p&gt;Of course, this would be justified if Ant shot above the break 3's better when he's &lt;em&gt;hot&lt;/em&gt;, but he doesn't. He makes 37% of his above the break 3's when he's &lt;em&gt;cold&lt;/em&gt; but that drops to 34% when he's hot. So he's trading restricted area shots, with an expected value of .601 * 2 = 1.202 points, for above the break 3's, with an expected value of .34 * 3 = 1.02 points.&lt;/p&gt;
&lt;p&gt;Here are the changes in FG percentages. His FG% on corner 3's goes up, but it's on insignificant volume:&lt;/p&gt;
&lt;pre&gt;
| BASIC_ZONE            |   hot |   cold |   diff |
|:----------------------|------:|-------:|-------:|
| Above the Break 3     |  34   |   37.1 |   -3.1 |
| Corner 3              |  45   |   33   |   12   |
| In The Paint (Non-RA) |  40.8 |   34   |    6.8 |
| Mid-Range             |  36.3 |   34.8 |    1.5 |
| Restricted Area       |  60.1 |   65.4 |   -5.2 |
&lt;/pre&gt;

&lt;h2&gt;The rest of the league&lt;/h2&gt;
&lt;p&gt;I looked at league-wide shot selection in &lt;em&gt;hot&lt;/em&gt;/&lt;em&gt;cold&lt;/em&gt; situations. I restricted to the last 10 seasons, since the rise of the 3 pointer has dramatically changed shot selection. Here are changes in shot selection for all players:&lt;/p&gt;
&lt;pre&gt;
| BASIC_ZONE            |   hot |   cold |   diff |
|:----------------------|------:|-------:|-------:|
| Above the Break 3     |  22.1 |   22.3 |   -0.2 |
| Corner 3              |   6.2 |    7   |   -0.9 |
| In The Paint (Non-RA) |  15.8 |   15.3 |    0.4 |
| Mid-Range             |  25.3 |   23.5 |    1.8 |
| Restricted Area       |  30.7 |   31.8 |   -1.2 |
&lt;/pre&gt;

&lt;p&gt;The mid-range shot is the lowest value shot type, so it's notable that the rate goes up when players are &lt;em&gt;hot&lt;/em&gt;. These additional mid ranges come at the expense of Corner 3's and Restricted Area shots, the two most valuable types of shots.&lt;/p&gt;
&lt;p&gt;As before, changes in shot selection could be justified if players actually shoot differently based on their last 5 results, but they don't. Here are the changes in shooting percentages (hot minus cold) for all players:&lt;/p&gt;
&lt;pre&gt;
| BASIC_ZONE            |   hot |   cold |   diff |
|:----------------------|------:|-------:|-------:|
| Above the Break 3     |  34.7 |   35   |   -0.3 |
| Corner 3              |  38.4 |   38.9 |   -0.4 |
| In The Paint (Non-RA) |  41.7 |   41.2 |    0.5 |
| Mid-Range             |  39.8 |   40.1 |   -0.3 |
| Restricted Area       |  62.7 |   60.7 |    2   |
&lt;/pre&gt;

&lt;p&gt;For 3 out of 5 shot types, the &lt;em&gt;hot&lt;/em&gt; FG percentages are lower than the &lt;em&gt;cold&lt;/em&gt; ones. Combined with the changes in shot selection, I think there's evidence that the league as a whole is scoring less efficiently because of the false belief in the hot hand. &lt;/p&gt;
&lt;p&gt;The data says that players are essentially trading Restricted Area (.627 * 2 = 1.25 points per shot) and Corner 3 (.384 * 3 = 1.15 points per shot) attempts for Mid-Ranges (.398 * 2 = .796 points per shot) when they think they've got the &lt;em&gt;hot hand&lt;/em&gt;. That's clearly bad! If it happens once a game, that's 38 points a year lost, which might be enough to swing a game or two.&lt;/p&gt;
&lt;p&gt;The change in restricted area and in the paint (non-RA) FG% is intriguing, but if the hot hand did exist, wouldn't we see it on 3 point or mid-range shots, rather than restricted area shots? The announcer doesn't say "he's heating up" after a guy has made 3 layups in a row, they say it after 3 longer range shots in a row, right?&lt;/p&gt;
&lt;h2&gt;Higher volume players&lt;/h2&gt;
&lt;p&gt;I decided to focus on players with at least 1000 streaks, which leaves 630 players. Collectively, they are responsible for 84% of all shots in the NBA over the last 20 years.&lt;/p&gt;
&lt;p&gt;Their FG percentages are, on average, 1% lower when they are &lt;em&gt;hot&lt;/em&gt; than when they are &lt;em&gt;cold&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;68% of them shoot worse when they're hot than when they're cold, which is a pretty dramatic split.&lt;/p&gt;
&lt;p&gt;&lt;img alt="fg-pct-hot-cold" src="/img/fg-pct-hot-cold.png"&gt;&lt;/p&gt;
&lt;p&gt;Here's a plot of the difference between hot and cold FG% versus z-score:&lt;/p&gt;
&lt;p&gt;&lt;img alt="z-score-hot-cold" src="/img/z-score-hot-cold.png"&gt;&lt;/p&gt;
&lt;p&gt;Players with negative values on the x axis shoot better when they're cold, and positive values shoot better when they're hot.&lt;/p&gt;
&lt;p&gt;Now, there should be some correlation between z-scores and hot/cold shooting tendency. I've shown simulations where a tendency to shoot &lt;em&gt;better cold&lt;/em&gt; produces unstreaky results (skewed towards positive z scores), and &lt;em&gt;better hot&lt;/em&gt; will produce streaky results (negative z scores). So there should be more dots in the upper left and bottom right quadrants compared to the other diagonal.&lt;/p&gt;
&lt;p&gt;But if players behaved by coin flips, we should see roughly the same number of players with positive and negative z scores, and roughly the same number of players who shoot better when they're hot and better when they're cold.&lt;/p&gt;
&lt;p&gt;I simulated all 3.5 million shots by these players, using their career average FG% for every shot. So any streakiness or unstreakiness is going to be totally random. As you can see, the data is much less spread out across both the X and Y axis.&lt;/p&gt;
&lt;p&gt;&lt;img alt="sim-z-hot-cold" src="/img/sim-z-hot-cold.png"&gt;&lt;/p&gt;
&lt;p&gt;Here are the crosstabs from the simulation:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;better cold&lt;/th&gt;
&lt;th&gt;better hot&lt;/th&gt;
&lt;th&gt;margin&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;positive z&lt;/td&gt;
&lt;td&gt;178&lt;/td&gt;
&lt;td&gt;135&lt;/td&gt;
&lt;td&gt;313&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;negative z&lt;/td&gt;
&lt;td&gt;112&lt;/td&gt;
&lt;td&gt;210&lt;/td&gt;
&lt;td&gt;322&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;margin&lt;/td&gt;
&lt;td&gt;290&lt;/td&gt;
&lt;td&gt;345&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As promised, the marginal values are pretty close to one another. That's what happens when "better hot" vs. "better cold" and "positive z" vs. "negative z" are determined purely by chance.&lt;/p&gt;
&lt;p&gt;Here are the actual crosstabs. The marginal values are much more imbalanced.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;better cold&lt;/th&gt;
&lt;th&gt;better hot&lt;/th&gt;
&lt;th&gt;margin&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;positive z&lt;/td&gt;
&lt;td&gt;343&lt;/td&gt;
&lt;td&gt;126&lt;/td&gt;
&lt;td&gt;469&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;negative z&lt;/td&gt;
&lt;td&gt;88&lt;/td&gt;
&lt;td&gt;78&lt;/td&gt;
&lt;td&gt;166&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;margin&lt;/td&gt;
&lt;td&gt;431&lt;/td&gt;
&lt;td&gt;204&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Things to note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;68% of the players shoot better when they're cold.&lt;/li&gt;
&lt;li&gt;74% of the players have a positive z-score.&lt;/li&gt;
&lt;li&gt;Even among players with a negative z score, the majority of them shoot better when they're cold. &lt;/li&gt;
&lt;li&gt;Even among players that shoot better when they're hot, the majority of them &lt;em&gt;still&lt;/em&gt; produce results that are less streaky than expected by chance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That's all super weird!&lt;/p&gt;
&lt;p&gt;As always, these are just general trends. There are 78 players in the "better hot" + "negative z" box, and there should be around 210 players. We can't really say which players are the 130 "missing" players, though.&lt;/p&gt;
&lt;p&gt;That's all I've got on the hot hand in the NBA for now. I think I understand it a lot better now, and I hope you do, too. &lt;/p&gt;</content><category term="sports analytics"></category><category term="basketball"></category><category term="the hot hand"></category></entry><entry><title>LeSimulation</title><link href="/lesimulation.html" rel="alternate"></link><published>2025-06-18T10:20:00-10:00</published><updated>2025-06-18T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-06-18:/lesimulation.html</id><summary type="html">&lt;p&gt;(As usual, all code and notebooks are available at &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Last time, we saw that LeBron James was by far the un-streakiest player in the NBA over the last 20 years and found out that it's at least partly caused by shot selection. He takes both …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(As usual, all code and notebooks are available at &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Last time, we saw that LeBron James was by far the un-streakiest player in the NBA over the last 20 years and found out that it's at least partly caused by shot selection. He takes both lower percentage shots than average when he's shooting well and higher percentage shots than average when he's shooting poorly.&lt;/p&gt;
&lt;h2&gt;LeMartingale&lt;/h2&gt;
&lt;p&gt;I got the question of why it's OK to use a player's overall FG% to gauge their streakiness. We know that every shot a player takes has a slightly different level of difficulty, and thus a different probability that it will go in. Shouldn't that affect the streakiness?&lt;/p&gt;
&lt;p&gt;It's a good question.  Let's say you've got a bag with 2 types of coins inside. One of them comes up heads 40% of the time, the other comes up heads 60% of the time. You can't tell which is which. If you pick a coin randomly out of the bag and flip it, what are the chances, on average, it comes up heads? &lt;/p&gt;
&lt;p&gt;It's 50%, right? The selecting of the coin and the flipping of the coin are two independent steps. We can multiply the probabilities at each step together, so the overall chances of heads are &lt;code&gt;(.5 * .4) + (.5 * .6) = .5&lt;/code&gt;. If we kept randomly selecting from the bag and flipping a coin, the results would be indistinguishable from just flipping a single fair coin over and over.&lt;/p&gt;
&lt;p&gt;In math, this is known as a &lt;a href="https://en.wikipedia.org/wiki/Martingale_(probability_theory)"&gt;Martingale&lt;/a&gt;. Previous outcomes don't give us information about the next event. (More in depth explanation &lt;a href="https://www.cs.yale.edu/homes/aspnes/pinewiki/Martingales.html"&gt;here&lt;/a&gt;).  That's different from LeBron. We know he essentially chooses the 60% heads coin when he's been getting a lot of tails recently, and the 60% tails coin when he's been getting a lot of heads recently.&lt;/p&gt;
&lt;h2&gt;LeSimulation&lt;/h2&gt;
&lt;p&gt;If I create a simulation of LeBron James that uses his exact shooting tendencies and FG percentages, and the shot selection is totally random, it shouldn't show any streaky or unstreaky tendencies beyond expected by chance. Let's see what LeSimulation looks like.&lt;/p&gt;
&lt;p&gt;At the end of the last edition, I got LeBron's shooting stats:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;Above&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Break&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;344598&lt;/span&gt;
&lt;span class="nv"&gt;Backcourt&lt;/span&gt;&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;058824&lt;/span&gt;
&lt;span class="nv"&gt;In&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;The&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Paint&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;RA&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;401369&lt;/span&gt;
&lt;span class="nv"&gt;Left&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Corner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;394799&lt;/span&gt;
&lt;span class="nv"&gt;Mid&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;Range&lt;/span&gt;&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;379890&lt;/span&gt;
&lt;span class="nv"&gt;Restricted&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Area&lt;/span&gt;&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;720138&lt;/span&gt;
&lt;span class="nv"&gt;Right&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Corner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;           &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;370370&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And shooting tendencies (what percent of the time he takes each type of shot):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;Above&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Break&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;204940&lt;/span&gt;
&lt;span class="nv"&gt;Backcourt&lt;/span&gt;&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;001160&lt;/span&gt;
&lt;span class="nv"&gt;In&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;The&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Paint&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;RA&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;109652&lt;/span&gt;
&lt;span class="nv"&gt;Left&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Corner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;014431&lt;/span&gt;
&lt;span class="nv"&gt;Mid&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;Range&lt;/span&gt;&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;267715&lt;/span&gt;
&lt;span class="nv"&gt;Restricted&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Area&lt;/span&gt;&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;386442&lt;/span&gt;
&lt;span class="nv"&gt;Right&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Corner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;           &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;015660&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The simulation randomly chooses a shot type, based on the actual tendencies, then attempts a shot at the corresponding FG%.&lt;/p&gt;
&lt;p&gt;&lt;img alt="le-fake-career" src="/img/le-fake-career.png"&gt;&lt;/p&gt;
&lt;p&gt;The z-scores look like they should -- mean is very close to 0, standard deviation close to 1. No streaky/unstreaky tendencies, as promised. No evidence that shot attempts were at different FG%.&lt;/p&gt;
&lt;h2&gt;LeSimulation 2 - last 5 FG%&lt;/h2&gt;
&lt;p&gt;My next simulation uses LeBron's FG% over his last 5 shots. We've seen he shoots the best with 0 makes in his last 5; the worst with 5 makes in his last 5. The simulation uses his exact percentages at each level. For the first 5 shots of every game, it uses his career FG%.&lt;/p&gt;
&lt;p&gt;I ran the simulation 1,000 times. Here are the z-scores:&lt;/p&gt;
&lt;p&gt;&lt;img alt="le-fake-career-2" src="/img/le-fake-career-2.png"&gt;&lt;/p&gt;
&lt;p&gt;As expected, this simulation is pretty un-streaky:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    1000.000000
mean        1.635843
std         0.985464
min        -1.665389
25%         1.001550
50%         1.623242
75%         2.346864
max         4.509869
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It's still not nearly as unstreaky as the man himself, though -- Lebron's z score of 5.9 would be way bigger than the largest value in 1,000 simulations (4.5). So he'd still be an outlier compared to these simulated un-streaky players.&lt;/p&gt;
&lt;h2&gt;LeSimulation 3 -- No resetting streaks&lt;/h2&gt;
&lt;p&gt;What about a fake player where the streaks don't reset between games? That should make the simulated player even more unstreaky.&lt;/p&gt;
&lt;p&gt;In this version of the simulation, every shot will be influenced by the FG% of the previous 5 shots, even if they happened in the previous game(s).&lt;/p&gt;
&lt;p&gt;&lt;img alt="le-fake-career-3" src="/img/le-fake-career-3.png"&gt;&lt;/p&gt;
&lt;p&gt;Here are the corresponding z-scores:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    1000.000000
mean        2.179821
std         0.963330
min        -1.033468
25%         1.536542
50%         2.203681
75%         2.865350
max         5.073167
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So, the mean went from 1.6 to 2.2, and the max z score went from 4.5 to 5.1. That's still not nearly unstreaky enough to match LeReal LeBron, but at least it's closer.&lt;/p&gt;
&lt;p&gt;It's possible that if we tracked the last 7 shots, or 9, instead of 5, we would see even more of a dramatic change in FG percentage. Or there's some other factor I haven't considered that is adding unstreakiness, such as the fact that his FG percentage tends to go down the more shots he's taken in a game.&lt;/p&gt;
&lt;h2&gt;DoppLeGangers&lt;/h2&gt;
&lt;p&gt;I was curious if I could find similar players to LeBron. There's a good way to do that, but I wanted to try my own way first. I found players where, like LeBron, their FG% steadily declines the more shots they've made out of the last 5.  There are 18 such players in the 2004-2024 years: Karl Malone (his last season), Grant Hill, Ben Wallace, Eddie House, Michael Redd, Jarvis Hayes, Andres Nocioni, JJ Redick, Nicolas Batum, Goran Dragic, DeMar DeRozan, Patrick Beverley, Marcus Morris Sr., Bradley Beal, Kelly Oubre Jr., Norman Powell, Donte DiVincenzo, and Landry Shamet.&lt;/p&gt;
&lt;p&gt;Overall, these players have a mean z-score of 1.47, which is pretty impressive, but except for Goran Dragic, there isn't much overlap over the players with the highest overall z scores. 18 players is a pretty small sample size, as well.&lt;/p&gt;
&lt;p&gt;I also looked at a broader set of players where at least 4 out of the 5 comparisons were decreasing. This gave 180 players, with an average z score of 1.0. &lt;/p&gt;
&lt;h3&gt;LeRight way&lt;/h3&gt;
&lt;p&gt;The right way to identify LeBron-alikes is probably to use a similarity metric that I didn't invent. The fg percentages after 0,1,2...5/5 makes are sort of like a probability distribution. &lt;/p&gt;
&lt;p&gt;In statistics and machine learning, we are often fitting a theoretical distribution to the actual observed data. Is it a good representation of the observed data? Do their distributions have the same sort of shape? The standard measure is relative entropy, also known as &lt;a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"&gt;KL divergence&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If I normalize the shooting percentages and compare them to LeBron's, players with a low relative entropy should show the same tendency to shoot better when they're shooting worse than average over their last 5, and vice versa.&lt;/p&gt;
&lt;p&gt;For example, LeBron's last 5 percentages are:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.564612&lt;/span&gt;
&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mf"&gt;0.50712&lt;/span&gt;
&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.505937&lt;/span&gt;
&lt;span class="mf"&gt;3&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.496538&lt;/span&gt;
&lt;span class="mf"&gt;4&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.473849&lt;/span&gt;
&lt;span class="mf"&gt;5&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.464052&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;By normalizing them, they act like a probability distribution (they all add up to one) but still have the same relative proportions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.187448&lt;/span&gt;
&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mf"&gt;0.16836&lt;/span&gt;
&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.167968&lt;/span&gt;
&lt;span class="mf"&gt;3&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.164847&lt;/span&gt;
&lt;span class="mf"&gt;4&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.157315&lt;/span&gt;
&lt;span class="mf"&gt;5&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.154062&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The normalization also corrects for the fact that shooters have different overall FG percentages.&lt;/p&gt;
&lt;p&gt;Normalized values can then be compared to other players' values. The lower the entropy, the more similar their shapes are.&lt;/p&gt;
&lt;p&gt;I also calculated the Jensen-Shannon distance, which is like relative entropy, but symmetrical (&lt;code&gt;distance(le_bron, le_other_guy) = distance(le_other_guy, le_bron)&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;The closest guys to LeBron by this measure are CJ McCollum, Terry Rozier, Andrea Bargnani, Marcus Morris, Richard Hamilton, Nikola Vucevic, Zach Randolph, Lauri Markkanen, Kawhi Leonard, and Kevin Huerter. &lt;/p&gt;
&lt;p&gt;Since Richard Hamilton had the streakiest game in the last 20 years, it's not surpring to see him. But except for Randolph and Vucevic, none of the top 10 had exceptional z scores, though they were all positive.&lt;/p&gt;
&lt;p&gt;The Jensen-Shannon distance results were extremely similar to entropy. It agreed exactly with the entropy on 73 of the top 100 players. The average z score for those players was 1.16, versus 1.15 for entropy. So, in aggregate, both were better than my homegrown metric at identifying unstreaky players.&lt;/p&gt;
&lt;p&gt;This graph shows the shape of the 10 players most similar to LeBron. They all have the same downward trend&lt;/p&gt;
&lt;p&gt;&lt;img alt="most-similar-last5" src="/img/most-similar-last5.png"&gt;&lt;/p&gt;
&lt;p&gt;I haven't looked at whether the reason for the trend in last 5 FG% is due to shot selection for these other players, which is probably the interesting part. Some of the players flagged here are inevitably due to chance. It's based on six 50/50 measurements, so 1 in 64 players would get flagged as "LeBron like" even if the data was randomly generated.&lt;/p&gt;
&lt;p&gt;None of my queries here turned up the un-streakiest players like Luka Doncic and Anthony Edwards. Whatever causes their extreme unstreakiness (beyond randomness) must be different from LeBron's tendencies. Stay tuned!&lt;/p&gt;</content><category term="sports analytics"></category><category term="basketball"></category><category term="the hot hand"></category></entry><entry><title>LeBron James, the Unstreaky King</title><link href="/lebron-james-the-unstreaky-king.html" rel="alternate"></link><published>2025-06-12T10:20:00-10:00</published><updated>2025-06-12T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-06-12:/lebron-james-the-unstreaky-king.html</id><summary type="html">&lt;p&gt;In previous installments, I've shown that NBA players are, as a whole, less streaky than they should be. This is apparent in game-level data, and more obvious looking at multi season trends.&lt;/p&gt;
&lt;p&gt;So far, I've only looked at the past few seasons of the NBA. I decided to gather as …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In previous installments, I've shown that NBA players are, as a whole, less streaky than they should be. This is apparent in game-level data, and more obvious looking at multi season trends.&lt;/p&gt;
&lt;p&gt;So far, I've only looked at the past few seasons of the NBA. I decided to gather as much data as I could, analyzing every single shot taken in the NBA from 2004 to 2024.&lt;/p&gt;
&lt;p&gt;Data is taken from https://www.kaggle.com/datasets/mexwell/nba-shots.&lt;/p&gt;
&lt;h2&gt;The streakiest games of the past 20 years&lt;/h2&gt;
&lt;p&gt;As I showed in the last installment, there are two ways of measuring how relatively streaky each individual game is. We can use the normal approximation from the Wald-Wolfowitz test, or we can calculate the percentile ranks from the exact probabilities.&lt;/p&gt;
&lt;p&gt;These two metrics give different answers to what is the streakiest game of the past 20 years.  According to percentile rank, the streakiest ever was Cedi Osman, who in 2022 missed 10 shots in a row, followed by making 6 shots in a row, for an equivalent z-score of -3.6.&lt;/p&gt;
&lt;p&gt;According to the normal approximation, the streakiest game ever was Chris Bosh in 2007, who made 15 shots in a row before missing his final 4. Bosh doesn't even make the top 5 by percentile rank. &lt;/p&gt;
&lt;p&gt;Other strong performances include Andre Iguodala, who had 16 straight misses followed by 3 makes in 2008, and Willie Green, who had 5 misses followed by 12 makes. The sheer length of those streaks is impressive, but to maximize the number of expected streaks, there need to be similar numbers of makes and misses. A game with 5 makes and 5 misses has a maximum of 10 streaks. A game with 15 makes and 4 misses, like Chris Bosh, has a maximum of 9 streaks.&lt;/p&gt;
&lt;p&gt;Kobe Bryant's final game in the NBA also deserves mention. He went an extremely streaky 22 for 50, earning the highest number of expected streaks in the data I have (25.64): &lt;code&gt;11111000100110000101110000101100001100001111100000&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;The least streaky games&lt;/h2&gt;
&lt;p&gt;The least streaky was by Richard Hamilton in 2006, who had 10 makes and 13 misses, no two makes in a row: &lt;code&gt;01001010101010010101010&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Kyrie Irving, Dejounte Murray (previously covered), and Kevin Martin also had strong showings. &lt;/p&gt;
&lt;h1&gt;The un-streaky king&lt;/h1&gt;
&lt;p&gt;The 4th most un-streaky game of the past 20 years belongs to LeBron James.  &lt;a href="https://www.basketball-reference.com/boxscores/200511090CLE.html"&gt;LeBron scored 31 points in an easy win over the SuperSonics in 2005&lt;/a&gt;. Aside from 2 makes in a row at the start of the game, he perfectly alternated makes and misses the rest of the game: &lt;code&gt;110101010101010101&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In the 20 years of shot data I analyzed, LeBron stands out as by far the most un-streaky player. Here are the career z scores of every player from 2004-2024:&lt;/p&gt;
&lt;p&gt;&lt;img alt="career-z-scores" src="/img/career-z-scores.png"&gt;&lt;/p&gt;
&lt;p&gt;LeBron can't even be seen on this chart. He is in a world of his own, with a career z score of 5.9. We have to go to the Jon Bois style scatterplot with one extreme outlier in the corner:&lt;/p&gt;
&lt;p&gt;&lt;img alt="career-z-scatter" src="/img/career-z-scatter.png"&gt;&lt;/p&gt;
&lt;p&gt;If this were a Youtube video, imagine me zooming in on the solitary dot in the upper right while the saxophone hook from &lt;a href="https://youtu.be/BO1qcWa6blQ?t=22"&gt;Baker Street&lt;/a&gt; kicks in.&lt;/p&gt;
&lt;p&gt;Which is to say, it's really, really unlikely. The odds are around 1 in 550 million. That puts him in the 99.9999998th percentile.&lt;/p&gt;
&lt;p&gt;If all 8.2 Billion people on the planet had LeBron's NBA career, taking over 29,000 shots like he has, at the same FG% he did, we'd expect 15 people to be that unstreaky or more. That's elite company. Not only is LeBron James the LeBron James of basketball, he's also the LeBron James of being unstreaky at basketball.&lt;/p&gt;
&lt;p&gt;As both the most unstreaky player of all time, and the most prolific scorer of all time, LeBron James makes a perfect test subject for understanding unstreakiness.&lt;/p&gt;
&lt;p&gt;He's had 15,159 shooting streaks in his career so far, which is 504 more streaks than expected.  Say LeBron takes a low percentage shot because he feels like he has the hot hand. It might be lower, but it's probably not dramatically worse than his regular shot. So for him to have 500 more streaks than expected, that's potentially thousands of choices LeBron has made over his career that increased the likelihood of streaks getting broken.&lt;/p&gt;
&lt;h2&gt;Streak lengths&lt;/h2&gt;
&lt;p&gt;I simulated LeBron's career 1000 times and compared the frequency of streak lengths to his actual career. Here are his actual streaks compared to the expected frequencies:&lt;/p&gt;
&lt;p&gt;&lt;img alt="lebron-make-streaks" src="/img/lebron-make-streaks.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="lebron-miss-streaks" src="/img/lebron-miss-streaks.png"&gt;&lt;/p&gt;
&lt;p&gt;He has slightly more 1 and 2 shot make/miss streaks than expected, and fewer streaks of 5-6 or more.&lt;/p&gt;
&lt;p&gt;Previously I discussed that players could cause unstreakiness because they "go get a bucket" when the "shot isn't falling" -- in other words, they take higher percentage shots when they're on a cold streak. They might try to draw contact from a defender, and if they do get fouled, it only counts as a shot attempt if the shot goes in. On the other hand, they might take risky "heat check" shots when they are performing relatively well because they feel like they can't miss.&lt;/p&gt;
&lt;p&gt;To capture "hot" versus "cold", I decided to track the FG% over the previous 5 shots in the game. So, it's undefined for the player's first 5 shots of the game, then defined from the 6th on. Because LeBron is such a high volume scorer and has been for so many years, that's still a lot of data to look at. &lt;/p&gt;
&lt;p&gt;here are the number of shot attempts by LeBron by each "last 5" shooting percentage.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;NaN    7460
0.6    7222
0.4    6906
0.8    3518
0.2    3090
1.0     612
0.0     503
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I have defined &lt;em&gt;cold&lt;/em&gt; as making 0 or 1 of the last 5 shots, and &lt;em&gt;hot&lt;/em&gt; as making 4 or 5 of the last 5. This was a semi-arbitrary choice based on make/miss streaks longer than 5 happening less frequently than chance would dictate. It also matches how my simulated un-streaky player works.&lt;/p&gt;
&lt;p&gt;There's a clear trend. LeBron's FG% is 10% higher when he's missed his last 5 shots than when he's made his last 5.&lt;/p&gt;
&lt;p&gt;&lt;img alt="lebron-last-5" src="/img/lebron-last-5.png"&gt;&lt;/p&gt;
&lt;p&gt;That's a pretty big swing.&lt;/p&gt;
&lt;h2&gt;LeBron is un-streaky due to shot selection&lt;/h2&gt;
&lt;p&gt;What's behind this trend?&lt;/p&gt;
&lt;p&gt;LeBron takes a lot more high percentage shots when he's &lt;em&gt;cold&lt;/em&gt; versus when he's &lt;em&gt;hot&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;Change&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;shot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;rates&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;cold&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;minus&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;hot&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:

&lt;span class="nv"&gt;Above&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Break&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;119694&lt;/span&gt;
&lt;span class="nv"&gt;Backcourt&lt;/span&gt;&lt;span class="w"&gt;               &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;001659&lt;/span&gt;
&lt;span class="nv"&gt;In&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;The&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Paint&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;RA&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;023637&lt;/span&gt;
&lt;span class="nv"&gt;Left&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Corner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;000429&lt;/span&gt;
&lt;span class="nv"&gt;Mid&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;Range&lt;/span&gt;&lt;span class="w"&gt;               &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;056841&lt;/span&gt;
&lt;span class="nv"&gt;Restricted&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Area&lt;/span&gt;&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;159098&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When he's &lt;em&gt;hot&lt;/em&gt;, he takes 29% of his shots in the restricted area (right near the basket, which is his highest percentage shot). When LeBron's &lt;em&gt;cold&lt;/em&gt;, that jumps up to 45% of his shots. When he's hot, 29% of his shots are above the break 3's, but he only takes that shot 17% of the time when he's &lt;em&gt;cold&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;LeBron's FG% at each type of shot doesn't change much between times when he's &lt;em&gt;hot&lt;/em&gt; and &lt;em&gt;cold&lt;/em&gt; and &lt;em&gt;in between&lt;/em&gt;. He's a tiny biy better at corner 3's when he's cold vs. hot, but that's on very small volume. LeBron is usually attacking the middle of the court, not standing in the corner. &lt;/p&gt;
&lt;p&gt;He's actually slightly worse at his three most common shot types (above the break 3, mid-range, restricted area) when he's on a cold streak. He's not un-streaky because he suddenly becomes a better shooter. He chooses to "go get a bucket" and seek out a higher percentage shot.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;Change&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;FG&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;cold&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;minus&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;hot&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:

&lt;span class="nv"&gt;Above&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Break&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;036856&lt;/span&gt;
&lt;span class="nv"&gt;In&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;The&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Paint&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;RA&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;001647&lt;/span&gt;
&lt;span class="nv"&gt;Left&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Corner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;026525&lt;/span&gt;
&lt;span class="nv"&gt;Mid&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;Range&lt;/span&gt;&lt;span class="w"&gt;               &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;023709&lt;/span&gt;
&lt;span class="nv"&gt;Restricted&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Area&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;013754&lt;/span&gt;
&lt;span class="nv"&gt;Right&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Corner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;           &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;157949&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It looks like it cuts both ways. LeBron takes lower percentage shots when he's shooting well, and higher percentage shots when he's shooting poorly over the past 5 shots, compared to the average performance.&lt;/p&gt;
&lt;h2&gt;Shot order trends&lt;/h2&gt;
&lt;p&gt;LeBron's FG% appears to trend downward with the more shots that he takes in a game. The white line is his career average:&lt;/p&gt;
&lt;p&gt;&lt;img alt="seq-vs-fg" src="/img/seq-vs-fg.png"&gt;&lt;/p&gt;
&lt;p&gt;I haven't looked into it yet, but I suspect this is partially due to LeBron often taking the last shot of the game. Final shots of the game should be harder than average if it's a close game. Everybody knows the ball's going to LeBron for the final shot, so the defense is keying in on him. I'll save that for another installment, though.&lt;/p&gt;
&lt;h2&gt;Other unstreaky guys&lt;/h2&gt;
&lt;p&gt;Kyle Kuzma, Julius Randle, Elton Brand, and Anthony Edwards are all in the 4+ z score club, with Luka Doncic, Giannis, John Henson, Goran Dragic, and Jordan Poole also in the top 10.&lt;/p&gt;
&lt;h2&gt;League-wide trends&lt;/h2&gt;
&lt;p&gt;I went back and did the same analysis for every non-LeBron shot over the last 20 years. The league as a whole doesn't show the same trends that LeBron does. FG% isn't correlated with number of makes of the last 5. Here are the shooting percentages, graphed on the same scale as the one I used for LeBron:&lt;/p&gt;
&lt;p&gt;&lt;img alt="league-last-5" src="/img/league-last-5.png"&gt;&lt;/p&gt;
&lt;p&gt;There's a very slight uptick when a player has made all 5 of their last 5 shots in the game, but otherwise it's remarkably flat.&lt;/p&gt;
&lt;p&gt;Looking at the order of of shots taken, the NBA as a whole shows the same rough trend as LeBron's, though less dramatically. Lower FG% on the first shot of the game, and FG% slowly going down as the number of attempts goes up. (Again, I've locked the Y axis to match the scale of LeBron's.)&lt;/p&gt;
&lt;p&gt;&lt;img alt="league-shot-seq" src="/img/league-shot-seq.png"&gt;&lt;/p&gt;
&lt;p&gt;Not a lot there in aggregate. I also looked at just higher volume shooters, but there wasn't a trend I could see there.&lt;/p&gt;
&lt;p&gt;Finally, I looked at players with a z-score over 2 (aside from LeBron). Now, by artificially selecting players with a high z-score, I need to be careful with my analysis to avoid self-fulfilling prophecy. &lt;/p&gt;
&lt;p&gt;By definition, they're going to seem more unstreaky. But it's notable they're unstreaky in the same way as LeBron -- higher shooting percentage when they're &lt;em&gt;cold&lt;/em&gt; and lower when they're &lt;em&gt;hot&lt;/em&gt;. It's not a strong trend, but it's there. They shoot 47% when they've missed their last 5 in a row, and 44.8% when they've made their last 5 in a row. If the high Z scores were solely due to chance, I wouldn't expect to see such a clear pattern in the last 5 data.&lt;/p&gt;
&lt;p&gt;&lt;img alt="high-z-last5" src="/img/high-z-last5.png"&gt;&lt;/p&gt;
&lt;h2&gt;Streaky guys&lt;/h2&gt;
&lt;p&gt;There's only one super streaky guy in the last 20 years, Ivica Zubac, with a Z score of -3.98. That's pretty crazy, but still plausibly within the realm of chance, around 1 in 30,000.&lt;/p&gt;
&lt;p&gt;The other guys with extremely streaky behavior on high volume are Dwight Powell, Nemanja Bjelica, Erick Dampier, Aaron Nesmith and Rudy Gobert, with z scores around -3. Most of those guys are big men who aren't primarily scorers. I wonder if it has something to do with rebounding their own shot. Sometimes a big man who isn't good at shooting will do what I call the Moses Malone -- miss a shot, get their own rebound, miss that, get their own rebound again, shoot again, etc, which might produce longer streaks of misses than makes.&lt;/p&gt;
&lt;p&gt;However, I don't think there's a need to deeply analyze the streaky players at this point, because it could be due to chance alone. &lt;/p&gt;
&lt;h2&gt;Goofy Nonsense&lt;/h2&gt;
&lt;p&gt;Zydrunas Ilgauskas was a longtime player for the Cleveland Cavaliers who was nicknamed "The Big Z". However, his career z score was only 1.49, so I don't think it's a statistics based nickname. Which is too bad, because the game could use some of those. "Small Z" for Ivica Zubac's -3.98 score might be confusin to people, unfortunately.&lt;/p&gt;
&lt;h2&gt;Final thoughts&lt;/h2&gt;
&lt;p&gt;If I were LeBron's coach, I'd try to talk him out of believing he has the hot hand, because as we've seen, acting like it exists has caused him to be the most &lt;em&gt;lukewarm handed&lt;/em&gt; player of the past 20 years.&lt;/p&gt;
&lt;p&gt;Shot selection shouldn't change for the worse just because a player is shooting well. LeBron on a hot streak has roughly the same shooting percentages for each type of shot as when he's not on a hot streak, or when he's on a cold streak. &lt;/p&gt;
&lt;p&gt;His innate shooting skill doesn't change, he just takes lower percentage shots, perhaps believing they're not really lower percentage shots when he's &lt;em&gt;feeling it&lt;/em&gt;. It's feel vs. real, as it often is in sports, and life in general. Regardless of feel, they're still worse shots than he would normally take.&lt;/p&gt;
&lt;p&gt;Going the other way, it's like the old joke about an airplane's black box -- if black boxes are indestructible, why don't they just build the whole airplane out of that material? If LeBron has a higher shooting percentage when he's &lt;em&gt;cold&lt;/em&gt; and decides to "go get a bucket", and that works, why doesn't he just do that on every play?&lt;/p&gt;
&lt;p&gt;I don't have a statistical answer to that question, but I do have a common sense one. In sports, part of the game is making the other team have to handle as many possibilities at a time. A quarterback in football shouldn't throw deep passes every play, because that's easy to defend. A baseball pitcher shouldn't just throw their best pitch every time, because that's easy for the hitter to anticipate. &lt;/p&gt;
&lt;p&gt;Likewise, LeBron probably shouldn't just put his head down and "get a bucket" every possession, because that's easy to plan against. LeBron wouldn't be an all time great if he only shot in the restricted area. While 3 pointers and midrange shots may have a lower expected value versus driving to the hoop, they force the defender to worry about LeBron no matter where he is on the court. But I think both as a hoops fan and a data nerd, trying to create a high percentage shot isn't a bad thing to do when a player is struggling in a game. That's especially true if a player can become less engaged in other aspects of the game when they are shooting poorly.&lt;/p&gt;</content><category term="sports analytics"></category><category term="basketball"></category><category term="the hot hand"></category></entry><entry><title>Approximate Normality and Continuity Corrections</title><link href="/approximate-normality-and-continuity-corrections.html" rel="alternate"></link><published>2025-06-08T10:20:00-10:00</published><updated>2025-06-08T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-06-08:/approximate-normality-and-continuity-corrections.html</id><summary type="html">&lt;p&gt;(Notebooks and other code available at: &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;. As usual, there is stuff in there I'm not covering here.)&lt;/p&gt;
&lt;h1&gt;What is "approximately normal"?&lt;/h1&gt;
&lt;p&gt;In the last installment, I looked at NBA game-level player data, which involve very small samples.&lt;/p&gt;
&lt;p&gt;Like a lot of things in statistics, the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(Notebooks and other code available at: &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;. As usual, there is stuff in there I'm not covering here.)&lt;/p&gt;
&lt;h1&gt;What is "approximately normal"?&lt;/h1&gt;
&lt;p&gt;In the last installment, I looked at NBA game-level player data, which involve very small samples.&lt;/p&gt;
&lt;p&gt;Like a lot of things in statistics, the Wald Wolfowitz test says that the number of streaks is approximately normal. What does that mean in practical terms? How approximately are we talking?&lt;/p&gt;
&lt;p&gt;The number of streaks is a discrete value (0,1,2,3,...). In a small sample like 2 makes and 3 misses, which will be extremely common in player game level shooting data, how could that be &lt;em&gt;approximately normal&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Below is a bar chart of the exact probabilities of each number of streaks, overlaid with the normal approximation in white. Not very normal, is it?&lt;/p&gt;
&lt;p&gt;&lt;img alt="not very normal" src="/img/not-very-normal.png"&gt;&lt;/p&gt;
&lt;p&gt;To make things more interesting, let's say the player made 7 shots and missed 4. That's enough for the graph to look more like a proper bell curve.&lt;/p&gt;
&lt;p&gt;&lt;img alt="exact 7-4 (or 4-7)" src="/img/exact-7-4.png"&gt;&lt;/p&gt;
&lt;p&gt;The bell curve looks skewed relative to the histogram, right? That's what happens when you model a discrete distribution (the number of streaks) with a continuous one -- the normal distribution.&lt;/p&gt;
&lt;p&gt;A continuous distribution has zero probability at any single point, so we calculate the area under the curve between a range of values. The bar for exactly 7 streaks should line up with the probability of between 6.5 and 7.5 streaks in the normal approximation. The curve should be going through the middle of each bar, not the left edge.&lt;/p&gt;
&lt;p&gt;We need to shift the curve to the right a half a streak for things to line up. Fixing this is called &lt;a href="https://en.wikipedia.org/wiki/Continuity_correction"&gt;continuity correction&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's the same graph with the continuity correction applied:&lt;/p&gt;
&lt;p&gt;&lt;img alt="with cc" src="/img/with-cc.png"&gt;&lt;/p&gt;
&lt;p&gt;So... better, but there's still a problem. The normal approximation will assign a nonzero probability to impossible things. In this case of 7 makes and 4 misses, the minimum possible number of streaks is 2 and the max is 9 (alternate wins and losses till you run out of losses, then have a string of wins at the end.)&lt;/p&gt;
&lt;p&gt;Yet the normal approximation says there's a nonzero chance of -1, 10, or even a million streaks. The odds are tiny, but the normal distribution never ends. These differences go away with big sample sizes, but they may be worth worrying about for small sample sizes.&lt;/p&gt;
&lt;p&gt;Is that interfering with my results? It's quite possible. I'm trying to use the mean and the standard deviation to decide how "weird" each player is in the form of a z score. The z score gives the likelihood of the data happening by chance, given certain assumptions. If the assumptions don't hold, the z score, and using it to interpret how &lt;em&gt;weird&lt;/em&gt; things are, is suspect.&lt;/p&gt;
&lt;h2&gt;Exact-ish odds&lt;/h2&gt;
&lt;p&gt;We can easily calculate the exact odds. In the notebook, I showed how to calculate the odds with brute force -- generate all permutations of seven 1's and four 0's, and measure the number of streaks for each one. That's impractical and silly, since the exact counting formula can be worked out using the rules of combinatorics, as this page nicely shows:  &lt;a href="https://online.stat.psu.edu/stat415/lesson/21/21.1"&gt;https://online.stat.psu.edu/stat415/lesson/21/21.1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In order to compare players with different numbers of makes and misses, we'd want to calculate a percentile value for each one from the exact odds. The percentiles will be based on number of streaks, so 1st percentile would be super streaky, 99th percentile super un-streaky.&lt;/p&gt;
&lt;p&gt;Let's say we're looking at the case of 7 makes and 4 misses, and are trying to calculate the percentile value that should go with each number of streaks.  Here are the exact odds of each number of streaks:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.006061&lt;/span&gt;
&lt;span class="mf"&gt;3&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.027273&lt;/span&gt;
&lt;span class="mf"&gt;4&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.109091&lt;/span&gt;
&lt;span class="mf"&gt;5&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.190909&lt;/span&gt;
&lt;span class="mf"&gt;6&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.272727&lt;/span&gt;
&lt;span class="mf"&gt;7&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.227273&lt;/span&gt;
&lt;span class="mf"&gt;8&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.121212&lt;/span&gt;
&lt;span class="mf"&gt;9&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.045455&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here are the cumulative odds (the odds of getting that number of streaks or fewer):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.006061&lt;/span&gt;
&lt;span class="mf"&gt;3&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.033333&lt;/span&gt;
&lt;span class="mf"&gt;4&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.142424&lt;/span&gt;
&lt;span class="mf"&gt;5&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.333333&lt;/span&gt;
&lt;span class="mf"&gt;6&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.606061&lt;/span&gt;
&lt;span class="mf"&gt;7&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.833333&lt;/span&gt;
&lt;span class="mf"&gt;8&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;0.954545&lt;/span&gt;
&lt;span class="mf"&gt;9&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mf"&gt;1.000000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let's say we get 6 streaks. Exactly 6 streaks happens 27% of the time. 5 or fewer streaks happens 33% of the time. So we could say 6 streaks is equal to the 33rd percentile, the &lt;code&gt;33.3%+27.3% = 61&lt;/code&gt;st percentile, or some value in between those two numbers.&lt;/p&gt;
&lt;p&gt;The obvious way of deciding the &lt;a href="https://en.wikipedia.org/wiki/Percentile_rank"&gt;percentile rank&lt;/a&gt; is to take the average of the upper and lower values, in this case &lt;code&gt;mean(.333, .606) = .47&lt;/code&gt;. You could also think of it as taking the probability of &lt;code&gt;streaks &amp;lt;=5&lt;/code&gt; and adding half the probability of &lt;code&gt;streaks=6&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If we want to compare the percentile ranks from the exact odds to Wald-Wolfowitz, we could convert them to an equivalent z score. Or, we can take the z-scores from the Wald Wolfowitz test and convert them to percentiles.&lt;/p&gt;
&lt;p&gt;The two are bound to be a little different because the normal approximation is a bell curve, whereas we're getting the percentile rank from a linear interpolation of two values.&lt;/p&gt;
&lt;p&gt;Here's an illustration of what I mean. This is a graph of the percentile ranks vs the CDF of the normal approximation.&lt;/p&gt;
&lt;p&gt;&lt;img alt="cdf-normal-exact2" src="/img/cdf-normal-exact2.png"&gt;&lt;/p&gt;
&lt;p&gt;Let's zoom in on the section between 4.5 and 5.5 streaks. Where the white line hits the red line is the percentile estimate we'd get from the z-score (.475).&lt;/p&gt;
&lt;p&gt;&lt;img alt="cdf-zoom" src="/img/cdf-zoom.png"&gt;&lt;/p&gt;
&lt;p&gt;The green line is a straight line that represents calculating the percentile rank. It goes from the middle of the top of the &lt;code&gt;runs &amp;lt;= 5&lt;/code&gt; bar to the middle of the top of the &lt;code&gt;runs &amp;lt;=6&lt;/code&gt; bar. Where it hits the red line is the average of the two, which is percentile rank (.470).&lt;/p&gt;
&lt;p&gt;In other situations, the Wald-Wolfowitz estimate will be less than the exact percentile rank. We can see that on the first graph. The green lines and white line are very close to each other, but sometimes the green is higher (like at runs=4), and sometimes the white is higher (like at runs=8).&lt;/p&gt;
&lt;h2&gt;Is Wald-Wolfowitz unbiased?&lt;/h2&gt;
&lt;p&gt;Yeah. The test provides the exact expected value of the number of streaks. It's not just a pretty good estimate. It is the (weighted) mean of the exact probabilities.&lt;/p&gt;
&lt;p&gt;From the exact odds, the mean of all the streak lengths is 6.0909:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    330.000000
mean       6.090909
std        1.445329
min        2.000000
25%        5.000000
50%        6.000000
75%        7.000000
max        9.000000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The Wald-Wolfowitz test says the expected value is 1 plus the harmonic mean of 7 and 4, which is 6.0909... on the nose.&lt;/p&gt;
&lt;h2&gt;Is the normal approximation throwing off my results?&lt;/h2&gt;
&lt;p&gt;Quite possibly. So I went back and calculated the percentile ranks for every player-game combo over the course of the season.&lt;/p&gt;
&lt;p&gt;Here's a scatter plot of the two ways to calculate the percentile on actual NBA player games. The dots above the x=y line are where the Wald-Wolfowitz percentile is bigger than the percentile rank one.&lt;/p&gt;
&lt;p&gt;&lt;img alt="percentile-vs-ww" src="/img/percentile-vs-ww.png"&gt;&lt;/p&gt;
&lt;p&gt;59% of the time, the Wald-Wolfowitz estimate produces a higher percentile value than the percentile rank. The same trend occurs if I restrict the data set to only high volume shooters (more than 10 makes or misses on the game).&lt;/p&gt;
&lt;p&gt;Here's a bar chart of the differences between the W-W percentile and the percentile rank:&lt;/p&gt;
&lt;p&gt;&lt;img alt="ww-minus-pr" src="/img/ww-minus-pr.png"&gt;&lt;/p&gt;
&lt;p&gt;A percentile over 50, or a positive z score, means more streaks than average, thus less streaky than average. In other words, &lt;em&gt;on this specific data set&lt;/em&gt;, the Wald-Wolfowitz z-scores will be more un-streaky compared to the exact probabilities.&lt;/p&gt;
&lt;h2&gt;Interlude: our un-streaky king&lt;/h2&gt;
&lt;p&gt;For the record, the un-streakiest NBA game of the 2023-24 season was by Dejounte Murray on 4/9/2024. My dude went 12 for 31 and managed 25 streaks, the most possible for that number of makes and misses, by virtue of never making 2 shots in a row.&lt;/p&gt;
&lt;p&gt;It was a crazy game all around for Murray. A 29-13-13 triple double with 4 steals, and a Kobe-esque 29 points on 31 shots. He could've gotten more, too. The game went to double overtime, and he missed his last 4 in a row. If he had made the 2nd and the 4th of those, he could've gotten 4 more streaks on the game.&lt;/p&gt;
&lt;p&gt;The summary of the game doesn't mention this exceptional achievement. Of course they wouldn't. There's no clue of it in the box score. You couldn't bet on it. Why would anyone notice?&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.basketball-reference.com/boxscores/202404090ATL.html"&gt;box score on bbref&lt;/a&gt;    &lt;/p&gt;
&lt;p&gt;Look at that unstreakiness. Isn't it beautiful?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;makes&lt;/span&gt;&lt;span class="w"&gt;                                                  &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;
&lt;span class="n"&gt;misses&lt;/span&gt;&lt;span class="w"&gt;                                                 &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;
&lt;span class="n"&gt;total_streaks&lt;/span&gt;&lt;span class="w"&gt;                                          &lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;
&lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="w"&gt;                  &lt;/span&gt;&lt;span class="n"&gt;LWLWLWLWLWLWLLWLLLWLWLWLWLWLLLL&lt;/span&gt;
&lt;span class="n"&gt;expected_streaks&lt;/span&gt;&lt;span class="w"&gt;                                &lt;/span&gt;&lt;span class="mf"&gt;15.709677&lt;/span&gt;
&lt;span class="n"&gt;variance&lt;/span&gt;&lt;span class="w"&gt;                                         &lt;/span&gt;&lt;span class="mf"&gt;6.722164&lt;/span&gt;
&lt;span class="n"&gt;z_score&lt;/span&gt;&lt;span class="w"&gt;                                          &lt;/span&gt;&lt;span class="mf"&gt;3.583243&lt;/span&gt;
&lt;span class="n"&gt;exact_percentile_rank&lt;/span&gt;&lt;span class="w"&gt;                           &lt;/span&gt;&lt;span class="mf"&gt;99.993423&lt;/span&gt;
&lt;span class="n"&gt;z_from_percentile_rank&lt;/span&gt;&lt;span class="w"&gt;                           &lt;/span&gt;&lt;span class="mf"&gt;3.823544&lt;/span&gt;
&lt;span class="n"&gt;ww_percentile&lt;/span&gt;&lt;span class="w"&gt;                                   &lt;/span&gt;&lt;span class="mf"&gt;99.983032&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On the other end, the streakiest performance of the year belonged to Jabari Walker of the Portland Trail Blazers. Made his first 6 shots in a row, then missed his last 8 in a row.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;makes&lt;/span&gt;&lt;span class="w"&gt;                                  &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;
&lt;span class="n"&gt;misses&lt;/span&gt;&lt;span class="w"&gt;                                 &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;total_streaks&lt;/span&gt;&lt;span class="w"&gt;                          &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="w"&gt;                  &lt;/span&gt;&lt;span class="n"&gt;WWWWWWLLLLLLLL&lt;/span&gt;
&lt;span class="n"&gt;expected_streaks&lt;/span&gt;&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="mf"&gt;7.857143&lt;/span&gt;
&lt;span class="n"&gt;variance&lt;/span&gt;&lt;span class="w"&gt;                        &lt;/span&gt;&lt;span class="mf"&gt;3.089482&lt;/span&gt;
&lt;span class="n"&gt;z_score&lt;/span&gt;&lt;span class="w"&gt;                        &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;3.332292&lt;/span&gt;
&lt;span class="n"&gt;exact_percentile_rank&lt;/span&gt;&lt;span class="w"&gt;             &lt;/span&gt;&lt;span class="mf"&gt;0.0333&lt;/span&gt;
&lt;span class="n"&gt;z_from_percentile_rank&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;3.403206&lt;/span&gt;
&lt;span class="n"&gt;ww_percentile&lt;/span&gt;&lt;span class="w"&gt;                   &lt;/span&gt;&lt;span class="mf"&gt;0.043067&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Actual player performances&lt;/h2&gt;
&lt;p&gt;Let's look at actual NBA games where a player had exactly 7 makes and 4 misses. (We can also include the flip side, 4 makes and 7 misses, because it will be the same distribution of streak lengths)&lt;/p&gt;
&lt;p&gt;The green areas are where the players had more streaks than the exact probabilities; the red areas are where players had fewer streaks. The two are very close, except for a lot more games with 9 streaks in the player data, and fewer 6 streak games.&lt;/p&gt;
&lt;p&gt;The exact mean is 6.09 streaks. The mean for player performances is 6.20 streaks. Even in this little slice of data, there's a slight tendency towards unstreakiness.&lt;/p&gt;
&lt;p&gt;&lt;img alt="streaks-vs-probs" src="/img/streaks-vs-probs.png"&gt;&lt;/p&gt;
&lt;h2&gt;Percentile ranks are still unstreaky, though&lt;/h2&gt;
&lt;p&gt;Well, for all that windup, the game-level percentile ranks didn't turn out all that different when I calcualted them for all 18,000+ player-game combos. The mean and median are still shifted to the un-streaky side, to a significant degree.&lt;/p&gt;
&lt;p&gt;&lt;img alt="z-from-percentile" src="/img/z-from-percentile.png"&gt;&lt;/p&gt;
&lt;p&gt;Plotting the deciles shows an interesting tendency: a lot more values in the 60-70th percentile range than expected. the shift to the un-streaky side comes pretty much from these values.&lt;/p&gt;
&lt;p&gt;&lt;img alt="perc-rank-deciles" src="/img/perc-rank-deciles.png"&gt;&lt;/p&gt;
&lt;p&gt;The bias towards the unstreaky side is still there, and still significant:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    18982.000000
mean         0.039683
std          0.893720
min         -3.403206
25%         -0.643522
50%          0.059717
75%          0.674490
max          3.823544
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;A weird continuity correction that seems obviously bad&lt;/h2&gt;
&lt;p&gt;SAS, the granddaddy of statistics software, applies a continuity correction to the runs test whenever the count is less than 50.&lt;/p&gt;
&lt;p&gt;While it's true that we should be careful with normal approximations and small sample size, this ain't the way.&lt;/p&gt;
&lt;p&gt;The exact code used is here: &lt;a href="https://support.sas.com/kb/33/092.html"&gt;https://support.sas.com/kb/33/092.html&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;N&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;GE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Runs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;mu&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;sigma&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Runs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;mu&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;LT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Runs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;mu&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sigma&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Runs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;mu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sigma&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Other implementations I looked at, like the one in R's &lt;a href="https://www.rdocumentation.org/packages/randtests/versions/1.0.1/topics/runs.test"&gt;&lt;code&gt;randtests&lt;/code&gt; package&lt;/a&gt;, don't do the correction.&lt;/p&gt;
&lt;p&gt;What does this sort of correction look like?&lt;/p&gt;
&lt;p&gt;For starters, it gives us something that doesn't look like a z score. The std is way too small.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    18982.000000
mean        -0.031954
std          0.687916
min         -3.047828
25%         -0.401101
50%          0.000000
75%          0.302765
max          3.390395
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="sas-cc" src="/img/sas-cc.png"&gt;&lt;/p&gt;
&lt;h3&gt;What does this look like on random data?&lt;/h3&gt;
&lt;p&gt;It could just be this dataset, though. I will generate a fake season of data like in the last installment, but the players will have no unstreaky/streaky tendencies. They will behave like a coin flip, weighted to their season FG%. So the results should be distributed like we expect z scores to be (mean=0, std=1)&lt;/p&gt;
&lt;p&gt;Here are the z-scores. They're not obviously bad, but the center is a bit higher than it should be.&lt;/p&gt;
&lt;p&gt;&lt;img alt="sas-sim" src="/img/sas-sim.png"&gt;&lt;/p&gt;
&lt;p&gt;However, the continuity correction especially stands out when looking at small sample sizes (in this case, simulated players with fewer than 30 shooting streaks over the course of the season).&lt;/p&gt;
&lt;p&gt;In the below graph, red are the SAS corrected z-scores, green are the wald-wolfowitz z scores, brown are the overlap.&lt;/p&gt;
&lt;p&gt;&lt;img alt="sas-low-vol" src="/img/sas-low-vol.png"&gt;&lt;/p&gt;
&lt;p&gt;Continuity corrections are at best an imperfect substitute for calculating the exact odds. These days, there's no reason not to use exact odds for smaller sample sizes. Even though it ended up not mattering much, I should've started with the percentile rank for individual games. However, I don't think that the game level results are as important to the case I'm making as the career-long shooting results.&lt;/p&gt;
&lt;p&gt;Next time, I will look at the past 20 years of NBA data. Who is the un-streakiest player of all time?&lt;/p&gt;</content><category term="statistics"></category><category term="basketball"></category><category term="the hot hand"></category></entry><entry><title>Simulating hot and lukewarm hands</title><link href="/simulating-hot-and-lukewarm-hands.html" rel="alternate"></link><published>2025-05-28T10:20:00-10:00</published><updated>2025-05-28T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-05-28:/simulating-hot-and-lukewarm-hands.html</id><summary type="html">&lt;p&gt;(Notebooks and other code available at: &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;. There's a bunch of stuff in the notebook about the Wald-Wolfowitz test that I will save for another week.)&lt;/p&gt;
&lt;p&gt;In my last installment, I was looking at season long shooting records from the NBA, and I concluded that NBA …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(Notebooks and other code available at: &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;. There's a bunch of stuff in the notebook about the Wald-Wolfowitz test that I will save for another week.)&lt;/p&gt;
&lt;p&gt;In my last installment, I was looking at season long shooting records from the NBA, and I concluded that NBA players were less streaky than expected. They have fewer long strings of makes and misses than a series of coin flips would.&lt;/p&gt;
&lt;p&gt;I've been thinking this could be due to "heat check" shots -- a player has made a bunch of shots in a row, or are having a good shooting game in general, so they take harder shots than they normally take. 
It would explain some players that fans consider streaky or "heat check" players who are actually super un-streaky. Jordan Poole was the least streaky player over the last 4 seasons, which defies my expectations. Say he believes he is streaky, so tends to take bad shots when&lt;/p&gt;
&lt;p&gt;Or it could be due to "get a bucket" shots -- a player is having a bad shooting game, so they force higher percentage shots and potentially free throws. &lt;/p&gt;
&lt;p&gt;There's a quirk of NBA stats to remember: if a player is fouled while shooting, it only counts as a field goal attempt if they make the shot. So driving to the hoop is guaranteed to not decrease a player's field goal percentage if they successfully draw a foul, or get called for an offensive foul.&lt;/p&gt;
&lt;p&gt;I'm not sure I've made an airtight case for the &lt;em&gt;lukewarm hand&lt;/em&gt;. Combining every game in a season could hide the hot hand effect. What about individual games?&lt;/p&gt;
&lt;h2&gt;Game-level shooting statistics show a lukewarm tendency&lt;/h2&gt;
&lt;p&gt;I am using the complete shooting statistics available from this kaggle project: &lt;a href="https://www.kaggle.com/datasets/mexwell/nba-shots"&gt;https://www.kaggle.com/datasets/mexwell/nba-shots&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I'm looking at the 2023-2024 season, since the current season isn't included yet.&lt;/p&gt;
&lt;p&gt;I went through every game that every player played in the NBA season and calculated the expected vs. actual number of streaks.  &lt;/p&gt;
&lt;p&gt;There are 24,895 player+game combos. 10,285 of them had more streaks than expected against 8,977 who had fewer streaks than expected (and around 5,000 that are exactly as expected). This is a significant imbalance towards the "lukewarm hand" side.&lt;/p&gt;
&lt;p&gt;Here's the histogram of individual game z-scores:&lt;/p&gt;
&lt;p&gt;&lt;img alt="individual game z-scores, 2023" src="/img/game-zscores-2023.png"&gt;&lt;/p&gt;
&lt;p&gt;And the breakdown:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;count&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="m m-Double"&gt;18982.000000&lt;/span&gt;
&lt;span class="nx"&gt;mean&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="m m-Double"&gt;0.051765&lt;/span&gt;
&lt;span class="nx"&gt;std&lt;/span&gt;&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="m m-Double"&gt;0.988789&lt;/span&gt;
&lt;span class="nx"&gt;min&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m m-Double"&gt;3.332292&lt;/span&gt;
&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m m-Double"&gt;0.707107&lt;/span&gt;
&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="m m-Double"&gt;0.104103&lt;/span&gt;
&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="m m-Double"&gt;0.816497&lt;/span&gt;
&lt;span class="nx"&gt;max&lt;/span&gt;&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="m m-Double"&gt;3.583243&lt;/span&gt;
&lt;span class="nx"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;z_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;float64&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Limiting to higher volume games (at least 10 makes or 10 misses) shows the same tendency.&lt;/p&gt;
&lt;p&gt;&lt;img alt="high attempt games, 2023-24" src="/img/high-attempt-games.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;count&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="m m-Double"&gt;2536.000000&lt;/span&gt;
&lt;span class="nx"&gt;mean&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="m m-Double"&gt;0.055925&lt;/span&gt;
&lt;span class="nx"&gt;std&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="m m-Double"&gt;1.010195&lt;/span&gt;
&lt;span class="nx"&gt;min&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m m-Double"&gt;3.079575&lt;/span&gt;
&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m m-Double"&gt;0.616678&lt;/span&gt;
&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="m m-Double"&gt;0.072404&lt;/span&gt;
&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="m m-Double"&gt;0.750366&lt;/span&gt;
&lt;span class="nx"&gt;max&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="m m-Double"&gt;3.583243&lt;/span&gt;
&lt;span class="nx"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;z_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;float64&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There definitely appears to be a bias towards the lukewarm hand in individual game data. The mean z scores aren't that much bigger than zero, but it's a huge sample size.&lt;/p&gt;
&lt;h2&gt;Simulating streaky and non-streaky players&lt;/h2&gt;
&lt;p&gt;I coded up a simulation of a non-streaky player. When they have hit a minimum number of attempts in the game, if their shooting percentage goes above a certain level, they get a penalty. If it goes below a certain level, they get a boost.&lt;/p&gt;
&lt;p&gt;I was able to create results that look like NBA players in aggregate with an extremely simplified model. The parameters were arbitrarily chosen&lt;/p&gt;
&lt;p&gt;By default, the thresholds are 20% and 80%, and the boost/penalty is 20%. So a 50% shooter who has taken at least 4 shots and is shooting 80% or better for the game will get their FG% knocked down to 30% till their game percentage drops below the threshold. Likewise if they hit 20% or less, they get a boost until they're over the threshold.&lt;/p&gt;
&lt;p&gt;I used the game level shooting statistics I got for the individual game-by-game analysis. I then replayed every shot in the NBA in the 2023-24 season using the simulated lukewarm player (and the actual fg% and number of shots attempted in each game). This is what I got:&lt;/p&gt;
&lt;p&gt;&lt;img alt="sim-z-scores" src="/img/sim-z-scores.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;count&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="m m-Double"&gt;526.000000&lt;/span&gt;
&lt;span class="nx"&gt;mean&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="m m-Double"&gt;0.218032&lt;/span&gt;
&lt;span class="nx"&gt;std&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="m m-Double"&gt;0.965737&lt;/span&gt;
&lt;span class="nx"&gt;min&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m m-Double"&gt;2.397958&lt;/span&gt;
&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m m-Double"&gt;0.491051&lt;/span&gt;
&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="m m-Double"&gt;0.241554&lt;/span&gt;
&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="m m-Double"&gt;0.836839&lt;/span&gt;
&lt;span class="nx"&gt;max&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="m m-Double"&gt;3.787951&lt;/span&gt;
&lt;span class="nx"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;z_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;float64&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;My simulation was actually less biased to the right than the actual results:&lt;/p&gt;
&lt;p&gt;&lt;img alt="actual-2023-24" src="/img/actual-2023-24.png"&gt;&lt;/p&gt;
&lt;p&gt;Several big things to note:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I simulated every player in the league as being a little un-streaky.&lt;/li&gt;
&lt;li&gt;I simulated them being un-streaky in both directions&lt;/li&gt;
&lt;li&gt;The boost/penalty are pretty big -- going from 50% FG percentage to 30% is going from a good NBA player to a bad college player level, and the boost to 70% FG percentage has no precedent. The most accurate shooters in the NBA are usually big men who only shoot dunks and layups, and they still usually end up in the 60-65% range.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Which is to say, my simulation is kind of silly and seemingly over-exaggerated. And it's still not as lukewarm as real NBA players are.  Wild, isn't it?&lt;/p&gt;
&lt;h2&gt;Streakiness in only one direction&lt;/h2&gt;
&lt;p&gt;I also simulated players who were only streaky in one direction: "get a bucket" players who get a boost to shooting percentage when they are shooting poorly, but no penalty when they are doing well, and "heat check" players who only get the penalty.&lt;/p&gt;
&lt;p&gt;The results were biased to the unstreaky side, but about half as much as the ones that are streaky in both directions. I had to crank the penalties/boosts up to unrealistic levels to get the bias of the z-scores up to the .2-.3 range I'm seeing with real season-level data.&lt;/p&gt;
&lt;h2&gt;The truly streaky player&lt;/h2&gt;
&lt;p&gt;Of course, I had to simulate the hot hand. The &lt;code&gt;TrulyStreakyPlayer&lt;/code&gt; is the exact opposite of the &lt;code&gt;LukewarmPlayer&lt;/code&gt;. They get a 20% boost when they're shooting well on the game, and a 20% penalty when they're shooting poorly.&lt;/p&gt;
&lt;p&gt;What stands out to me here is how much it affects the z-score. I was expecting the z-scores to be biased to the negative side by about as much as the unstreaky player was to the positive side. But the effect was a lot more dramatic:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    524.000000
mean      -0.455522
std        1.144570
min       -4.413268
25%       -1.225128
50%       -0.458503
75%        0.404549
max        2.486584
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="truly-streaky-player" src="/img/truly-streaky-player.png"&gt;&lt;/p&gt;
&lt;p&gt;Unlike the un-streaky simulations, the streaky behavior increased the dispersion (&lt;code&gt;std&lt;/code&gt;), like we saw with the real shot data. There are many more outliers to the negative side than we'd expect.&lt;/p&gt;
&lt;h2&gt;What next?&lt;/h2&gt;
&lt;p&gt;I could certainly sim a mixture of streaky and unstreaky players, and eventually maybe get something that matches the real numbers pretty closely. But there are so many parameters to fit that it would be pretty arbitrary. Someone else could produce a different model that works just as well. &lt;/p&gt;
&lt;p&gt;Most importantly, it couldn't tell us which players might be streaky due to chance versus streaky due to behavior/shot selection. So I think the next step is looking at the shot selection in the "hot hand" vs. "get a bucket" situations -- do players switch to higher percentage shots when they're having a bad game, and worse shots when they're shooting better than usual?&lt;/p&gt;</content><category term="sports analytics"></category><category term="basketball"></category><category term="the hot hand"></category></entry><entry><title>What are the most important events at the NFL Combine?</title><link href="/what-are-the-most-important-events-at-the-nfl-combine.html" rel="alternate"></link><published>2025-05-23T10:20:00-10:00</published><updated>2025-05-23T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-05-23:/what-are-the-most-important-events-at-the-nfl-combine.html</id><summary type="html">&lt;p&gt;(the code used is available at &lt;a href="https://github.com/csdurfee/nfl_combine_data/"&gt;https://github.com/csdurfee/nfl_combine_data/&lt;/a&gt;).&lt;/p&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;Every year, the National Football League hosts an event called the Combine, where teams can evaluate the top prospects before the upcoming draft.&lt;/p&gt;
&lt;p&gt;Athletes are put through a series of physical and mental tests over the course of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(the code used is available at &lt;a href="https://github.com/csdurfee/nfl_combine_data/"&gt;https://github.com/csdurfee/nfl_combine_data/&lt;/a&gt;).&lt;/p&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;Every year, the National Football League hosts an event called the Combine, where teams can evaluate the top prospects before the upcoming draft.&lt;/p&gt;
&lt;p&gt;Athletes are put through a series of physical and mental tests over the course of four days. There is a lot of talk of hand size, arm length, and whether a guy looks athletic enough when he's running with his shirt off. It's basically the world's most invasive job interview. &lt;/p&gt;
&lt;p&gt;NFL teams have historically put a lot of stock in the results of the combine. A good showing at the combine can improve a player's career prospects, and a bad showing can significantly hurt them. For that reason, some players will opt out of attending the combine, but that can backfire as well.&lt;/p&gt;
&lt;p&gt;I was curious about which events in the combine correlate most strongly with draft position. There are millions of dollars at stake. The first pick in the NFL draft gets a $43 Million dollar contract, the 33rd pick gets $9.6 Million, and the 97th pick gets $4.6 Million.&lt;/p&gt;
&lt;p&gt;The main events of the combine are the 40 yard dash, vertical leap, bench press, broad jump, 3 cone drill and shuttle drill. The shuttle drill and the 3 cone drill are pretty similar -- a guy running between some cones as fast as possible. The other drills are what they sound like.&lt;/p&gt;
&lt;p&gt;I'm taking the data from Pro Football Reference. Example page: &lt;a href="https://www.pro-football-reference.com/draft/2010-combine.htm"&gt;https://www.pro-football-reference.com/draft/2010-combine.htm&lt;/a&gt;. I'm only looking at players who got drafted.&lt;/p&gt;
&lt;h2&gt;Position Profiles&lt;/h2&gt;
&lt;p&gt;It makes no sense to compare a cornerback's bench press numbers to a defensive lineman's. There are vast differences in the job requirements. A player in the combine is competing against other players at the same position. &lt;/p&gt;
&lt;p&gt;The graph shows a position's performance on each exercise relative to all players. The color indicates how the position as a whole compares to the league as a whole. You can change the selected position with the dropdown.&lt;/p&gt;
&lt;iframe src="/img/position_view_2025.html" width="550" height="450" frameborder="0"&gt;&lt;/iframe&gt;

&lt;p&gt;Cornerbacks are exceptional on the 40 yard dash and shuttle drills compared to NFL athletes as a whole, whereas defensive linemen are outliers when it comes high bench press numbers, and below average at every other event. Tight Ends and Linebackers are near the middle in every single event, which makes sense because both positions need to be strong enough to deal with the strong guys, and fast enough to deal with the fast guys.&lt;/p&gt;
&lt;h2&gt;Importance of Events by Position&lt;/h2&gt;
&lt;p&gt;I analyzed how a player's performance relative to others at their position correlates with draft rank. Pro-Football-Reference has combine data going back to 2000.  I have split the data up into 2000-2014 and 2015-2025 to look at how things have changed. &lt;/p&gt;
&lt;p&gt;For each position, the exercises are ranked from most to least important. The tooltip gives the exact r^2 value.&lt;/p&gt;
&lt;p&gt;Here are the results up to 2014:&lt;/p&gt;
&lt;iframe src="/img/before_2015.html" width="800" height="700" frameborder="0"&gt;&lt;/iframe&gt;

&lt;p&gt;Here are the last 10 years:&lt;/p&gt;
&lt;iframe src="/img/after_2015.html" width="800" height="700" frameborder="0"&gt;&lt;/iframe&gt;

&lt;p&gt;Some things I notice:&lt;/p&gt;
&lt;p&gt;The main combine events matter that much either way for offensive and defensive linemen. That's held true for 25 years.&lt;/p&gt;
&lt;p&gt;The shuttle and 3 cone drill have gone up significantly in importance for tight ends.&lt;/p&gt;
&lt;p&gt;Broad jump and 40 yard dash are important for just about every position. However, the importance of the 40 yard dash time has gone down quite a bit for running backs. &lt;/p&gt;
&lt;p&gt;As a fan, it used to be a huge deal when a running back posted an exceptional 40 yard time. It seemed Chris Johnson's legendary 4.24 40 yard time was referenced every year. But I remember there being lot of guys who got drafted in the 2000's primarily based on speed who turned out to not be very good. &lt;/p&gt;
&lt;p&gt;The bench press is probably the least important exercise across the board. There's almost no correlation between performance and draft order, for every position. Offensive and defensive linemen basically bench press each other for 60 minutes straight; for everybody else, that sort of strength is less relevant.  Here's one of the greatest guys at throwing the football in human history, Tom Brady:&lt;/p&gt;
&lt;p&gt;&lt;img alt="behold" src="/img/Tom-Brady-Combine.png"&gt;&lt;/p&gt;
&lt;p&gt;Compared to all quarterbacks who have been drafted since 2000, Brady's shuttle time was in the top 25%, his 3 cone time was in the top 50%, and his broad jump, vertical leap and 40 yard dash were all in the bottom 25%.&lt;/p&gt;
&lt;h2&gt;Changes in combine performance over time&lt;/h2&gt;
&lt;p&gt;Athlete performance has changed over time. &lt;/p&gt;
&lt;p&gt;I've plotted average performance by year for each of the events. For the 40 yard dash, shuttle, and 3 cone drills, lower is better, and for the other events, higher is better.&lt;/p&gt;
&lt;p&gt;&lt;img alt="change over time" src="/img/combine-trends.png"&gt;&lt;/p&gt;
&lt;p&gt;40 yard dash times and broad jump distances have clearly improved, whereas shuttle times and bench press reps have gotten slightly worse.&lt;/p&gt;
&lt;p&gt;There's a cliche in sports that "you can't coach speed".  While some people are innately faster than others, the 40 yard dash is partly a skill exercise -- learning to get off the block as quickly as possible without faulting, for starters. The high priority given to the 40 yard dash should lead to prospects practicing it more, and thus getting better numbers.&lt;/p&gt;
&lt;p&gt;The bench press should be going down or staying level, since it's not very important to draft position.&lt;/p&gt;
&lt;p&gt;There's been a significant improvement in the broad jump - about 7.5% over 25 years. As with the 40 yard dash, I'd guess it's better coaching and preparation. Perhaps it's easier to improve than some of the other events. I don't think there's more broad jumping in an NFL game than there was 25 years ago.&lt;/p&gt;
&lt;p&gt;Shuttle times getting slightly worse is a little surprising. It's very similar to the 3 Cone drill, which has slightly improved. But as we saw, neither one is particularly important as far as draft position, and it's not a strong trend.&lt;/p&gt;
&lt;h2&gt;Caveats&lt;/h2&gt;
&lt;p&gt;Some of the best athletes skip the combine entirely, because their draft position is already secure. And some athletes will only choose to do the exercises they think they will do well at, and skip their weak events. This is known as &lt;a href="https://www.ncbi.nlm.nih.gov/books/NBK493614/"&gt;MNAR data&lt;/a&gt; (missing, not at random). All analysis of MNAR data is potentially biased.&lt;/p&gt;
&lt;p&gt;I'm assuming a linear relationship between draft position and performance. It's possible that a good performance helps more than a bad performance hurts, or vice versa.&lt;/p&gt;
&lt;p&gt;I didn't calculate statistical significance for anything. Some correlations will occur even in random data. This isn't meant to be rigorous.&lt;/p&gt;</content><category term="sports analytics"></category><category term="football"></category></entry><entry><title>Majority Voting in Ensemble Learning</title><link href="/majority-voting-in-ensemble-learning.html" rel="alternate"></link><published>2025-05-22T10:20:00-10:00</published><updated>2025-05-22T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-05-22:/majority-voting-in-ensemble-learning.html</id><summary type="html">&lt;p&gt;(notebook is available at &lt;a href="https://github.com/csdurfee/ensemble_learning/blob/main/ensemble_voting.ipynb"&gt;github.com/csdurfee/ensemble_learning&lt;/a&gt;.)&lt;/p&gt;
&lt;h2&gt;Ensemble Learning&lt;/h2&gt;
&lt;p&gt;AI and machine learning systems are often used for classification. Is this email spam or not? Is this person a good credit risk or not? Is this a photo of a cat or not?&lt;/p&gt;
&lt;p&gt;There are a lot of ways …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(notebook is available at &lt;a href="https://github.com/csdurfee/ensemble_learning/blob/main/ensemble_voting.ipynb"&gt;github.com/csdurfee/ensemble_learning&lt;/a&gt;.)&lt;/p&gt;
&lt;h2&gt;Ensemble Learning&lt;/h2&gt;
&lt;p&gt;AI and machine learning systems are often used for classification. Is this email spam or not? Is this person a good credit risk or not? Is this a photo of a cat or not?&lt;/p&gt;
&lt;p&gt;There are a lot of ways to build classifiers, and they all potentially have different strengths and weaknesses. It's natural to try combining multiple models together to produce better results than the individual models would. &lt;/p&gt;
&lt;p&gt;Model A might be bad at classifying black cats but good at orange ones, model B might be bad at classifying orange cats but good at black ones, model C is OK at both. So if we average together the results of the three classifiers, or go with the majority opinion between them, the results might be better than the individual classifiers.&lt;/p&gt;
&lt;p&gt;This is called an ensemble. Random forests and gradient boosting are two popular machine learning techniques that use ensembles of &lt;em&gt;weak learners&lt;/em&gt; -- a large number of deliberately simple models that are all trained on different subsets of the data. This strategy can lead to systems that are more powerful than their individual components. While each little tree in a random forest is weak and prone to overfitting, the forest as a whole can be robust and give high quality predictions.&lt;/p&gt;
&lt;h2&gt;Majority Voting&lt;/h2&gt;
&lt;p&gt;We can also create ensembles of &lt;em&gt;strong learners&lt;/em&gt; -- combining multiple powerful models together. Each individual model is powerful enough to do the entire classification on its own, but we hope to achieve higher accuracy by combining their results.  The most common way to do that is with voting. Query several classifiers, and have the ensemble return the majority pick, or otherwise combine the results.&lt;/p&gt;
&lt;p&gt;There are some characteristics of ensembles that seem pretty common sense [1]. The classifiers in the ensemble need to be &lt;em&gt;diverse&lt;/em&gt;: as different as possible in the mistakes they make. If they all make the same mistakes, then there's no way for the ensemble to correct for that. &lt;/p&gt;
&lt;p&gt;The more classification categories, the more classifiers are needed in the ensemble. However, in real world settings, there's usually a point where adding more classifiers doesn't improve the ensemble. &lt;/p&gt;
&lt;h2&gt;&lt;a name="model"&gt;&lt;/a&gt;The Model&lt;/h2&gt;
&lt;p&gt;I like building really simple models. They can illustrate fundamental characteristics, and show what happens at the extremes. &lt;/p&gt;
&lt;p&gt;So I created an extremely simple model of majority voting (see &lt;a href="https://github.com/csdurfee/ensemble_learning/blob/main/ensemble_voting.ipynb"&gt;notebook&lt;/a&gt;). I'm generating a random list of 0's and 1's, indicating the ground truth of some binary classification problem. Then I make several copies of the ground truth and randomly flip &lt;code&gt;x%&lt;/code&gt; of the bits. Each of those copies represent the responses from an individual classifier within the ensemble. Each fake classifier will have &lt;code&gt;100-x%&lt;/code&gt; accuracy. There's no correlation between the wrong answers that each classifier gives, because the changes were totally random. &lt;/p&gt;
&lt;p&gt;For every pair of fake classifiers with 60% accuracy, they will both be right &lt;code&gt;60% * 60% = 36%&lt;/code&gt; of the time, and both wrong &lt;code&gt;40% * 40% = 16%&lt;/code&gt;. So they will agree &lt;code&gt;36% + 16% = 52%&lt;/code&gt; of the time at minimum.&lt;/p&gt;
&lt;p&gt;That's different from the real world. Machine learning algorithms trained on the same data will make a lot of the same mistakes and get a lot of the same questions right. If there are outliers in the data, any classifier can overfit on them. And they're all going to find the same basic trends in the data. If there aren't a lot of good walrus pictures in the training data, every model is probably going to be bad at recognizing walruses. There's no way to make up for what isn't there.&lt;/p&gt;
&lt;h2&gt;Theory vs Reality&lt;/h2&gt;
&lt;p&gt;In the real world, there seem to be limits on how much an ensemble can improve classification. On paper, there are none, as the simulation shows.&lt;/p&gt;
&lt;p&gt;What is the probability of the ensemble being wrong about a particular classification?&lt;/p&gt;
&lt;p&gt;That's the probability that the majority of the classifiers predict 0, given that the true value is 1 (and vice versa). If each classifier is more likely to be right than wrong, as the number of classifiers goes to infinity, the probability of the majority of predictions being wrong goes to 0.&lt;/p&gt;
&lt;p&gt;If each binary classifier has a probability &amp;gt; .5 of being right, we can make the ensemble arbitrarily precise if we add enough classifiers to the ensemble (assuming their errors are independent). We could grind the math using the normal approximation to get the exact number if need be.&lt;/p&gt;
&lt;p&gt;Let's say each classifier is only right 50.5% of the time. We might have to add 100,000 of them to the ensemble, but we can make the error rate arbitrarily small.&lt;/p&gt;
&lt;h2&gt;Correlated errors ruin ensembles&lt;/h2&gt;
&lt;p&gt;The big difference between my experiment and reality is that the errors the fake classifiers make are totally uncorrelated with each other. I don't think that would ever happen in the real world. &lt;/p&gt;
&lt;p&gt;The more the classifiers' wrong answers are correlated with each other, the less useful the ensemble becomes. If they are 100% correlated with each other, the ensemble will give the exact same results as the individual classifiers, right? An ensemble doesn't &lt;em&gt;have to&lt;/em&gt; improve results.&lt;/p&gt;
&lt;p&gt;To put it in human terms, the "wisdom of the crowd" comes from people in the crowd having wrong beliefs about uncorrelated things (and being right more often than not overall). If most people are wrong in the same way, there's no way to overcome that with volume. &lt;/p&gt;
&lt;p&gt;My experience has been that different models tend to make the same mistakes, even if they're using very different AI/machine learning algorithms, and a lot of that is driven by weaknesses in the training data used.&lt;/p&gt;
&lt;p&gt;For a more realistic scenario, I created fake classifiers with correlated answers, so that they agree with the ground truth 60% of the time, and with each other 82% of the time, instead of the minimum 52% of the time. 
The Cohen kappa score is .64, on a scale from -1 to 1, so they aren't as correlated as they could be.&lt;/p&gt;
&lt;p&gt;The simulation shows that if the responses are fairly strongly correlated with each other, there's a hard limit to how much the ensemble can improve things. &lt;/p&gt;
&lt;p&gt;Even with 99 classifiers in the ensemble, the simulation only achieves an f1 score of .62. That's just a slight bump from the .60 achieved individually. There is no marginal value to adding more than 5 classifiers to the ensemble at this level of correlation.&lt;/p&gt;
&lt;h2&gt;Ensembles: The Rich Get Richer&lt;/h2&gt;
&lt;p&gt;I've seen voting ensembles suggested for especially tricky classification problems, where the accuracy of even the  best models is pretty low. I haven't found that to be true, though, and the simulation backs that up. Ensembles are only going to give a significant boost for binary classification if the individual classifiers are significantly better than 50% accuracy.&lt;/p&gt;
&lt;p&gt;The more accurate the individual classifiers, the bigger the boost from the ensemble. These numbers are for an ensemble of 3 classifiers (in the ideal case of no correlation between their responses):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Classifier Accuracy&lt;/th&gt;
&lt;th&gt;Ensemble Accuracy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;55%&lt;/td&gt;
&lt;td&gt;57%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;60%&lt;/td&gt;
&lt;td&gt;65%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;70%&lt;/td&gt;
&lt;td&gt;78%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;80%&lt;/td&gt;
&lt;td&gt;90%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Hard vs. soft voting&lt;/h2&gt;
&lt;p&gt;There are two different ways of doing majority voting, hard and soft. This choice can have an impact on how well an ensemble works, but I haven't seen a lot of guidance on when to use each. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hard voting&lt;/em&gt; is where we convert the outputs of each binary classifier into a boolean yes/no, and go with the majority opinion. If there are an odd number of components and it's a binary classification, there's always going to be a clear winner. That's what I've been simulating so far.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Soft voting&lt;/em&gt; is where we combine the raw outputs of all the components, and then round the combined result to make the prediction. &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"&gt;sklearn's documentation&lt;/a&gt; advises to use soft voting "for an ensemble of well-calibrated classifiers".&lt;/p&gt;
&lt;p&gt;In the real world, binary classifiers don't return a nice, neat 0 or 1 value. They return some value between 0 or 1 indicating a relative level of confidence in the prediction, and we round that value to 0 or 1. A lot of models will never return a 0 or 1 -- for them, nothing is impossible, just extremely unlikely.&lt;/p&gt;
&lt;p&gt;If a classifier returns &lt;code&gt;.2&lt;/code&gt;, we can think of it as the model giving a &lt;code&gt;20%&lt;/code&gt; chance that the answer is &lt;code&gt;1&lt;/code&gt; and an &lt;code&gt;80%&lt;/code&gt; chance it's &lt;code&gt;0&lt;/code&gt;. That's not really true, but the big idea is that there's potentially additional context that we're throwing away by rounding the individual results.&lt;/p&gt;
&lt;p&gt;For instance, say the raw results are &lt;code&gt;[.3,.4,.9]&lt;/code&gt;. With hard voting, these would get rounded to &lt;code&gt;[0,0,1]&lt;/code&gt;, so it would return &lt;code&gt;0&lt;/code&gt;. With soft voting, it would take the average of &lt;code&gt;[.3,.4,.9]&lt;/code&gt;, which is &lt;code&gt;.53&lt;/code&gt;, which rounds to &lt;code&gt;1&lt;/code&gt;. So the two methods can return different answers.&lt;/p&gt;
&lt;p&gt;To emulate the soft voting case, I flipped a percentage of the bits, as before. Then I replaced every 0 with a number chosen randomly from the uniform distribution from &lt;code&gt;[0,.5]&lt;/code&gt; and every &lt;code&gt;1&lt;/code&gt; with a sample from &lt;code&gt;[.5,1]&lt;/code&gt;. The values will still round to what they did before, but there's additional noise on top. &lt;/p&gt;
&lt;p&gt;In this simulation (3 classifiers), the soft voting ensemble gives less of a boost than the hard voting ensemble -- about half the benefits. As with hard voting, the more accurate the individual classifiers are, the bigger the boost the ensemble gives. &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Classifier Accuracy&lt;/th&gt;
&lt;th&gt;Ensemble Accuracy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;55%&lt;/td&gt;
&lt;td&gt;56%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;60%&lt;/td&gt;
&lt;td&gt;62%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;70%&lt;/td&gt;
&lt;td&gt;74%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;80%&lt;/td&gt;
&lt;td&gt;85%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;Let's say a classifier returns &lt;code&gt;.21573&lt;/code&gt; and I round that down to 0. How much of the &lt;code&gt;.21573&lt;/code&gt; that got lost was noise, and how much was signal? If a classification task is truly binary, it could be all noise. Let's say we're classifying numbers as odd or even. Those are unambiguous categories, so a perfect classifier should always return exactly 0 or 1. It shouldn't say that three is odd, with 90% confidence. In that case, it clearly means the classifier is 10% wrong. There's no good reason for uncertainty.&lt;/p&gt;
&lt;p&gt;On the other hand, say we're classifying whether photos contain a cat or not. What if a cat is wearing a walrus costume in one of the photos? Shouldn't the classifier return a value greater than 0 for the possibility of it not being a cat, even if there really is a cat in the photo? Isn't it somehow less cat-like than another photo where it's not wearing a walrus costume? In this case, the &lt;code&gt;.21573&lt;/code&gt; at least partially represents signal, doesn't it? It's saying "this is pretty cat-like, but not as cat-like as another photo that scored &lt;code&gt;.0001&lt;/code&gt;".&lt;/p&gt;
&lt;p&gt;When I'm adding noise to emulate the soft voting case, is that &lt;em&gt;fair&lt;/em&gt;? A different way of fuzzing the numbers (selecting the noise from a non-uniform distribution, for instance) might reduce the gap in performance between hard and soft voting ensembles, and it would probably be more realistic. But the point of a model like this is to show the extremes -- it's possible that hard voting will give better results than soft voting, so it's worth testing.&lt;/p&gt;
&lt;h2&gt;Big Takeaways&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Ensembles aren't magic; they can only improve things significantly if the underlying classifiers are diverse and fairly accurate.&lt;/li&gt;
&lt;li&gt;Hard and soft voting aren't interchangeable. If there's a lot of random noise in the responses, hard voting is probably a better option, otherwise soft voting is probably better. It's definitely worth testing both options when building an ensemble.&lt;/li&gt;
&lt;li&gt;Anyone thinking of using an ensemble should look at the amount of correlation between the responses from different classifiers. If the classifiers are all making basically the same mistakes, an ensemble won't help regardless of hard vs. soft voting. If models with very different architectures are failing in the same ways, that could be a weakness in the training data that can't be fixed by an ensemble.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;[1] Bonab, Hamed; Can, Fazli (2017). "Less is More: A Comprehensive Framework for the Number of Components of Ensemble Classifiers". arXiv:1709.02925&lt;/p&gt;
&lt;p&gt;Tsymbal, A., Pechenizkiy, M., &amp;amp; Cunningham, P. (2005). Diversity in search strategies for ensemble feature selection. Information Fusion, 6(1), 83–98. doi:10.1016/j.inffus.2004.04.003 &lt;/p&gt;</content><category term="machine learning"></category></entry><entry><title>The hot hand doesn't exist in the NBA, but its opposite does</title><link href="/the-hot-hand-doesnt-exist-in-the-nba-but-its-opposite-does.html" rel="alternate"></link><published>2025-05-16T10:20:00-10:00</published><updated>2025-05-16T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-05-16:/the-hot-hand-doesnt-exist-in-the-nba-but-its-opposite-does.html</id><summary type="html">&lt;p&gt;(The code used, and ipython notebooks with a fuller investigation of the data is available at &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;.)&lt;/p&gt;
&lt;h1&gt;Streaks&lt;/h1&gt;
&lt;p&gt;When I'm watching a basketball game, sometimes it seems like a certain player just can't miss. Every shot looks like it's going to go in. Other times, it …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(The code used, and ipython notebooks with a fuller investigation of the data is available at &lt;a href="https://github.com/csdurfee/hot_hand"&gt;https://github.com/csdurfee/hot_hand&lt;/a&gt;.)&lt;/p&gt;
&lt;h1&gt;Streaks&lt;/h1&gt;
&lt;p&gt;When I'm watching a basketball game, sometimes it seems like a certain player just can't miss. Every shot looks like it's going to go in. Other times, it seems like they've gone cold. They can't get a shot to go in no matter what they do. &lt;/p&gt;
&lt;p&gt;This phenomenon is known as the "hot hand" and whether it exists or not has been debated for decades, even as it's taken for granted in the common language around sports. We're used to commentators saying that a player is  "heating up", or, "that was a heat check".&lt;/p&gt;
&lt;p&gt;As a fan of the game, it certainly seems like the hot hand exists. If you follow basketball, some names probably come to mind. JR Smith, Danny Green, Dion Waiters, Jamal Crawford. When they're on, they just can't miss. It doesn't matter how crazy the shot is, it's going in. And when they're cold, they're &lt;em&gt;cold&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It's a thing we collectively believe in, but it turns out that there isn't clear statistical evidence to support it.&lt;/p&gt;
&lt;p&gt;We have to be careful with our feelings about the hot hand. It certainly feels real, but that doesn't mean that it is. Within the drama of a basketball game, we're inclined to notice and assign stories to runs of makes or misses. Just because we notice them, that doesn't mean they're significant. This is sometimes called "the law of small numbers" -- our brains have a tendency to reach spurious conclusions from a very small amount of data.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Pareidolia"&gt;Pareidolia&lt;/a&gt; is the human tendency to see human faces in inanimate objects -- clouds, the bark of a tree, a tortilla. While the faces might seem real, they are just a product of our brain's natural inclination to identify patterns. It's possible the "hot hand" is a similar phenomenon -- a product of the way human brains are wired to see patterns, rather than an objective truth.&lt;/p&gt;
&lt;h2&gt;Defining Streakiness&lt;/h2&gt;
&lt;p&gt;Streaks of 1's and 0's in randomly generated binary data follow regular mathematical laws, ones our brains can't realy replicate. Writer &lt;a href="https://www.football-data.co.uk/blog/Wald_Wolfowitz.php"&gt;Joseph Buchdal&lt;/a&gt; found that he couldn't create a random-looking sequence by hand that would fool a statistical test called the Wald-Wolfowitz test, even though he knew exactly how the statistical test worked.&lt;/p&gt;
&lt;p&gt;I think at some level, we're physically incapable of generating truly random data, so it makes sense to me that our intuitions about randomness are a little off. Our brains are wired to notice the streaks, but we seem to have no such circuitry for noticing when something is a little bit too un-streaky. Our brains are too quick to see meaningless patterns in small amounts of data, and not clever enough to see subtle, meaningful patterns in large amounts of data. Good thing we have statistics to help us escape those biases!&lt;/p&gt;
&lt;p&gt;For the sake of this discussion, a streak starts whenever a sequence of outcomes changes from wins (W) to losses (L), or vice-versa. (I'm talking about makes and misses, but those start with the same letter, so I'll use "W" and "L".)&lt;/p&gt;
&lt;p&gt;The sequence &lt;code&gt;WLWLWL&lt;/code&gt; has 6 streaks: &lt;code&gt;W, L, W, L, W, L&lt;/code&gt;      &lt;br&gt;
The sequence &lt;code&gt;WWLLLW&lt;/code&gt; has 3 streaks: &lt;code&gt;WW, LLL, W&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Imagine I asked someone to produce a random-looking string of 3 W's and 3 L's. If they were making the results up, I think the average person would be more likely to write the first string. It just looks "more random", right? &lt;/p&gt;
&lt;p&gt;If they flipped a coin, it would be more likely to produce something with longer streaks, like the second example. With a fair coin, both of those &lt;em&gt;exact&lt;/em&gt; sequences are equally likely to occur. But the second sequence has a more probable number of streaks, according to the &lt;a href="https://en.wikipedia.org/wiki/Wald%E2%80%93Wolfowitz_runs_test"&gt;Wald-Wolfowitz Runs Test&lt;/a&gt;. The expected number in 3 wins and 3 losses is (2 * (3 * 3) / (3+3)) + 1 = 4.&lt;/p&gt;
&lt;p&gt;The expected number of streaks is the &lt;a href="https://en.wikipedia.org/wiki/Harmonic_mean"&gt;harmonic mean&lt;/a&gt; of the number of wins and the number of losses, plus one. Neat, right?&lt;/p&gt;
&lt;p&gt;Around 500 players attempted a shot in the NBA this season. Let's say we create a custom coin for each player. It comes up heads with the same percentage as the player's shooting percentage on the season. If we took those coins and simulated every shot in the NBA this season, some of the coins would inevitably appear to be "streakier" than others.&lt;/p&gt;
&lt;p&gt;Players never intend to miss shots, yet most players shoot around 50%, so there has to be some element of chance as far as which shots go in or not. Otherwise, why wouldn't players just choose to make all of them?&lt;/p&gt;
&lt;p&gt;So makes versus misses are at least somewhat random, which means if we look at the shooting records of 500 players in an NBA season, some will seem more or less consistent due to the laws of probability. That means a player with longer or shorter streaks than expected could just be due to chance, not due to the player actively doing something that makes them more streaky.&lt;/p&gt;
&lt;h2&gt;The Lukewarm Hand&lt;/h2&gt;
&lt;p&gt;We might call players who have fewer streaks than expected by chance &lt;em&gt;consistent&lt;/em&gt;. Maybe they go exactly 5 for 10 every single game, never being especially good or especially bad. Or maybe they go 1 for 3 every game, always being pretty bad.&lt;/p&gt;
&lt;p&gt;But that feels like the wrong word, and I don't think our brains aren't really wired to notice a player that has fewer streaks than average. As we already saw, the "right" number of streaks is counterintuitive. &lt;/p&gt;
&lt;p&gt;I might notice a player is unusually consistent after the fact when looking at their basketball-reference page, but the feeling of a player having the &lt;em&gt;hot hand&lt;/em&gt; is visceral, experienced in the moment. Even without consulting the box score, sometimes players look like they just can't miss, or can't make, a shot. They seem more confident, or their shot seems more natural, than usual. Both the shooter and the spectator seem to have a higher expectation that the shot will go in than usual. The hot hand is a social phenomenon.&lt;/p&gt;
&lt;p&gt;&lt;img alt="there's always an xkcd" src="/img/xkcd-sports.png"&gt;  &lt;br&gt;
(from &lt;a href="https://xkcd.com/904/"&gt;https://xkcd.com/904/&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;If we look at the makes and misses of every player in the league, do they look like the results of flipping a coin (weighted to match their shooting percentage), or is there a tendency for players to be more or less streaky than expected by chance? &lt;/p&gt;
&lt;p&gt;We don't really have a formal word for players who are less streaky than they should be, so I'm going to call the opposite of the &lt;em&gt;hot hand&lt;/em&gt; the &lt;em&gt;lukewarm hand&lt;/em&gt;. While the &lt;em&gt;lukewarm hand&lt;/em&gt; isn't a thing we would viscerally notice the way we do the &lt;em&gt;hot hand&lt;/em&gt;, it's certainly possible to exist. And it's just as surprising, from the perspective of treating basketball players like weighted coins. &lt;/p&gt;
&lt;p&gt;Some people I've seen analyze the hot hand treat the question as &lt;em&gt;streaky&lt;/em&gt; versus &lt;em&gt;non-streaky&lt;/em&gt;. But it's not a binary thing. There are two possible extremes, and a region in between. It's &lt;em&gt;unusually streaky&lt;/em&gt; versus &lt;em&gt;normal amount of streaky&lt;/em&gt; versus &lt;em&gt;unusually non-streaky&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The Wald-Wolfowitz test says that the number of streaks in randomly-generated data will be normally distributed, and gives a formula for the variance of the number of streaks. The normal distribution is symmetrical, so there should be as many &lt;em&gt;hot hand&lt;/em&gt; players as &lt;em&gt;lukewarm hand&lt;/em&gt; ones. Players have varying numbers of shots taken over the course of the season so we can't compare them directly, but we can calculate the z score for each player's expected vs. actual number of streaks. The z score represents how "weird" the player is. If we look at all the z-scores together, we can see whether NBA players as a whole are streakier or less streaky than chance alone would predict. We can also see if the outliers correspond to the popular notions of who the streaky shooters in the NBA are.&lt;/p&gt;
&lt;h2&gt;Simplifying Assumptions&lt;/h2&gt;
&lt;p&gt;We should start with the assumption that athletes really are weighted random number generators. A coin might have "good days" and "bad days" based on the results, but it's not because the coin is "in the zone" one day, or a little injured the next day. At least some of the variance in a player's streakiness is due to randomness, so we have to be looking for effects that can't be explained by randomness alone.&lt;/p&gt;
&lt;p&gt;So I am analyzing all shots a player took, across all games. This could cause problems, which I will discuss later on, but splitting the results up game-by-game or week-by-week leads to other problems. Looking at shooting percentages by game or by week means smaller sample sizes, and thus more sampling error. It also means that comparisions between high volume shooters and low volume shooters can be misinterpreted. The high volume shooters may appear more "consistent" simply because it's a larger sample size.&lt;/p&gt;
&lt;p&gt;I think I need to prove that &lt;em&gt;streakiness&lt;/em&gt; exists before making assumptions about how it works. Let's say the "hot hand" does exist. If a player makes a bunch of shots in a row, how long might they stay hot? Does it last through halftime? Does it carry over to the next game? How many makes in a row before they "heat up"? How much does a player's field goal percentage go up? Does a player have cold streaks and hot streaks, or are they only streaky in one direction?&lt;/p&gt;
&lt;p&gt;There are an infinite number of ways to model how it could work, which means it's ripe for overfitting. So I wanted to start with the simplest, most easily justifiable model. The &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/0010028585900106?via%3Dihub"&gt;original paper about the hot hand&lt;/a&gt; was co-written by Amos Tversky, who went on to win a Nobel Prize for helping to invent behavioral economics. I figure any time you can crib off of a Nobel Prize winner's homework, you probably should!&lt;/p&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;I started off by getting data on every shot taken in the 2024-25 NBA regular season. I calculated the expected number of streaks and actual number, then a z-score for every player.&lt;/p&gt;
&lt;p&gt;Players with a z-score of 0 are just like what we'd expect from flipping a coin. A positive z-score indicates there were more streaks than expected. More streaks than expected means the streaks were shorter than expected, which means less streaky than expected. &lt;/p&gt;
&lt;p&gt;A negative z-score indicates the opposite. Those players had fewer streaks than expected, which means the streaks were longer.  When people talk about the "hot hand" or "streaky shooters", they are talking about players who should have a negative z-score by this test.&lt;/p&gt;
&lt;p&gt;&lt;img alt="all players, 2024-5" src="/img/all-players-2024.png"&gt;&lt;/p&gt;
&lt;p&gt;The curve over the top is the distribution of z-scores we'd expect if the players worked like weighted coin flips. &lt;/p&gt;
&lt;p&gt;Just eyeballing it, it's pretty close. It's definitely a bell curve, centered pretty close to zero. If there is a skew, it's actually to the positive, un-streaky side, though.  The mean z-score is .21, when we'd expect it to be zero.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    554.000000
mean       0.212491
std        1.075563
min       -3.081194
25%       -0.546340
50%        0.236554
75%        0.951653
max        3.054836
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The Wilk-Shapiro test is way to decide whether a set of data plausibly came from a normal distribution. It passed. There is no conclusive evidence that players in general are streakier or less streaky than predicted by chance. This data very well could've come from flipping a bunch of coins.&lt;/p&gt;
&lt;p&gt;But it's still sorta skewed. There were 320 players with a positive z-score (un-streaky) versus 232 with a negative z-score (streaky). That's suspicious.&lt;/p&gt;
&lt;h2&gt;Outliers&lt;/h2&gt;
&lt;p&gt;A whole lot of those 554 players didn't make very many shots.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="numer of makes, 2024-5" src="/img/makes-2024.png"&gt;&lt;/p&gt;
&lt;p&gt;I decided to split up players with over 100 makes versus under 100 makes. Unlike high volume shooters, the low volume shooters had no bias towards unstreakiness. They look like totally random data.&lt;/p&gt;
&lt;p&gt;Here are just the high volume shooters (323 players in total). Notice how none of them have a z-score less than about -2. It should be symmetrical.&lt;/p&gt;
&lt;p&gt;&lt;img alt="over 100 makes, 2024-5" src="/img/over-100-makes.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    323.000000
mean       0.347452
std        1.068341
min       -2.082528
25%       -0.454794
50%        0.363949
75%        1.091244
max        3.054836
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There were 20 players with a z-score less than -2 versus only 2 players with a score greater than 2.&lt;/p&gt;
&lt;h2&gt;The Eye Test&lt;/h2&gt;
&lt;p&gt;I looked at which players had exceptionally high or low z scores. The names don't really make sense to me as an NBA fan. There were players like Jordan Poole and Jalen Green, who I think fans would consider streaky, but they had exceptionally un-streaky z-scores. I don't think the average NBA fan would say Jalen Green is less streaky than 97.5% of the players in the league, but he is (by this test).&lt;/p&gt;
&lt;p&gt;On the other hand, two streakiest players in the NBA this year were Goga Bitadze and Thomas Bryant, two players who don't fit the profile of the stereotypical streaky shooter by any means.&lt;/p&gt;
&lt;h2&gt;Makes vs. Streakiness&lt;/h2&gt;
&lt;p&gt;The more shots a player made this season, the less streaky they tended to be. Here's a plot of makes on the 2024-25 season versus the z-score.&lt;/p&gt;
&lt;p&gt;&lt;img alt="makes vs z-score" src="/img/makes-vs-zscore.png"&gt;&lt;/p&gt;
&lt;p&gt;That's pretty odd, isn't it?&lt;/p&gt;
&lt;h2&gt;Getting more data: 2021-present&lt;/h2&gt;
&lt;p&gt;I figured a bigger sample size would be better. Maybe this season was just weird. So got the last 4 seasons of data (2021-22,2022-2023, 2023-2024, 2024-2025) for players who made a shot in the NBA this season and combined them.&lt;/p&gt;
&lt;p&gt;The four year data is even more skewed towards the &lt;em&gt;lukewarm hand&lt;/em&gt;, or un-streaky side, than the single year data.&lt;/p&gt;
&lt;p&gt;&lt;img alt="all players, 2021-2025" src="/img/all-players-four-year.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    562.000000
mean       0.443496
std        1.157664
min       -4.031970
25%       -0.312044
50%        0.449647
75%        1.184918
max        4.184025
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The correlation between number of makes and z-score is quite strong in the 4 year data:&lt;/p&gt;
&lt;p&gt;&lt;img alt="2021-2025 z score vs makes" src="/img/four-year-makes-vs-zscore.png"&gt;&lt;/p&gt;
&lt;p&gt;There were 48 players with a z-score &amp;gt; 2, versus only 9 with a score &amp;lt;-2. That's like flipping a coin and getting 48 heads and 9 tails. There's around a 2 in 10 million chance of that happening with a fair coin.&lt;/p&gt;
&lt;h2&gt;High Volume Shooters, Redux&lt;/h2&gt;
&lt;p&gt;The bias towards the lukewarm hand is even stronger among high volume shooters. Here are players with more than 500 makes over the past 4 years.&lt;/p&gt;
&lt;p&gt;&lt;img alt="over 500 makes" src="/img/over-500-makes.png"&gt;&lt;/p&gt;
&lt;p&gt;The z-scores are normally distributed according to the Wilk-Shapiro test, but they're no longer even close to being centered at zero. They're also overdispersed (the std is bigger than the expected 1.) It's not plausible that the true mean is 0, given the sample mean is .680.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    265.000000
mean       0.680097
std        1.217946
min       -2.392061
25%       -0.149211
50%        0.776917
75%        1.485595
max        4.184025
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="high volume hist" src="/img/high-volume-hist.png"&gt;&lt;/p&gt;
&lt;h2&gt;Streak Lengths&lt;/h2&gt;
&lt;p&gt;I looked at the length of make/miss streaks for the actual NBA players versus simulating the results. The results were simulated by taking the exact number of makes and misses for each NBA player, and then shuffling those results randomly. What I found confirmed the "lukewarm hand" -- overall, NBA players have slightly more 1 and 2 shot streaks than expected, and fewer long streaks than expected.&lt;/p&gt;
&lt;p&gt;&lt;img alt="streaks" src="/img/streaks.png"&gt;&lt;/p&gt;
&lt;h2&gt;Obvious objections, and what about free throws?&lt;/h2&gt;
&lt;p&gt;I'm treating every field goal attempt like it has the same chance of going in. Clearly that's not the case. Players, especially high volume scorers, can choose which shots they take. It's easy to imagine a player that has missed several shots in a row and is feeling "cold" would concentrate on only taking higher percentage shots. There's also the fact that I'm combining games together. That could potentially lead to players looking less streaky than they are within the course of a single game. But it should also make truly unstreaky players look less &lt;em&gt;unstreaky&lt;/em&gt;. Streaks getting "reset" by the end of the game should make players act more like a purely random process -- not too streaky or unstreaky. It shouldn't increase the standard deviation of the z-scores like we're seeing, or cause a shift towards unstreakiness. &lt;/p&gt;
&lt;p&gt;I may do a simulation to illustrate that, but in the meantime, the most controlled shot data we have is free throw data. Every free throw should have exactly the same level of difficulty for the player. &lt;/p&gt;
&lt;p&gt;I got the data for the 200,000+ free throws in the NBA regular season over the past four years (October 2021 through April 2025).&lt;/p&gt;
&lt;p&gt;Here are the z-scores for all players. There's a big chunk taken out of the middle of the bell curve, but it's normal-ish other than that.&lt;/p&gt;
&lt;p&gt;&lt;img alt="free throws" src="/img/free-throws.png"&gt;&lt;/p&gt;
&lt;p&gt;240 players have made over 200 free throws in the past 4 years. When I restrict to just those players, there's a slight skew towards the "hot hand", or being more streaky than expected. There are no exceptionally &lt;em&gt;lukewarm hands&lt;/em&gt; when it comes to free throws. It's sort of the mirror image of what we saw with high volume field goal shooters.&lt;/p&gt;
&lt;p&gt;&lt;img alt="free throws, over 200 makes" src="/img/over-200-ft.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;count    240.000000
mean      -0.144277
std        1.021330
min       -2.686543
25%       -0.854723
50%       -0.174146
75%        0.660302
max        1.845302
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Conclusions, for now&lt;/h2&gt;
&lt;p&gt;I feel comfortable concluding that the hot hand doesn't exist when it comes to field goals. I can't say why there's a tendency towards &lt;em&gt;unstreakiness&lt;/em&gt; yet, but I suspect it is due to shot selection. Players who have made a bunch of shots may take more difficult shots than average, and players who have missed a bunch of shots will go for an easier shot than average. While players can't choose when to "heat up" or "go cold", they can certainly change shot selection based on their emotions or the momentum of the game.&lt;/p&gt;
&lt;p&gt;There may be a slight tendency towards the hot hand when it comes to free throws. It's worth investigating further, I think. But the effect there doesn't appear to be nearly as strong as the &lt;em&gt;lukewarm hand&lt;/em&gt; tendency for field goals.&lt;/p&gt;</content><category term="sports analytics"></category><category term="basketball"></category><category term="the hot hand"></category></entry><entry><title>The Hardest Road</title><link href="/the-hardest-road.html" rel="alternate"></link><published>2025-05-01T10:20:00-10:00</published><updated>2025-05-01T10:20:00-10:00</updated><author><name>casey durfee</name></author><id>tag:None,2025-05-01:/the-hardest-road.html</id><summary type="html">&lt;h2&gt;What geology can tell us about Kevin Durant's next team&lt;/h2&gt;
&lt;p&gt;When NBA superstar Kevin Durant left the Oklahoma City Thunder to join the Golden State Warriors, he said that doing so was taking "the hardest road". This was met with a lot of mockery, because the Golden State Warriors had …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;What geology can tell us about Kevin Durant's next team&lt;/h2&gt;
&lt;p&gt;When NBA superstar Kevin Durant left the Oklahoma City Thunder to join the Golden State Warriors, he said that doing so was taking "the hardest road". This was met with a lot of mockery, because the Golden State Warriors had just won 73 games, the most in NBA history, the previous year.&lt;/p&gt;
&lt;p&gt;It was widely regarded as an uncool move, ring chasing, the ultimate bandwagon riding. It was clearly an absurd thing to say about the level of challenge he chose. It also made the NBA less interesting for several years, so he deserved some hate for it.&lt;/p&gt;
&lt;p&gt;What people missed was that according to geology, he wasn't totally off-base. Streets are paved with asphalt, which is a combination of local rocks (aggregate) and tar. That means that some regions of America have harder roads than others, based on the local geology:&lt;/p&gt;
&lt;p&gt;&lt;img alt="taken from https://www.forconstructionpros.com/equipment/worksite/article/10745911/aggregate-hardness-map-of-the-united-states" src="/img/aggregate-map.jpg"&gt;
(&lt;a href="https://www.forconstructionpros.com/equipment/worksite/article/10745911/aggregate-hardness-map-of-the-united-states"&gt;source: https://www.forconstructionpros.com/equipment/worksite/article/10745911/aggregate-hardness-map-of-the-united-states&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Oklahoma City is located right in the center of Oklahoma, with some of the softest aggregate in the United States. It's reasonable for someone who cares about road hardness to want to leave. Just about anywhere (except for Florida) would have been an improvement.&lt;/p&gt;
&lt;p&gt;The "hardest road" out of OKC at that time would've been the one to New Orleans. It's about a 700 mile drive, and it looks like it's a nice gradient from some of the softest roads in the United States to the very hardest ones. &lt;/p&gt;
&lt;p&gt;The New Orleans Pelicans at the time were &lt;a href="https://www.basketball-reference.com/teams/NOP/2016.html"&gt;pretty bad&lt;/a&gt;, basically just Anthony Davis, a couple good role players (Ryan Anderson, Jrue Holiday), and a rich collection of "Let's Remember Some Guys" Guys (Jimmer Fredette, Nate Robinson, Luke Babbitt, Ish Smith, Alonzo Gee, Norris Cole). KD and AD on the same team would have been cool, but even with Kevin Durant, the Pelicans would likely have been pretty bad. Certainly worse than the OKC team that Durant wanted to leave.&lt;/p&gt;
&lt;p&gt;Although technically the "hardest road" out of Oklahoma City, going to New Orleans would have been a poor career choice for KD. The Pelicans have always been a cheap, poorly run team. I can't imagine it being a destination for any free agent of Kevin Durant's caliber. &lt;/p&gt;
&lt;p&gt;He really should have said "I'm taking the hardest road that doesn't lead to a mismanaged tire fire of a team. Also by "hardest" I mean on the &lt;a href="https://en.wikipedia.org/wiki/Mohs_scale"&gt;Mohs scale&lt;/a&gt;, not the challenge" and everybody would have understood.&lt;/p&gt;
&lt;p&gt;Northern California has a medium-hard substrate, so his choice to go to the Warriors was definitely a harder road than a lot of other places he could have gone. Since leaving the Warriors, he's played for two other teams with medium-hard roads: the Brooklyn Nets and the Phoenix Suns. He's never chosen to take a softer road. Give him credit for that. &lt;/p&gt;
&lt;p&gt;Now that there are rumors about Kevin Durant being traded from the Suns, what can geology tell us about Durant's next destination?&lt;/p&gt;
&lt;p&gt;The other NBA cities with medium-hard to hard roads are New Orleans, Boston, Charlotte, Houston, New York, Sacramento, Utah, and Washington DC. He's from DC so that might be nice. But Durant always says he wants to compete for a championship. So we can rule them out, as well as New Orleans, Charlotte and Utah. &lt;/p&gt;
&lt;p&gt;I can't really see Boston or New York wanting to tweak their rosters too much, because they're both already good enough to win a championship and don't have a lot of tradeable assets. Sacramento's not a great fit. The Kings would be dreadful on defense, and have too many players who need the ball at once.&lt;/p&gt;
&lt;p&gt;That leaves Houston. Durant would fix the Rockets' biggest weakness -- not having a go-to scorer -- and Houston could surround him with a bunch of guys who can play defense. Most importantly, he'd get to continue to drive on medium-hard roads. &lt;/p&gt;
&lt;p&gt;Kevin Durant to the Houston Rockets. The geology doesn't lie.&lt;/p&gt;</content><category term="sports analytics"></category><category term="basketball"></category></entry></feed>