<!DOCTYPE html>
<html lang="english">
        <head>
                        <meta charset="utf-8" />
                        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
                        <meta name="generator" content="Pelican" />
                        <title>mathletix - statistics</title>
                        <link rel="stylesheet" href="/theme/css/main.css" />
                                <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="mathletix Atom Feed" />
        </head>

        <body id="index" class="home">
                <header id="banner" class="body">
                        <h1><a href="/">mathletix</a></h1>
                        <nav><ul>
                                                <li><a href="/category/machine-learning.html">machine learning</a></li>
                                                <li><a href="/category/sports-analytics.html">sports analytics</a></li>
                                                <li class="active"><a href="/category/statistics.html">statistics</a></li>
                        </ul></nav>
                </header><!-- /#banner -->

                <aside id="featured" class="body">
                    <article>
                        <h1 class="entry-title"><a href="/approximate-normality-and-continuity-corrections.html">Approximate Normality and Continuity Corrections</a></h1>
<footer class="post-info">
        <abbr class="published" title="2025-06-08T10:20:00-10:00">
                Published: Sun 08 June 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="/author/casey-durfee.html">casey durfee</a>
                </address>
        <p>In <a href="/category/statistics.html">statistics</a>.</p>
        
</footer><!-- /.post-info --><p>(Notebooks and other code available at: <a href="https://github.com/csdurfee/hot_hand">https://github.com/csdurfee/hot_hand</a>. As usual, there is stuff in there I'm not covering here.)</p>
<h1>What is "approximately normal"?</h1>
<p>In the last installment, I looked at game-level player data, which involve very small samples.</p>
<p>Like a lot of things in statistics, the Wald Wolfowitz test says that the number of streaks is approximately normal. What does that mean in practical terms? How approximately are we talking?</p>
<p>The number of streaks is a discrete value (0,1,2,3,...). In a small sample like 2 makes and 3 misses, which will be extremely common in player game level shooting data, how could that be <em>approximately normal</em>?</p>
<p>Below is a bar chart of the exact probabilities of each number of streaks, overlaid with the normal approximation in white. Not very normal, is it?</p>
<p><img alt="not very normal" src="/img/not-very-normal.png"></p>
<p>To make things more interesting, let's say the player made 7 shots and missed 4. That's enough for the graph to look more like a proper bell curve.</p>
<p><img alt="exact 7-4 (or 4-7)" src="/img/exact-7-4.png"></p>
<p>The bell curve looks skewed relative to the histogram, right? That's what happens when you model a discrete distribution (the number of streaks) with a continuous one -- the normal distribution.</p>
<p>A continuous distribution has zero probability at any single point, so we always calculate the area under the curve between a range of values. So the bar for exactly 7 streaks should line up with the probability of between 6.5 and 7.5 streaks in the normal approximation. The curve should be going through the middle of each bar.</p>
<p>We need to shift the curve to the right a half a streak for things to line up right. Fixing this is called <a href="https://en.wikipedia.org/wiki/Continuity_correction">continuity correction</a>.</p>
<p>Here's the same graph with the continuity correction applied:</p>
<p><img alt="with cc" src="/img/with-cc.png"></p>
<p>So... better, but there's still a problem. The normal approximation will assign a nonzero probability to impossible things. In this case of 7 wins and 7 losses, the minimum possible number of streaks is 2 and the max is 9 (alternate wins and losses till you run out of losses, then have a string of wins at the end.)</p>
<p>Yet the normal approximation says there's a nonzero chance of 10, or 11, or even a million streaks. The odds are tiny, but the normal distribution never ends. These differences go away with big sample sizes, but they may be worth worrying about for small sample sizes.</p>
<p>Is that interfering with my results? It's quite possible. I'm trying to use the mean and the standard deviation to decide how "weird" each player is in the form of a z score. The z score gives the likelihood of the data happening by chance, given certain assumptions. If the assumptions don't hold, the z score, and using it to interpret how <em>weird</em> things are, is suspect.</p>
<h2>Exact-ish odds</h2>
<p>We can just calculate the exact odds. In the notebook, I showed how to calculate the odds with brute force -- generate all permutations of seven 1's and four 0's, and measure the number of streaks for each one. That's impractical and silly, since the exact formula can be worked out using the rules of combinatorics, as this page nicely shows:  <a href="https://online.stat.psu.edu/stat415/lesson/21/21.1">https://online.stat.psu.edu/stat415/lesson/21/21.1</a></p>
<p>In order to compare all these players, with different numbers of makes and misses, we'd want to calculate a percentile value for each one from the exact odds. The percentiles will be based on number of streaks, so 1st percentile would be super streaky, 99th percentile super un-streaky.</p>
<p>Let's say we're looking at the case of 7 makes and 4 misses, and are trying to calculate the percentile value that should go with each number of streaks.  Here are the exact odds of each streak length:</p>
<div class="highlight"><pre><span></span><code><span class="mf">2</span><span class="w">    </span><span class="mf">0.006061</span>
<span class="mf">3</span><span class="w">    </span><span class="mf">0.027273</span>
<span class="mf">4</span><span class="w">    </span><span class="mf">0.109091</span>
<span class="mf">5</span><span class="w">    </span><span class="mf">0.190909</span>
<span class="mf">6</span><span class="w">    </span><span class="mf">0.272727</span>
<span class="mf">7</span><span class="w">    </span><span class="mf">0.227273</span>
<span class="mf">8</span><span class="w">    </span><span class="mf">0.121212</span>
<span class="mf">9</span><span class="w">    </span><span class="mf">0.045455</span>
</code></pre></div>

<p>Here are the cumulative odds (the odds of getting that number of streaks or fewer):</p>
<div class="highlight"><pre><span></span><code><span class="mf">2</span><span class="w">    </span><span class="mf">0.006061</span>
<span class="mf">3</span><span class="w">    </span><span class="mf">0.033333</span>
<span class="mf">4</span><span class="w">    </span><span class="mf">0.142424</span>
<span class="mf">5</span><span class="w">    </span><span class="mf">0.333333</span>
<span class="mf">6</span><span class="w">    </span><span class="mf">0.606061</span>
<span class="mf">7</span><span class="w">    </span><span class="mf">0.833333</span>
<span class="mf">8</span><span class="w">    </span><span class="mf">0.954545</span>
<span class="mf">9</span><span class="w">    </span><span class="mf">1.000000</span>
</code></pre></div>

<p>Let's say we get 6 streaks. Exactly 6 streaks happens 27% of the time. 5 or fewer streaks happens 33% of the time. So we could say 6 streaks is equal to the 33rd percentile, the <code>33.3%+27.3% = 61</code>st percentile, or some value in between those two numbers.</p>
<p>The obvious way of deciding what's called the <a href="https://en.wikipedia.org/wiki/Percentile_rank">percentile rank</a> for a discrete distribution is to take the average of the upper and lower bound, in this case <code>mean(.333, .606) = .47</code>. You could also think of it as taking the probability of <code>streaks &lt;=5</code> and adding half the probability of <code>streaks=6</code>.</p>
<p>If we want to compare the percentile ranks from the exact odds to Wald-Wolfowitz, we could convert them to an equivalent z score. Or, we can take the z-scores from the Wald Wolfowitz test and convert them to percentiles.</p>
<p>The z-scores are bound to be a little different because the normal approximation is a bell curve, whereas we're getting the percentile rank from a linear interpolation of two values.</p>
<p>Here's an illustration of what I mean. Here's a graph of the exact cumulative probabilities vs the CDF of the normal approximation.</p>
<p><img alt="cdf-normal-exact" src="/img/cdf-normal-exact.png"></p>
<p>Let's zoom in on the section between 4.5 and 5.5 streaks. Where the white line hits the red line is the percentile estimate we'd get from the z-score (.475).</p>
<p><img alt="cdf-zoom" src="/img/cdf-zoom.png"></p>
<p>The green line is a straight line that represents calculating the percentile rank. It goes from the middle of the top of the <code>runs &lt;= 5</code> bar to the middle of the top of the <code>runs &lt;=6</code> bar. Where it hits the red line is the average of the two, which is percentile rank (.470).</p>
<p>In other situations, the Wald-Wolfowitz estimate will be less than the exact percentile rank.</p>
<h2>Is Wald-Wolfowitz unbiased?</h2>
<p>Yeah. The test provides the exact expected value of the number of streaks. It's not just, like, a pretty good estimate. It is the (weighted) mean of the exact probabilities.</p>
<p>From the exact odds, the mean of all the streak lengths is 6.0909:</p>
<div class="highlight"><pre><span></span><code>count    330.000000
mean       6.090909
std        1.445329
min        2.000000
25%        5.000000
50%        6.000000
75%        7.000000
max        9.000000
</code></pre></div>

<p>The Wald-Wolfowitz test says the expected value is 1 plus the harmonic mean of 7 and 4, which is 6.0909...</p>
<h2>Is the normal approximation throwing off my results?</h2>
<p>Quite possibly. So I went back and calculated the percentile ranks for every player-game combo over the course of the season.</p>
<p>Here's a scatter plot of the two ways to calculate the percentile on actual NBA player games. The dots above the x=y line are where the Wald-Wolfowitz percentile is bigger than the percentile rank one.</p>
<p><img alt="percentile-vs-ww" src="/img/percentile-vs-ww.png"></p>
<p>59% of the time, the Wald-Wolfowitz estimate produces a higher percentile value than the percentile rank. The same trend occurs if I restrict the data set to only high volume shooters (more than 10 makes or misses on the game).</p>
<p>Here's a bar chart of the differences between the W-W percentile and the percentile rank:</p>
<p><img alt="ww-minus-pr" src="/img/ww-minus-pr.png"></p>
<p>A percentile over 50, or a positive z score, means more streaks than average, thus less streaky than average. In other words, on this data set, the Wald-Wolfowitz z-scores will be more flattering to the un-streaky side compared to percentile rank with the exact probabilities.</p>
<h2>Interlude: our un-streaky king</h2>
<p>For the record, the un-streakiest NBA game of the 2023-24 season was by Dejounte Murray on 4/9/2024. My dude went 12 for 31 and managed 25 streaks, the most possible for that number of makes and misses, by virtue of never making 2 shots in a row.</p>
<p>It was a crazy game all around for Murray. A 29-13-13 triple double with 4 steals, and a Kobe-esque 29 points on 31 shots. He could've gotten more, too. The game went to double overtime, and he missed his last 4 in a row. If he had made the 2nd and the 4th of those, he could've gotten 4 more streaks on the game.</p>
<p>The summary of the game doesn't mention this exceptional achievement. Of course they wouldn't. There's no clue of it in the box score. You couldn't bet on it. Why would anyone notice?</p>
<p><a href="https://www.basketball-reference.com/boxscores/202404090ATL.html">box score on bbref</a>    </p>
<p>Look at that unstreakiness. Isn't it beautiful?</p>
<div class="highlight"><pre><span></span><code><span class="n">makes</span><span class="w">                                                  </span><span class="mi">12</span>
<span class="n">misses</span><span class="w">                                                 </span><span class="mi">19</span>
<span class="n">total_streaks</span><span class="w">                                          </span><span class="mi">25</span>
<span class="n">raw_data</span><span class="w">                  </span><span class="n">LWLWLWLWLWLWLLWLLLWLWLWLWLWLLLL</span>
<span class="n">expected_streaks</span><span class="w">                                </span><span class="mf">15.709677</span>
<span class="n">variance</span><span class="w">                                         </span><span class="mf">6.722164</span>
<span class="n">z_score</span><span class="w">                                          </span><span class="mf">3.583243</span>
<span class="n">exact_percentile_rank</span><span class="w">                           </span><span class="mf">99.993423</span>
<span class="n">z_from_percentile_rank</span><span class="w">                           </span><span class="mf">3.823544</span>
<span class="n">ww_percentile</span><span class="w">                                   </span><span class="mf">99.983032</span>
</code></pre></div>

<p>On the other end, the streakiest performance of the year belonged to Jabari Walker of the Portland Trail Blazers. Made his first 6 shots in a row, then missed his last 8 in a row.</p>
<div class="highlight"><pre><span></span><code><span class="n">makes</span><span class="w">                                  </span><span class="mi">6</span>
<span class="n">misses</span><span class="w">                                 </span><span class="mi">8</span>
<span class="n">total_streaks</span><span class="w">                          </span><span class="mi">2</span>
<span class="n">raw_data</span><span class="w">                  </span><span class="n">WWWWWWLLLLLLLL</span>
<span class="n">expected_streaks</span><span class="w">                </span><span class="mf">7.857143</span>
<span class="n">variance</span><span class="w">                        </span><span class="mf">3.089482</span>
<span class="n">z_score</span><span class="w">                        </span><span class="o">-</span><span class="mf">3.332292</span>
<span class="n">exact_percentile_rank</span><span class="w">             </span><span class="mf">0.0333</span>
<span class="n">z_from_percentile_rank</span><span class="w">         </span><span class="o">-</span><span class="mf">3.403206</span>
<span class="n">ww_percentile</span><span class="w">                   </span><span class="mf">0.043067</span>
</code></pre></div>

<h2>Actual player performances</h2>
<p>Let's look at actual NBA games where a player had exactly 7 makes and 4 misses. (We can also include the flip side, 4 makes and 7 misses, because it will be the same distribution of streak lengths)</p>
<p>The green areas are where the players had more streaks than the exact probabilities; the red areas are where players had fewer streaks. The two are very close, except for a lot more games with 9 streaks in the player data, and fewer 6 streak games.</p>
<p>The exact mean is 6.09 streaks. The mean for player performances is 6.20 streaks. Even in this little slice of data, there's a slight tendency towards unstreakiness.</p>
<p><img alt="streaks-vs-probs" src="/img/streaks-vs-probs.png"></p>
<h2>Percentile ranks are still unstreaky, though</h2>
<p>Well, for all that windup, the percentile ranks didn't turn out all that different when I calcualted them for all 18,000+ player-game combos. The mean and median are still shifted to the un-streaky side, to a significant degree.</p>
<p><img alt="z-from-percentile" src="/img/z-from-percentile.png"></p>
<p>Plotting the deciles shows an interesting tendency: a lot more values in the 60-70th percentile range than expected. the shift to the un-streaky side comes pretty much from these values.</p>
<p><img alt="perc-rank-deciles" src="/img/perc-rank-deciles.png"></p>
<p>The bias towards the unstreaky side is still there, and still significant:</p>
<div class="highlight"><pre><span></span><code>count    18982.000000
mean         0.039683
std          0.893720
min         -3.403206
25%         -0.643522
50%          0.059717
75%          0.674490
max          3.823544
</code></pre></div>

<h2>A weird continuity correction that seems obviously bad</h2>
<p>SAS, the granddaddy of statistics software, applies a continuity correction to the runs test whenever the count is less than 50.</p>
<p>While it's true that we should be careful with normal approximations and small sample size, this ain't the way.</p>
<p>The exact code used is here: https://support.sas.com/kb/33/092.html</p>
<div class="highlight"><pre><span></span><code><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nv">N</span><span class="w"> </span><span class="nv">GE</span><span class="w"> </span><span class="mi">50</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="nv">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">(</span><span class="nv">Runs</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nv">mu</span><span class="ss">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nv">sigma</span><span class="c1">;</span>
<span class="w">        </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nv">Runs</span><span class="o">-</span><span class="nv">mu</span><span class="w"> </span><span class="nv">LT</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="nv">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">(</span><span class="nv">Runs</span><span class="o">-</span><span class="nv">mu</span><span class="o">+</span><span class="mi">0</span>.<span class="mi">5</span><span class="ss">)</span><span class="o">/</span><span class="nv">sigma</span><span class="c1">;</span>
<span class="w">          </span><span class="k">else</span><span class="w"> </span><span class="nv">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">(</span><span class="nv">Runs</span><span class="o">-</span><span class="nv">mu</span><span class="o">-</span><span class="mi">0</span>.<span class="mi">5</span><span class="ss">)</span><span class="o">/</span><span class="nv">sigma</span><span class="c1">;</span>
</code></pre></div>

<p>Other implementations I looked at, like the one in R's <a href="https://www.rdocumentation.org/packages/randtests/versions/1.0.1/topics/runs.test"><code>randtests</code> package</a>, don't do the correction.</p>
<p>What does this sort of correction look like?</p>
<p>For starters, it gives us something that doesn't look like a z score. The std is way too small.</p>
<div class="highlight"><pre><span></span><code>count    18982.000000
mean        -0.031954
std          0.687916
min         -3.047828
25%         -0.401101
50%          0.000000
75%          0.302765
max          3.390395
</code></pre></div>

<p><img alt="sas-cc" src="/img/sas-cc.png"></p>
<h3>What does this look like on random data?</h3>
<p>I will generate a fake season of data like in the last installment, but the players will have no unstreaky/streaky tendencies. They will behave like a coin flip, weighted to their season FG%.</p>
<p>Here are the z-scores. They're not obviously bad, but the center is a bit higher than it should be.</p>
<p><img alt="sas-sim" src="/img/sas-sim.png"></p>
<p>However, the continuity correction especially stands out when looking at small sample sizes (in this case, simulated players with fewer than 30 shooting streaks over the course of the season).</p>
<p>In the below graph, red are the SAS corrected z-scores, green are the wald-wolfowitz z scores, brown are the overlap.</p>
<p><img alt="sas-low-vol" src="/img/sas-low-vol.png"></p>
<p>Continuity corrections are at best an imperfect substitute for calculating the exact odds. These days, there's no reason not to use exact odds for smaller sample sizes. Even though it ended up not mattering much, I should've started with the percentile rank for individual games.</p>                    </article>
                </aside><!-- /#featured -->
                <section id="extras" class="body">
                                <div class="social">
                                        <h2>social</h2>
                                        <ul>
                                                        <li><a href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                                        </ul>
                                </div><!-- /.social -->
                </section><!-- /#extras -->

                <footer id="contentinfo" class="body">
                        <address id="about" class="vcard body">
                                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                        </address><!-- /#about -->

                        <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
                </footer><!-- /#contentinfo -->

        </body>
</html>